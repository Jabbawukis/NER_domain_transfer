2023-07-07 12:13:06,623 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,625 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-07 12:13:06,625 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,625 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-07 12:13:06,625 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,625 Train:  14987 sentences
2023-07-07 12:13:06,625         (train_with_dev=False, train_with_test=False)
2023-07-07 12:13:06,625 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,625 Training Params:
2023-07-07 12:13:06,625  - learning_rate: "6e-05" 
2023-07-07 12:13:06,625  - mini_batch_size: "40"
2023-07-07 12:13:06,625  - max_epochs: "10"
2023-07-07 12:13:06,625  - shuffle: "True"
2023-07-07 12:13:06,625 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,625 Plugins:
2023-07-07 12:13:06,625  - LinearScheduler | warmup_fraction: '0.1'
2023-07-07 12:13:06,625 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,625 Final evaluation on model after last epoch (final-model.pt)
2023-07-07 12:13:06,625  - metric: "('micro avg', 'f1-score')"
2023-07-07 12:13:06,625 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,626 Computation:
2023-07-07 12:13:06,626  - compute on device: cuda:1
2023-07-07 12:13:06,626  - embedding storage: none
2023-07-07 12:13:06,626 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,626 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_40_lr_6e-05_ger_test_as_dev"
2023-07-07 12:13:06,626 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,626 Removed gradient clipping
2023-07-07 12:13:06,626 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:06,626 ----------------------------------------------------------------------------------------------------
2023-07-07 12:13:51,571 epoch 1 - iter 37/375 - loss 2.65728904 - time (sec): 44.94 - samples/sec: 446.54 - lr: 0.000006 - momentum: 0.000000
2023-07-07 12:14:36,708 epoch 1 - iter 74/375 - loss 1.68568304 - time (sec): 90.08 - samples/sec: 458.34 - lr: 0.000012 - momentum: 0.000000
2023-07-07 12:15:23,949 epoch 1 - iter 111/375 - loss 1.30439049 - time (sec): 137.32 - samples/sec: 450.54 - lr: 0.000018 - momentum: 0.000000
2023-07-07 12:16:10,948 epoch 1 - iter 148/375 - loss 1.07875019 - time (sec): 184.32 - samples/sec: 442.83 - lr: 0.000024 - momentum: 0.000000
2023-07-07 12:16:57,958 epoch 1 - iter 185/375 - loss 0.90935793 - time (sec): 231.33 - samples/sec: 438.92 - lr: 0.000029 - momentum: 0.000000
2023-07-07 12:17:45,132 epoch 1 - iter 222/375 - loss 0.78414702 - time (sec): 278.50 - samples/sec: 436.43 - lr: 0.000035 - momentum: 0.000000
2023-07-07 12:18:30,664 epoch 1 - iter 259/375 - loss 0.69040174 - time (sec): 324.04 - samples/sec: 436.65 - lr: 0.000041 - momentum: 0.000000
2023-07-07 12:19:17,223 epoch 1 - iter 296/375 - loss 0.61702991 - time (sec): 370.60 - samples/sec: 437.12 - lr: 0.000047 - momentum: 0.000000
2023-07-07 12:20:03,162 epoch 1 - iter 333/375 - loss 0.56359143 - time (sec): 416.53 - samples/sec: 435.54 - lr: 0.000053 - momentum: 0.000000
2023-07-07 12:20:48,782 epoch 1 - iter 370/375 - loss 0.60811948 - time (sec): 462.15 - samples/sec: 436.97 - lr: 0.000059 - momentum: 0.000000
2023-07-07 12:20:54,820 ----------------------------------------------------------------------------------------------------
2023-07-07 12:20:54,821 EPOCH 1 done: loss 0.6125 - lr: 0.000059
2023-07-07 12:21:44,802 DEV : loss 0.502882182598114 - f1-score (micro avg)  0.0
2023-07-07 12:22:27,773 TEST : loss 0.9454298615455627 - f1-score (micro avg)  0.0
2023-07-07 12:22:27,856 ----------------------------------------------------------------------------------------------------
2023-07-07 12:23:13,209 epoch 2 - iter 37/375 - loss 0.94382795 - time (sec): 45.35 - samples/sec: 437.59 - lr: 0.000059 - momentum: 0.000000
2023-07-07 12:24:00,815 epoch 2 - iter 74/375 - loss 0.95490897 - time (sec): 92.96 - samples/sec: 426.80 - lr: 0.000059 - momentum: 0.000000
2023-07-07 12:24:47,150 epoch 2 - iter 111/375 - loss 0.94701570 - time (sec): 139.29 - samples/sec: 432.93 - lr: 0.000058 - momentum: 0.000000
2023-07-07 12:25:33,166 epoch 2 - iter 148/375 - loss 0.94821037 - time (sec): 185.31 - samples/sec: 434.37 - lr: 0.000057 - momentum: 0.000000
2023-07-07 12:26:18,427 epoch 2 - iter 185/375 - loss 0.93730184 - time (sec): 230.57 - samples/sec: 436.40 - lr: 0.000057 - momentum: 0.000000
2023-07-07 12:27:03,722 epoch 2 - iter 222/375 - loss 0.92844145 - time (sec): 275.86 - samples/sec: 439.51 - lr: 0.000056 - momentum: 0.000000
2023-07-07 12:27:49,356 epoch 2 - iter 259/375 - loss 0.92818294 - time (sec): 321.50 - samples/sec: 439.13 - lr: 0.000055 - momentum: 0.000000
2023-07-07 12:28:35,079 epoch 2 - iter 296/375 - loss 0.92890138 - time (sec): 367.22 - samples/sec: 440.78 - lr: 0.000055 - momentum: 0.000000
2023-07-07 12:29:19,500 epoch 2 - iter 333/375 - loss 0.92810871 - time (sec): 411.64 - samples/sec: 440.60 - lr: 0.000054 - momentum: 0.000000
2023-07-07 12:30:04,801 epoch 2 - iter 370/375 - loss 0.92900038 - time (sec): 456.94 - samples/sec: 441.94 - lr: 0.000053 - momentum: 0.000000
2023-07-07 12:30:10,453 ----------------------------------------------------------------------------------------------------
2023-07-07 12:30:10,454 EPOCH 2 done: loss 0.9282 - lr: 0.000053
2023-07-07 12:30:54,419 DEV : loss 0.5033127069473267 - f1-score (micro avg)  0.0
2023-07-07 12:31:35,105 TEST : loss 0.9497050642967224 - f1-score (micro avg)  0.0
2023-07-07 12:31:35,166 ----------------------------------------------------------------------------------------------------
2023-07-07 12:32:20,187 epoch 3 - iter 37/375 - loss 0.87811454 - time (sec): 45.02 - samples/sec: 456.62 - lr: 0.000053 - momentum: 0.000000
2023-07-07 12:33:05,892 epoch 3 - iter 74/375 - loss 0.89159104 - time (sec): 90.72 - samples/sec: 450.10 - lr: 0.000052 - momentum: 0.000000
2023-07-07 12:33:52,021 epoch 3 - iter 111/375 - loss 0.89124274 - time (sec): 136.85 - samples/sec: 441.99 - lr: 0.000051 - momentum: 0.000000
2023-07-07 12:34:37,724 epoch 3 - iter 148/375 - loss 0.89295082 - time (sec): 182.56 - samples/sec: 441.93 - lr: 0.000051 - momentum: 0.000000
2023-07-07 12:35:24,520 epoch 3 - iter 185/375 - loss 0.89339282 - time (sec): 229.35 - samples/sec: 440.48 - lr: 0.000050 - momentum: 0.000000
2023-07-07 12:36:10,679 epoch 3 - iter 222/375 - loss 0.89608178 - time (sec): 275.51 - samples/sec: 440.05 - lr: 0.000049 - momentum: 0.000000
2023-07-07 12:36:56,026 epoch 3 - iter 259/375 - loss 0.89544659 - time (sec): 320.86 - samples/sec: 441.27 - lr: 0.000049 - momentum: 0.000000
2023-07-07 12:37:41,800 epoch 3 - iter 296/375 - loss 0.89801401 - time (sec): 366.63 - samples/sec: 440.67 - lr: 0.000048 - momentum: 0.000000
2023-07-07 12:38:27,838 epoch 3 - iter 333/375 - loss 0.89848427 - time (sec): 412.67 - samples/sec: 440.80 - lr: 0.000047 - momentum: 0.000000
2023-07-07 12:39:15,432 epoch 3 - iter 370/375 - loss 0.89610489 - time (sec): 460.26 - samples/sec: 439.28 - lr: 0.000047 - momentum: 0.000000
2023-07-07 12:39:21,198 ----------------------------------------------------------------------------------------------------
2023-07-07 12:39:21,198 EPOCH 3 done: loss 0.8973 - lr: 0.000047
2023-07-07 12:40:03,808 DEV : loss 0.500757098197937 - f1-score (micro avg)  0.0
2023-07-07 12:40:45,656 TEST : loss 0.9302068948745728 - f1-score (micro avg)  0.0
2023-07-07 12:40:45,708 ----------------------------------------------------------------------------------------------------
2023-07-07 12:41:30,412 epoch 4 - iter 37/375 - loss 0.89270405 - time (sec): 44.70 - samples/sec: 454.85 - lr: 0.000046 - momentum: 0.000000
2023-07-07 12:42:17,065 epoch 4 - iter 74/375 - loss 0.90231390 - time (sec): 91.36 - samples/sec: 432.34 - lr: 0.000045 - momentum: 0.000000
2023-07-07 12:43:02,337 epoch 4 - iter 111/375 - loss 0.89723560 - time (sec): 136.63 - samples/sec: 436.24 - lr: 0.000045 - momentum: 0.000000
2023-07-07 12:43:48,538 epoch 4 - iter 148/375 - loss 0.89400213 - time (sec): 182.83 - samples/sec: 435.79 - lr: 0.000044 - momentum: 0.000000
2023-07-07 12:44:33,692 epoch 4 - iter 185/375 - loss 0.89520480 - time (sec): 227.98 - samples/sec: 440.40 - lr: 0.000043 - momentum: 0.000000
2023-07-07 12:45:18,385 epoch 4 - iter 222/375 - loss 0.88946050 - time (sec): 272.68 - samples/sec: 444.14 - lr: 0.000043 - momentum: 0.000000
2023-07-07 12:46:03,945 epoch 4 - iter 259/375 - loss 0.88784210 - time (sec): 318.24 - samples/sec: 442.44 - lr: 0.000042 - momentum: 0.000000
2023-07-07 12:46:49,485 epoch 4 - iter 296/375 - loss 0.88471048 - time (sec): 363.78 - samples/sec: 445.25 - lr: 0.000041 - momentum: 0.000000
2023-07-07 12:47:34,656 epoch 4 - iter 333/375 - loss 0.88184413 - time (sec): 408.95 - samples/sec: 445.13 - lr: 0.000041 - momentum: 0.000000
2023-07-07 12:48:18,938 epoch 4 - iter 370/375 - loss 0.88404595 - time (sec): 453.23 - samples/sec: 446.15 - lr: 0.000040 - momentum: 0.000000
2023-07-07 12:48:24,874 ----------------------------------------------------------------------------------------------------
2023-07-07 12:48:24,874 EPOCH 4 done: loss 0.8852 - lr: 0.000040
2023-07-07 12:49:09,220 DEV : loss 0.5038666129112244 - f1-score (micro avg)  0.0
2023-07-07 12:49:52,179 TEST : loss 0.8973074555397034 - f1-score (micro avg)  0.0
2023-07-07 12:49:52,253 ----------------------------------------------------------------------------------------------------
2023-07-07 12:50:37,551 epoch 5 - iter 37/375 - loss 0.92178542 - time (sec): 45.30 - samples/sec: 435.07 - lr: 0.000039 - momentum: 0.000000
2023-07-07 12:51:22,685 epoch 5 - iter 74/375 - loss 0.90357000 - time (sec): 90.43 - samples/sec: 437.68 - lr: 0.000039 - momentum: 0.000000
2023-07-07 12:52:08,940 epoch 5 - iter 111/375 - loss 0.89576658 - time (sec): 136.68 - samples/sec: 434.27 - lr: 0.000038 - momentum: 0.000000
2023-07-07 12:52:55,562 epoch 5 - iter 148/375 - loss 0.88375639 - time (sec): 183.31 - samples/sec: 436.67 - lr: 0.000037 - momentum: 0.000000
2023-07-07 12:53:42,347 epoch 5 - iter 185/375 - loss 0.88075951 - time (sec): 230.09 - samples/sec: 438.65 - lr: 0.000037 - momentum: 0.000000
2023-07-07 12:54:28,610 epoch 5 - iter 222/375 - loss 0.88259320 - time (sec): 276.35 - samples/sec: 438.15 - lr: 0.000036 - momentum: 0.000000
2023-07-07 12:55:14,819 epoch 5 - iter 259/375 - loss 0.87963645 - time (sec): 322.56 - samples/sec: 438.86 - lr: 0.000035 - momentum: 0.000000
2023-07-07 12:56:01,289 epoch 5 - iter 296/375 - loss 0.87880191 - time (sec): 369.03 - samples/sec: 437.77 - lr: 0.000035 - momentum: 0.000000
2023-07-07 12:56:47,713 epoch 5 - iter 333/375 - loss 0.88313640 - time (sec): 415.46 - samples/sec: 437.50 - lr: 0.000034 - momentum: 0.000000
2023-07-07 12:57:33,962 epoch 5 - iter 370/375 - loss 0.88213766 - time (sec): 461.71 - samples/sec: 437.42 - lr: 0.000033 - momentum: 0.000000
2023-07-07 12:57:39,871 ----------------------------------------------------------------------------------------------------
2023-07-07 12:57:39,872 EPOCH 5 done: loss 0.8820 - lr: 0.000033
2023-07-07 12:58:23,384 DEV : loss 0.49943840503692627 - f1-score (micro avg)  0.0
2023-07-07 12:59:04,466 TEST : loss 0.9215282201766968 - f1-score (micro avg)  0.0
2023-07-07 12:59:04,527 ----------------------------------------------------------------------------------------------------
2023-07-07 12:59:50,915 epoch 6 - iter 37/375 - loss 0.89942710 - time (sec): 46.39 - samples/sec: 430.13 - lr: 0.000033 - momentum: 0.000000
2023-07-07 13:00:37,400 epoch 6 - iter 74/375 - loss 0.88547140 - time (sec): 92.87 - samples/sec: 435.64 - lr: 0.000032 - momentum: 0.000000
2023-07-07 13:01:23,087 epoch 6 - iter 111/375 - loss 0.88077681 - time (sec): 138.56 - samples/sec: 438.10 - lr: 0.000031 - momentum: 0.000000
2023-07-07 13:02:09,475 epoch 6 - iter 148/375 - loss 0.88399336 - time (sec): 184.95 - samples/sec: 432.61 - lr: 0.000031 - momentum: 0.000000
2023-07-07 13:02:54,494 epoch 6 - iter 185/375 - loss 0.88653655 - time (sec): 229.97 - samples/sec: 436.74 - lr: 0.000030 - momentum: 0.000000
2023-07-07 13:03:40,146 epoch 6 - iter 222/375 - loss 0.88024842 - time (sec): 275.62 - samples/sec: 439.30 - lr: 0.000029 - momentum: 0.000000
2023-07-07 13:04:25,643 epoch 6 - iter 259/375 - loss 0.88020658 - time (sec): 321.11 - samples/sec: 440.60 - lr: 0.000029 - momentum: 0.000000
2023-07-07 13:05:11,909 epoch 6 - iter 296/375 - loss 0.87868131 - time (sec): 367.38 - samples/sec: 440.88 - lr: 0.000028 - momentum: 0.000000
2023-07-07 13:05:56,344 epoch 6 - iter 333/375 - loss 0.87907536 - time (sec): 411.81 - samples/sec: 442.27 - lr: 0.000027 - momentum: 0.000000
2023-07-07 13:06:43,070 epoch 6 - iter 370/375 - loss 0.87785166 - time (sec): 458.54 - samples/sec: 441.25 - lr: 0.000027 - momentum: 0.000000
2023-07-07 13:06:48,996 ----------------------------------------------------------------------------------------------------
2023-07-07 13:06:48,996 EPOCH 6 done: loss 0.8782 - lr: 0.000027
2023-07-07 13:07:31,344 DEV : loss 0.5010719895362854 - f1-score (micro avg)  0.0
2023-07-07 13:08:13,510 TEST : loss 0.9031458497047424 - f1-score (micro avg)  0.0
2023-07-07 13:08:13,562 ----------------------------------------------------------------------------------------------------
2023-07-07 13:09:00,016 epoch 7 - iter 37/375 - loss 0.85720625 - time (sec): 46.45 - samples/sec: 452.19 - lr: 0.000026 - momentum: 0.000000
2023-07-07 13:09:46,553 epoch 7 - iter 74/375 - loss 0.86644416 - time (sec): 92.99 - samples/sec: 447.82 - lr: 0.000025 - momentum: 0.000000
2023-07-07 13:10:33,358 epoch 7 - iter 111/375 - loss 0.87179934 - time (sec): 139.79 - samples/sec: 442.32 - lr: 0.000025 - momentum: 0.000000
2023-07-07 13:11:21,008 epoch 7 - iter 148/375 - loss 0.87195402 - time (sec): 187.44 - samples/sec: 434.26 - lr: 0.000024 - momentum: 0.000000
2023-07-07 13:12:08,315 epoch 7 - iter 185/375 - loss 0.86904893 - time (sec): 234.75 - samples/sec: 431.07 - lr: 0.000023 - momentum: 0.000000
2023-07-07 13:12:55,710 epoch 7 - iter 222/375 - loss 0.87310739 - time (sec): 282.15 - samples/sec: 429.89 - lr: 0.000023 - momentum: 0.000000
2023-07-07 13:13:42,444 epoch 7 - iter 259/375 - loss 0.87850378 - time (sec): 328.88 - samples/sec: 428.48 - lr: 0.000022 - momentum: 0.000000
2023-07-07 13:14:29,579 epoch 7 - iter 296/375 - loss 0.87990758 - time (sec): 376.02 - samples/sec: 427.55 - lr: 0.000021 - momentum: 0.000000
2023-07-07 13:15:17,176 epoch 7 - iter 333/375 - loss 0.88058321 - time (sec): 423.61 - samples/sec: 427.78 - lr: 0.000021 - momentum: 0.000000
2023-07-07 13:16:03,386 epoch 7 - iter 370/375 - loss 0.87769956 - time (sec): 469.82 - samples/sec: 429.94 - lr: 0.000020 - momentum: 0.000000
2023-07-07 13:16:09,362 ----------------------------------------------------------------------------------------------------
2023-07-07 13:16:09,362 EPOCH 7 done: loss 0.8778 - lr: 0.000020
2023-07-07 13:16:53,568 DEV : loss 0.4983399510383606 - f1-score (micro avg)  0.0
2023-07-07 13:17:38,273 TEST : loss 0.9256384372711182 - f1-score (micro avg)  0.0
2023-07-07 13:17:38,336 ----------------------------------------------------------------------------------------------------
2023-07-07 13:18:24,962 epoch 8 - iter 37/375 - loss 0.88058248 - time (sec): 46.62 - samples/sec: 448.52 - lr: 0.000019 - momentum: 0.000000
2023-07-07 13:19:10,221 epoch 8 - iter 74/375 - loss 0.87775581 - time (sec): 91.88 - samples/sec: 443.99 - lr: 0.000019 - momentum: 0.000000
2023-07-07 13:19:55,485 epoch 8 - iter 111/375 - loss 0.87239352 - time (sec): 137.15 - samples/sec: 445.30 - lr: 0.000018 - momentum: 0.000000
2023-07-07 13:20:41,244 epoch 8 - iter 148/375 - loss 0.87706093 - time (sec): 182.91 - samples/sec: 445.97 - lr: 0.000017 - momentum: 0.000000
2023-07-07 13:21:27,781 epoch 8 - iter 185/375 - loss 0.87516073 - time (sec): 229.44 - samples/sec: 439.87 - lr: 0.000017 - momentum: 0.000000
2023-07-07 13:22:13,883 epoch 8 - iter 222/375 - loss 0.87512545 - time (sec): 275.54 - samples/sec: 441.45 - lr: 0.000016 - momentum: 0.000000
2023-07-07 13:22:59,832 epoch 8 - iter 259/375 - loss 0.87601531 - time (sec): 321.49 - samples/sec: 444.42 - lr: 0.000015 - momentum: 0.000000
2023-07-07 13:23:46,007 epoch 8 - iter 296/375 - loss 0.87952651 - time (sec): 367.67 - samples/sec: 442.01 - lr: 0.000015 - momentum: 0.000000
2023-07-07 13:24:30,582 epoch 8 - iter 333/375 - loss 0.87849130 - time (sec): 412.24 - samples/sec: 441.45 - lr: 0.000014 - momentum: 0.000000
2023-07-07 13:25:16,546 epoch 8 - iter 370/375 - loss 0.87518173 - time (sec): 458.21 - samples/sec: 440.61 - lr: 0.000014 - momentum: 0.000000
2023-07-07 13:25:22,561 ----------------------------------------------------------------------------------------------------
2023-07-07 13:25:22,562 EPOCH 8 done: loss 0.8755 - lr: 0.000014
2023-07-07 13:26:07,010 DEV : loss 0.5006666779518127 - f1-score (micro avg)  0.0
2023-07-07 13:26:49,653 TEST : loss 0.9068785309791565 - f1-score (micro avg)  0.0
2023-07-07 13:26:49,735 ----------------------------------------------------------------------------------------------------
2023-07-07 13:27:35,188 epoch 9 - iter 37/375 - loss 0.86770912 - time (sec): 45.45 - samples/sec: 463.25 - lr: 0.000013 - momentum: 0.000000
2023-07-07 13:28:21,795 epoch 9 - iter 74/375 - loss 0.86909992 - time (sec): 92.06 - samples/sec: 439.70 - lr: 0.000012 - momentum: 0.000000
2023-07-07 13:29:08,526 epoch 9 - iter 111/375 - loss 0.86263876 - time (sec): 138.79 - samples/sec: 436.62 - lr: 0.000011 - momentum: 0.000000
2023-07-07 13:29:52,898 epoch 9 - iter 148/375 - loss 0.86945068 - time (sec): 183.16 - samples/sec: 440.68 - lr: 0.000011 - momentum: 0.000000
2023-07-07 13:30:37,922 epoch 9 - iter 185/375 - loss 0.87305339 - time (sec): 228.18 - samples/sec: 439.77 - lr: 0.000010 - momentum: 0.000000
2023-07-07 13:31:23,043 epoch 9 - iter 222/375 - loss 0.87278525 - time (sec): 273.31 - samples/sec: 442.02 - lr: 0.000009 - momentum: 0.000000
2023-07-07 13:32:08,651 epoch 9 - iter 259/375 - loss 0.87603734 - time (sec): 318.91 - samples/sec: 443.41 - lr: 0.000009 - momentum: 0.000000
2023-07-07 13:32:53,228 epoch 9 - iter 296/375 - loss 0.87382757 - time (sec): 363.49 - samples/sec: 444.12 - lr: 0.000008 - momentum: 0.000000
2023-07-07 13:33:39,056 epoch 9 - iter 333/375 - loss 0.87448565 - time (sec): 409.32 - samples/sec: 442.76 - lr: 0.000008 - momentum: 0.000000
2023-07-07 13:34:23,989 epoch 9 - iter 370/375 - loss 0.87476709 - time (sec): 454.25 - samples/sec: 444.28 - lr: 0.000007 - momentum: 0.000000
2023-07-07 13:34:30,004 ----------------------------------------------------------------------------------------------------
2023-07-07 13:34:30,004 EPOCH 9 done: loss 0.8742 - lr: 0.000007
2023-07-07 13:35:13,125 DEV : loss 0.4993705451488495 - f1-score (micro avg)  0.0
2023-07-07 13:35:53,912 TEST : loss 0.9185920357704163 - f1-score (micro avg)  0.0
2023-07-07 13:35:53,990 ----------------------------------------------------------------------------------------------------
2023-07-07 13:36:40,175 epoch 10 - iter 37/375 - loss 0.88776374 - time (sec): 46.18 - samples/sec: 434.08 - lr: 0.000006 - momentum: 0.000000
2023-07-07 13:37:26,526 epoch 10 - iter 74/375 - loss 0.88139117 - time (sec): 92.53 - samples/sec: 426.98 - lr: 0.000005 - momentum: 0.000000
2023-07-07 13:38:12,905 epoch 10 - iter 111/375 - loss 0.88064294 - time (sec): 138.91 - samples/sec: 426.48 - lr: 0.000005 - momentum: 0.000000
2023-07-07 13:38:58,558 epoch 10 - iter 148/375 - loss 0.88122942 - time (sec): 184.57 - samples/sec: 429.52 - lr: 0.000004 - momentum: 0.000000
2023-07-07 13:39:45,417 epoch 10 - iter 185/375 - loss 0.88533050 - time (sec): 231.42 - samples/sec: 426.73 - lr: 0.000003 - momentum: 0.000000
2023-07-07 13:40:32,289 epoch 10 - iter 222/375 - loss 0.88396989 - time (sec): 278.30 - samples/sec: 429.64 - lr: 0.000003 - momentum: 0.000000
2023-07-07 13:41:18,280 epoch 10 - iter 259/375 - loss 0.88109664 - time (sec): 324.29 - samples/sec: 430.36 - lr: 0.000002 - momentum: 0.000000
2023-07-07 13:42:03,157 epoch 10 - iter 296/375 - loss 0.88036801 - time (sec): 369.16 - samples/sec: 433.18 - lr: 0.000002 - momentum: 0.000000
2023-07-07 13:42:49,770 epoch 10 - iter 333/375 - loss 0.87816736 - time (sec): 415.78 - samples/sec: 435.61 - lr: 0.000001 - momentum: 0.000000
2023-07-07 13:43:35,995 epoch 10 - iter 370/375 - loss 0.87304318 - time (sec): 462.00 - samples/sec: 437.56 - lr: 0.000000 - momentum: 0.000000
2023-07-07 13:43:41,435 ----------------------------------------------------------------------------------------------------
2023-07-07 13:43:41,435 EPOCH 10 done: loss 0.8734 - lr: 0.000000
2023-07-07 13:44:26,393 DEV : loss 0.49849164485931396 - f1-score (micro avg)  0.0
2023-07-07 13:45:09,011 TEST : loss 0.9189719557762146 - f1-score (micro avg)  0.0
2023-07-07 13:45:21,772 ----------------------------------------------------------------------------------------------------
2023-07-07 13:45:21,774 Testing using last state of model ...
2023-07-07 13:46:04,294 
Results:
- F-score (micro) 0.0
- F-score (macro) 0.0
- Accuracy 0.0

By class:
              precision    recall  f1-score   support

         LOC     0.0000    0.0000    0.0000    1668.0
         ORG     0.0000    0.0000    0.0000    1661.0
         PER     0.0000    0.0000    0.0000    1617.0
        MISC     0.0000    0.0000    0.0000     702.0

   micro avg     0.0000    0.0000    0.0000    5648.0
   macro avg     0.0000    0.0000    0.0000    5648.0
weighted avg     0.0000    0.0000    0.0000    5648.0

2023-07-07 13:46:04,295 ----------------------------------------------------------------------------------------------------
