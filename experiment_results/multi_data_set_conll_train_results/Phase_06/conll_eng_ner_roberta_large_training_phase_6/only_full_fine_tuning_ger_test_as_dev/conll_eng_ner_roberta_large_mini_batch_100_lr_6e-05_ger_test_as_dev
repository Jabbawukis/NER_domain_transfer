2023-07-07 18:26:16,074 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Train:  14987 sentences
2023-07-07 18:26:16,076         (train_with_dev=False, train_with_test=False)
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Training Params:
2023-07-07 18:26:16,076  - learning_rate: "6e-05" 
2023-07-07 18:26:16,076  - mini_batch_size: "100"
2023-07-07 18:26:16,076  - max_epochs: "10"
2023-07-07 18:26:16,076  - shuffle: "True"
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Plugins:
2023-07-07 18:26:16,076  - LinearScheduler | warmup_fraction: '0.1'
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Final evaluation on model after last epoch (final-model.pt)
2023-07-07 18:26:16,076  - metric: "('micro avg', 'f1-score')"
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Computation:
2023-07-07 18:26:16,076  - compute on device: cuda:1
2023-07-07 18:26:16,076  - embedding storage: none
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_6e-05_ger_test_as_dev"
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 Removed gradient clipping
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:26:16,076 ----------------------------------------------------------------------------------------------------
2023-07-07 18:27:00,818 epoch 1 - iter 15/150 - loss 3.41563097 - time (sec): 44.74 - samples/sec: 475.23 - lr: 0.000006 - momentum: 0.000000
2023-07-07 18:27:48,673 epoch 1 - iter 30/150 - loss 2.56420920 - time (sec): 92.60 - samples/sec: 439.48 - lr: 0.000012 - momentum: 0.000000
2023-07-07 18:28:35,971 epoch 1 - iter 45/150 - loss 1.94968382 - time (sec): 139.89 - samples/sec: 437.94 - lr: 0.000018 - momentum: 0.000000
2023-07-07 18:29:24,366 epoch 1 - iter 60/150 - loss 1.59560312 - time (sec): 188.29 - samples/sec: 435.14 - lr: 0.000024 - momentum: 0.000000
2023-07-07 18:30:12,575 epoch 1 - iter 75/150 - loss 1.36725528 - time (sec): 236.50 - samples/sec: 433.37 - lr: 0.000030 - momentum: 0.000000
2023-07-07 18:31:01,493 epoch 1 - iter 90/150 - loss 1.19715640 - time (sec): 285.42 - samples/sec: 431.59 - lr: 0.000036 - momentum: 0.000000
2023-07-07 18:31:48,594 epoch 1 - iter 105/150 - loss 1.06562806 - time (sec): 332.52 - samples/sec: 432.33 - lr: 0.000042 - momentum: 0.000000
2023-07-07 18:32:32,925 epoch 1 - iter 120/150 - loss 0.95972054 - time (sec): 376.85 - samples/sec: 435.10 - lr: 0.000048 - momentum: 0.000000
2023-07-07 18:33:17,518 epoch 1 - iter 135/150 - loss 0.86793412 - time (sec): 421.44 - samples/sec: 438.41 - lr: 0.000054 - momentum: 0.000000
2023-07-07 18:33:59,986 epoch 1 - iter 150/150 - loss 0.79616849 - time (sec): 463.91 - samples/sec: 440.96 - lr: 0.000060 - momentum: 0.000000
2023-07-07 18:33:59,987 ----------------------------------------------------------------------------------------------------
2023-07-07 18:33:59,987 EPOCH 1 done: loss 0.7962 - lr: 0.000060
2023-07-07 18:34:45,226 DEV : loss 0.2165522575378418 - f1-score (micro avg)  0.672
2023-07-07 18:35:26,009 TEST : loss 0.12119481712579727 - f1-score (micro avg)  0.8864
2023-07-07 18:35:26,056 ----------------------------------------------------------------------------------------------------
2023-07-07 18:36:11,208 epoch 2 - iter 15/150 - loss 0.11093392 - time (sec): 45.15 - samples/sec: 447.15 - lr: 0.000059 - momentum: 0.000000
2023-07-07 18:36:55,678 epoch 2 - iter 30/150 - loss 0.45029413 - time (sec): 89.62 - samples/sec: 453.20 - lr: 0.000059 - momentum: 0.000000
2023-07-07 18:37:39,414 epoch 2 - iter 45/150 - loss 0.74175280 - time (sec): 133.36 - samples/sec: 459.70 - lr: 0.000058 - momentum: 0.000000
2023-07-07 18:38:24,934 epoch 2 - iter 60/150 - loss 0.80052250 - time (sec): 178.88 - samples/sec: 457.72 - lr: 0.000057 - momentum: 0.000000
2023-07-07 18:39:09,942 epoch 2 - iter 75/150 - loss 0.82510762 - time (sec): 223.88 - samples/sec: 456.63 - lr: 0.000057 - momentum: 0.000000
2023-07-07 18:39:56,288 epoch 2 - iter 90/150 - loss 0.84609353 - time (sec): 270.23 - samples/sec: 451.99 - lr: 0.000056 - momentum: 0.000000
2023-07-07 18:40:44,573 epoch 2 - iter 105/150 - loss 0.86238543 - time (sec): 318.52 - samples/sec: 447.52 - lr: 0.000055 - momentum: 0.000000
2023-07-07 18:41:32,529 epoch 2 - iter 120/150 - loss 0.87264755 - time (sec): 366.47 - samples/sec: 444.99 - lr: 0.000055 - momentum: 0.000000
2023-07-07 18:42:21,116 epoch 2 - iter 135/150 - loss 0.88146430 - time (sec): 415.06 - samples/sec: 442.18 - lr: 0.000054 - momentum: 0.000000
2023-07-07 18:43:09,328 epoch 2 - iter 150/150 - loss 0.88529675 - time (sec): 463.27 - samples/sec: 441.57 - lr: 0.000053 - momentum: 0.000000
2023-07-07 18:43:09,328 ----------------------------------------------------------------------------------------------------
2023-07-07 18:43:09,328 EPOCH 2 done: loss 0.8853 - lr: 0.000053
2023-07-07 18:43:57,303 DEV : loss 0.4983849823474884 - f1-score (micro avg)  0.0
2023-07-07 18:44:44,859 TEST : loss 0.9232298731803894 - f1-score (micro avg)  0.0
2023-07-07 18:44:44,912 ----------------------------------------------------------------------------------------------------
2023-07-07 18:45:30,937 epoch 3 - iter 15/150 - loss 0.93456057 - time (sec): 46.02 - samples/sec: 451.48 - lr: 0.000053 - momentum: 0.000000
2023-07-07 18:46:17,203 epoch 3 - iter 30/150 - loss 0.94332028 - time (sec): 92.29 - samples/sec: 445.43 - lr: 0.000052 - momentum: 0.000000
2023-07-07 18:47:02,355 epoch 3 - iter 45/150 - loss 0.94146663 - time (sec): 137.44 - samples/sec: 445.52 - lr: 0.000051 - momentum: 0.000000
2023-07-07 18:47:48,541 epoch 3 - iter 60/150 - loss 0.93955833 - time (sec): 183.63 - samples/sec: 444.70 - lr: 0.000051 - momentum: 0.000000
2023-07-07 18:48:34,118 epoch 3 - iter 75/150 - loss 0.93599232 - time (sec): 229.20 - samples/sec: 443.36 - lr: 0.000050 - momentum: 0.000000
2023-07-07 18:49:19,404 epoch 3 - iter 90/150 - loss 0.93233105 - time (sec): 274.49 - samples/sec: 447.33 - lr: 0.000049 - momentum: 0.000000
2023-07-07 18:50:04,402 epoch 3 - iter 105/150 - loss 0.92429696 - time (sec): 319.49 - samples/sec: 449.77 - lr: 0.000049 - momentum: 0.000000
2023-07-07 18:50:50,299 epoch 3 - iter 120/150 - loss 0.92349286 - time (sec): 365.38 - samples/sec: 450.11 - lr: 0.000048 - momentum: 0.000000
2023-07-07 18:51:36,299 epoch 3 - iter 135/150 - loss 0.92293164 - time (sec): 411.38 - samples/sec: 448.20 - lr: 0.000047 - momentum: 0.000000
2023-07-07 18:52:22,078 epoch 3 - iter 150/150 - loss 0.92084807 - time (sec): 457.16 - samples/sec: 447.47 - lr: 0.000047 - momentum: 0.000000
2023-07-07 18:52:22,078 ----------------------------------------------------------------------------------------------------
2023-07-07 18:52:22,079 EPOCH 3 done: loss 0.9208 - lr: 0.000047
2023-07-07 18:53:09,609 DEV : loss 0.5008431077003479 - f1-score (micro avg)  0.0
2023-07-07 18:53:57,419 TEST : loss 0.9422571063041687 - f1-score (micro avg)  0.0
2023-07-07 18:53:57,476 ----------------------------------------------------------------------------------------------------
2023-07-07 18:54:45,812 epoch 4 - iter 15/150 - loss 0.89637510 - time (sec): 48.33 - samples/sec: 423.47 - lr: 0.000046 - momentum: 0.000000
2023-07-07 18:55:33,763 epoch 4 - iter 30/150 - loss 0.90091748 - time (sec): 96.29 - samples/sec: 434.24 - lr: 0.000045 - momentum: 0.000000
2023-07-07 18:56:21,944 epoch 4 - iter 45/150 - loss 0.90227359 - time (sec): 144.47 - samples/sec: 431.28 - lr: 0.000045 - momentum: 0.000000
2023-07-07 18:57:10,154 epoch 4 - iter 60/150 - loss 0.90292279 - time (sec): 192.68 - samples/sec: 429.53 - lr: 0.000044 - momentum: 0.000000
2023-07-07 18:57:57,672 epoch 4 - iter 75/150 - loss 0.90675837 - time (sec): 240.19 - samples/sec: 429.57 - lr: 0.000043 - momentum: 0.000000
2023-07-07 18:58:43,569 epoch 4 - iter 90/150 - loss 0.91143208 - time (sec): 286.09 - samples/sec: 430.33 - lr: 0.000043 - momentum: 0.000000
2023-07-07 18:59:28,670 epoch 4 - iter 105/150 - loss 0.91047855 - time (sec): 331.19 - samples/sec: 432.73 - lr: 0.000042 - momentum: 0.000000
2023-07-07 19:00:13,528 epoch 4 - iter 120/150 - loss 0.91362921 - time (sec): 376.05 - samples/sec: 436.53 - lr: 0.000041 - momentum: 0.000000
2023-07-07 19:01:00,275 epoch 4 - iter 135/150 - loss 0.91013410 - time (sec): 422.80 - samples/sec: 436.18 - lr: 0.000041 - momentum: 0.000000
2023-07-07 19:01:46,063 epoch 4 - iter 150/150 - loss 0.90710125 - time (sec): 468.59 - samples/sec: 436.56 - lr: 0.000040 - momentum: 0.000000
2023-07-07 19:01:46,064 ----------------------------------------------------------------------------------------------------
2023-07-07 19:01:46,064 EPOCH 4 done: loss 0.9071 - lr: 0.000040
2023-07-07 19:02:30,314 DEV : loss 0.49799075722694397 - f1-score (micro avg)  0.0
2023-07-07 19:03:11,910 TEST : loss 0.9247375726699829 - f1-score (micro avg)  0.0
2023-07-07 19:03:11,960 ----------------------------------------------------------------------------------------------------
2023-07-07 19:03:57,043 epoch 5 - iter 15/150 - loss 0.90088540 - time (sec): 45.08 - samples/sec: 445.46 - lr: 0.000039 - momentum: 0.000000
2023-07-07 19:04:41,642 epoch 5 - iter 30/150 - loss 0.91107412 - time (sec): 89.68 - samples/sec: 450.46 - lr: 0.000039 - momentum: 0.000000
2023-07-07 19:05:27,531 epoch 5 - iter 45/150 - loss 0.90667910 - time (sec): 135.57 - samples/sec: 445.15 - lr: 0.000038 - momentum: 0.000000
2023-07-07 19:06:16,556 epoch 5 - iter 60/150 - loss 0.89424805 - time (sec): 184.59 - samples/sec: 441.31 - lr: 0.000038 - momentum: 0.000000
2023-07-07 19:07:06,033 epoch 5 - iter 75/150 - loss 0.89773928 - time (sec): 234.07 - samples/sec: 436.52 - lr: 0.000037 - momentum: 0.000000
2023-07-07 19:07:53,851 epoch 5 - iter 90/150 - loss 0.89725464 - time (sec): 281.89 - samples/sec: 435.12 - lr: 0.000036 - momentum: 0.000000
2023-07-07 19:08:42,597 epoch 5 - iter 105/150 - loss 0.89977119 - time (sec): 330.64 - samples/sec: 433.22 - lr: 0.000036 - momentum: 0.000000
2023-07-07 19:09:31,309 epoch 5 - iter 120/150 - loss 0.89842481 - time (sec): 379.35 - samples/sec: 432.75 - lr: 0.000035 - momentum: 0.000000
2023-07-07 19:10:19,600 epoch 5 - iter 135/150 - loss 0.89723349 - time (sec): 427.64 - samples/sec: 432.32 - lr: 0.000034 - momentum: 0.000000
2023-07-07 19:11:03,818 epoch 5 - iter 150/150 - loss 0.89709590 - time (sec): 471.86 - samples/sec: 433.54 - lr: 0.000034 - momentum: 0.000000
2023-07-07 19:11:03,819 ----------------------------------------------------------------------------------------------------
2023-07-07 19:11:03,819 EPOCH 5 done: loss 0.8971 - lr: 0.000034
2023-07-07 19:11:48,965 DEV : loss 0.4994436800479889 - f1-score (micro avg)  0.0
2023-07-07 19:12:30,570 TEST : loss 0.9114576578140259 - f1-score (micro avg)  0.0
2023-07-07 19:12:30,632 ----------------------------------------------------------------------------------------------------
2023-07-07 19:13:16,960 epoch 6 - iter 15/150 - loss 0.88342051 - time (sec): 46.33 - samples/sec: 449.05 - lr: 0.000033 - momentum: 0.000000
2023-07-07 19:14:00,059 epoch 6 - iter 30/150 - loss 0.88775135 - time (sec): 89.43 - samples/sec: 471.43 - lr: 0.000032 - momentum: 0.000000
2023-07-07 19:14:43,048 epoch 6 - iter 45/150 - loss 0.89204240 - time (sec): 132.41 - samples/sec: 471.08 - lr: 0.000032 - momentum: 0.000000
2023-07-07 19:15:28,110 epoch 6 - iter 60/150 - loss 0.89459285 - time (sec): 177.48 - samples/sec: 467.12 - lr: 0.000031 - momentum: 0.000000
2023-07-07 19:16:15,026 epoch 6 - iter 75/150 - loss 0.89349241 - time (sec): 224.39 - samples/sec: 460.39 - lr: 0.000030 - momentum: 0.000000
2023-07-07 19:17:01,294 epoch 6 - iter 90/150 - loss 0.89008653 - time (sec): 270.66 - samples/sec: 454.99 - lr: 0.000030 - momentum: 0.000000
2023-07-07 19:17:46,815 epoch 6 - iter 105/150 - loss 0.89141508 - time (sec): 316.18 - samples/sec: 456.05 - lr: 0.000029 - momentum: 0.000000
2023-07-07 19:18:35,146 epoch 6 - iter 120/150 - loss 0.89056679 - time (sec): 364.51 - samples/sec: 450.82 - lr: 0.000028 - momentum: 0.000000
2023-07-07 19:19:23,691 epoch 6 - iter 135/150 - loss 0.88888876 - time (sec): 413.06 - samples/sec: 447.14 - lr: 0.000028 - momentum: 0.000000
2023-07-07 19:20:11,826 epoch 6 - iter 150/150 - loss 0.89053408 - time (sec): 461.19 - samples/sec: 443.56 - lr: 0.000027 - momentum: 0.000000
2023-07-07 19:20:11,827 ----------------------------------------------------------------------------------------------------
2023-07-07 19:20:11,827 EPOCH 6 done: loss 0.8905 - lr: 0.000027
2023-07-07 19:21:01,942 DEV : loss 0.5026911497116089 - f1-score (micro avg)  0.0
2023-07-07 19:21:48,249 TEST : loss 0.898270845413208 - f1-score (micro avg)  0.0
2023-07-07 19:21:48,303 ----------------------------------------------------------------------------------------------------
2023-07-07 19:22:37,654 epoch 7 - iter 15/150 - loss 0.88304019 - time (sec): 49.35 - samples/sec: 420.26 - lr: 0.000026 - momentum: 0.000000
2023-07-07 19:23:25,874 epoch 7 - iter 30/150 - loss 0.89885603 - time (sec): 97.57 - samples/sec: 422.83 - lr: 0.000026 - momentum: 0.000000
2023-07-07 19:24:11,215 epoch 7 - iter 45/150 - loss 0.89823112 - time (sec): 142.91 - samples/sec: 428.55 - lr: 0.000025 - momentum: 0.000000
2023-07-07 19:24:55,546 epoch 7 - iter 60/150 - loss 0.89704258 - time (sec): 187.24 - samples/sec: 435.64 - lr: 0.000024 - momentum: 0.000000
2023-07-07 19:25:39,091 epoch 7 - iter 75/150 - loss 0.89587654 - time (sec): 230.79 - samples/sec: 443.96 - lr: 0.000024 - momentum: 0.000000
2023-07-07 19:26:23,317 epoch 7 - iter 90/150 - loss 0.88983220 - time (sec): 275.01 - samples/sec: 447.80 - lr: 0.000023 - momentum: 0.000000
2023-07-07 19:27:06,099 epoch 7 - iter 105/150 - loss 0.88794244 - time (sec): 317.79 - samples/sec: 451.90 - lr: 0.000022 - momentum: 0.000000
2023-07-07 19:27:51,083 epoch 7 - iter 120/150 - loss 0.88604845 - time (sec): 362.78 - samples/sec: 452.24 - lr: 0.000022 - momentum: 0.000000
2023-07-07 19:28:37,178 epoch 7 - iter 135/150 - loss 0.88793093 - time (sec): 408.87 - samples/sec: 449.76 - lr: 0.000021 - momentum: 0.000000
2023-07-07 19:29:22,225 epoch 7 - iter 150/150 - loss 0.88658647 - time (sec): 453.92 - samples/sec: 450.67 - lr: 0.000020 - momentum: 0.000000
2023-07-07 19:29:22,225 ----------------------------------------------------------------------------------------------------
2023-07-07 19:29:22,226 EPOCH 7 done: loss 0.8866 - lr: 0.000020
2023-07-07 19:30:04,471 DEV : loss 0.49901705980300903 - f1-score (micro avg)  0.0
2023-07-07 19:30:48,116 TEST : loss 0.9117150902748108 - f1-score (micro avg)  0.0
2023-07-07 19:30:48,193 ----------------------------------------------------------------------------------------------------
2023-07-07 19:31:35,758 epoch 8 - iter 15/150 - loss 0.90471175 - time (sec): 47.56 - samples/sec: 437.13 - lr: 0.000020 - momentum: 0.000000
2023-07-07 19:32:23,536 epoch 8 - iter 30/150 - loss 0.89199588 - time (sec): 95.34 - samples/sec: 430.67 - lr: 0.000019 - momentum: 0.000000
2023-07-07 19:33:11,893 epoch 8 - iter 45/150 - loss 0.89106309 - time (sec): 143.70 - samples/sec: 425.55 - lr: 0.000018 - momentum: 0.000000
2023-07-07 19:34:00,458 epoch 8 - iter 60/150 - loss 0.88826349 - time (sec): 192.26 - samples/sec: 428.42 - lr: 0.000018 - momentum: 0.000000
2023-07-07 19:34:48,554 epoch 8 - iter 75/150 - loss 0.88666978 - time (sec): 240.36 - samples/sec: 428.11 - lr: 0.000017 - momentum: 0.000000
2023-07-07 19:35:36,995 epoch 8 - iter 90/150 - loss 0.88323182 - time (sec): 288.80 - samples/sec: 426.52 - lr: 0.000016 - momentum: 0.000000
2023-07-07 19:36:24,526 epoch 8 - iter 105/150 - loss 0.88697852 - time (sec): 336.33 - samples/sec: 426.71 - lr: 0.000016 - momentum: 0.000000
2023-07-07 19:37:10,058 epoch 8 - iter 120/150 - loss 0.88673941 - time (sec): 381.86 - samples/sec: 430.66 - lr: 0.000015 - momentum: 0.000000
2023-07-07 19:37:55,404 epoch 8 - iter 135/150 - loss 0.88371919 - time (sec): 427.21 - samples/sec: 433.10 - lr: 0.000014 - momentum: 0.000000
2023-07-07 19:38:39,117 epoch 8 - iter 150/150 - loss 0.88391031 - time (sec): 470.92 - samples/sec: 434.40 - lr: 0.000014 - momentum: 0.000000
2023-07-07 19:38:39,118 ----------------------------------------------------------------------------------------------------
2023-07-07 19:38:39,118 EPOCH 8 done: loss 0.8839 - lr: 0.000014
2023-07-07 19:39:22,217 DEV : loss 0.50238037109375 - f1-score (micro avg)  0.0
2023-07-07 19:40:04,118 TEST : loss 0.8981708288192749 - f1-score (micro avg)  0.0
2023-07-07 19:40:04,165 ----------------------------------------------------------------------------------------------------
2023-07-07 19:40:48,698 epoch 9 - iter 15/150 - loss 0.87352747 - time (sec): 44.53 - samples/sec: 460.05 - lr: 0.000013 - momentum: 0.000000
2023-07-07 19:41:35,907 epoch 9 - iter 30/150 - loss 0.88369947 - time (sec): 91.74 - samples/sec: 448.34 - lr: 0.000012 - momentum: 0.000000
2023-07-07 19:42:22,637 epoch 9 - iter 45/150 - loss 0.88365403 - time (sec): 138.47 - samples/sec: 442.68 - lr: 0.000012 - momentum: 0.000000
2023-07-07 19:43:08,353 epoch 9 - iter 60/150 - loss 0.88167539 - time (sec): 184.19 - samples/sec: 446.38 - lr: 0.000011 - momentum: 0.000000
2023-07-07 19:43:54,376 epoch 9 - iter 75/150 - loss 0.88245028 - time (sec): 230.21 - samples/sec: 446.41 - lr: 0.000010 - momentum: 0.000000
2023-07-07 19:44:44,081 epoch 9 - iter 90/150 - loss 0.88261329 - time (sec): 279.91 - samples/sec: 439.94 - lr: 0.000010 - momentum: 0.000000
2023-07-07 19:45:34,675 epoch 9 - iter 105/150 - loss 0.88190631 - time (sec): 330.51 - samples/sec: 434.98 - lr: 0.000009 - momentum: 0.000000
2023-07-07 19:46:23,986 epoch 9 - iter 120/150 - loss 0.88291891 - time (sec): 379.82 - samples/sec: 431.58 - lr: 0.000008 - momentum: 0.000000
2023-07-07 19:47:11,725 epoch 9 - iter 135/150 - loss 0.88302014 - time (sec): 427.56 - samples/sec: 429.98 - lr: 0.000008 - momentum: 0.000000
2023-07-07 19:47:59,478 epoch 9 - iter 150/150 - loss 0.88263904 - time (sec): 475.31 - samples/sec: 430.38 - lr: 0.000007 - momentum: 0.000000
2023-07-07 19:47:59,479 ----------------------------------------------------------------------------------------------------
2023-07-07 19:47:59,479 EPOCH 9 done: loss 0.8826 - lr: 0.000007
2023-07-07 19:48:47,041 DEV : loss 0.5020729899406433 - f1-score (micro avg)  0.0
2023-07-07 19:49:33,851 TEST : loss 0.8973793387413025 - f1-score (micro avg)  0.0
2023-07-07 19:49:33,898 ----------------------------------------------------------------------------------------------------
2023-07-07 19:50:20,460 epoch 10 - iter 15/150 - loss 0.85959027 - time (sec): 46.56 - samples/sec: 449.75 - lr: 0.000006 - momentum: 0.000000
2023-07-07 19:51:05,857 epoch 10 - iter 30/150 - loss 0.87232399 - time (sec): 91.96 - samples/sec: 439.44 - lr: 0.000006 - momentum: 0.000000
2023-07-07 19:51:52,376 epoch 10 - iter 45/150 - loss 0.88227382 - time (sec): 138.48 - samples/sec: 434.56 - lr: 0.000005 - momentum: 0.000000
2023-07-07 19:52:36,929 epoch 10 - iter 60/150 - loss 0.87747436 - time (sec): 183.03 - samples/sec: 441.77 - lr: 0.000004 - momentum: 0.000000
2023-07-07 19:53:21,952 epoch 10 - iter 75/150 - loss 0.87970772 - time (sec): 228.05 - samples/sec: 445.71 - lr: 0.000004 - momentum: 0.000000
2023-07-07 19:54:07,334 epoch 10 - iter 90/150 - loss 0.88012687 - time (sec): 273.44 - samples/sec: 447.07 - lr: 0.000003 - momentum: 0.000000
2023-07-07 19:54:53,886 epoch 10 - iter 105/150 - loss 0.88153878 - time (sec): 319.99 - samples/sec: 446.97 - lr: 0.000002 - momentum: 0.000000
2023-07-07 19:55:40,467 epoch 10 - iter 120/150 - loss 0.88100869 - time (sec): 366.57 - samples/sec: 447.04 - lr: 0.000002 - momentum: 0.000000
2023-07-07 19:56:26,096 epoch 10 - iter 135/150 - loss 0.88133842 - time (sec): 412.20 - samples/sec: 446.54 - lr: 0.000001 - momentum: 0.000000
2023-07-07 19:57:14,884 epoch 10 - iter 150/150 - loss 0.88097325 - time (sec): 460.98 - samples/sec: 443.76 - lr: 0.000000 - momentum: 0.000000
2023-07-07 19:57:14,884 ----------------------------------------------------------------------------------------------------
2023-07-07 19:57:14,884 EPOCH 10 done: loss 0.8810 - lr: 0.000000
2023-07-07 19:58:02,948 DEV : loss 0.5020866990089417 - f1-score (micro avg)  0.0
2023-07-07 19:58:49,587 TEST : loss 0.897179901599884 - f1-score (micro avg)  0.0
2023-07-07 19:59:03,045 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:03,051 Testing using last state of model ...
2023-07-07 19:59:50,596 
Results:
- F-score (micro) 0.0
- F-score (macro) 0.0
- Accuracy 0.0

By class:
              precision    recall  f1-score   support

         LOC     0.0000    0.0000    0.0000    1668.0
         ORG     0.0000    0.0000    0.0000    1661.0
         PER     0.0000    0.0000    0.0000    1617.0
        MISC     0.0000    0.0000    0.0000     702.0

   micro avg     0.0000    0.0000    0.0000    5648.0
   macro avg     0.0000    0.0000    0.0000    5648.0
weighted avg     0.0000    0.0000    0.0000    5648.0

2023-07-07 19:59:50,596 ----------------------------------------------------------------------------------------------------
