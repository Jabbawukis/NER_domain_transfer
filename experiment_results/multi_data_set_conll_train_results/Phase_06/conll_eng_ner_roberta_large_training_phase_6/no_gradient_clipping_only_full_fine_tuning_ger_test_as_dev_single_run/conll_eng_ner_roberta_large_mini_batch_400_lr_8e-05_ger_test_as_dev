2023-07-08 03:52:46,838 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,840 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-08 03:52:46,840 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,840 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-08 03:52:46,840 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,840 Train:  14987 sentences
2023-07-08 03:52:46,840         (train_with_dev=False, train_with_test=False)
2023-07-08 03:52:46,840 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,840 Training Params:
2023-07-08 03:52:46,840  - learning_rate: "8e-05" 
2023-07-08 03:52:46,840  - mini_batch_size: "400"
2023-07-08 03:52:46,840  - max_epochs: "10"
2023-07-08 03:52:46,840  - shuffle: "True"
2023-07-08 03:52:46,840 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,840 Plugins:
2023-07-08 03:52:46,840  - LinearScheduler | warmup_fraction: '0.1'
2023-07-08 03:52:46,840 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,840 Final evaluation on model after last epoch (final-model.pt)
2023-07-08 03:52:46,840  - metric: "('micro avg', 'f1-score')"
2023-07-08 03:52:46,840 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,840 Computation:
2023-07-08 03:52:46,841  - compute on device: cuda:1
2023-07-08 03:52:46,841  - embedding storage: none
2023-07-08 03:52:46,841 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,841 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_400_lr_8e-05_ger_test_as_dev"
2023-07-08 03:52:46,841 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,841 Removed gradient clipping
2023-07-08 03:52:46,841 ----------------------------------------------------------------------------------------------------
2023-07-08 03:52:46,841 ----------------------------------------------------------------------------------------------------
2023-07-08 03:53:24,569 epoch 1 - iter 3/38 - loss 3.97297717 - time (sec): 37.73 - samples/sec: 425.04 - lr: 0.000004 - momentum: 0.000000
2023-07-08 03:54:02,177 epoch 1 - iter 6/38 - loss 3.87248950 - time (sec): 75.33 - samples/sec: 425.10 - lr: 0.000011 - momentum: 0.000000
2023-07-08 03:54:38,436 epoch 1 - iter 9/38 - loss 3.63612643 - time (sec): 111.59 - samples/sec: 437.54 - lr: 0.000017 - momentum: 0.000000
2023-07-08 03:55:14,039 epoch 1 - iter 12/38 - loss 3.23584546 - time (sec): 147.20 - samples/sec: 440.50 - lr: 0.000023 - momentum: 0.000000
2023-07-08 03:55:50,553 epoch 1 - iter 15/38 - loss 2.81249090 - time (sec): 183.71 - samples/sec: 442.79 - lr: 0.000029 - momentum: 0.000000
2023-07-08 03:56:27,053 epoch 1 - iter 18/38 - loss 2.50881361 - time (sec): 220.21 - samples/sec: 444.14 - lr: 0.000036 - momentum: 0.000000
2023-07-08 03:57:02,762 epoch 1 - iter 21/38 - loss 2.26825433 - time (sec): 255.92 - samples/sec: 446.07 - lr: 0.000042 - momentum: 0.000000
2023-07-08 03:57:39,627 epoch 1 - iter 24/38 - loss 2.07212357 - time (sec): 292.78 - samples/sec: 445.90 - lr: 0.000048 - momentum: 0.000000
2023-07-08 03:58:15,066 epoch 1 - iter 27/38 - loss 1.90191615 - time (sec): 328.22 - samples/sec: 449.27 - lr: 0.000055 - momentum: 0.000000
2023-07-08 03:58:50,167 epoch 1 - iter 30/38 - loss 1.76608188 - time (sec): 363.32 - samples/sec: 451.38 - lr: 0.000061 - momentum: 0.000000
2023-07-08 03:59:25,887 epoch 1 - iter 33/38 - loss 1.65162814 - time (sec): 399.04 - samples/sec: 453.27 - lr: 0.000067 - momentum: 0.000000
2023-07-08 04:00:01,492 epoch 1 - iter 36/38 - loss 1.56101279 - time (sec): 434.65 - samples/sec: 451.83 - lr: 0.000074 - momentum: 0.000000
2023-07-08 04:00:18,955 ----------------------------------------------------------------------------------------------------
2023-07-08 04:00:18,955 EPOCH 1 done: loss 1.5178 - lr: 0.000074
2023-07-08 04:01:02,324 DEV : loss 0.2688646614551544 - f1-score (micro avg)  0.4997
2023-07-08 04:01:49,044 TEST : loss 0.40015608072280884 - f1-score (micro avg)  0.4664
2023-07-08 04:01:49,098 ----------------------------------------------------------------------------------------------------
2023-07-08 04:02:27,172 epoch 2 - iter 3/38 - loss 0.43592658 - time (sec): 38.07 - samples/sec: 416.58 - lr: 0.000080 - momentum: 0.000000
2023-07-08 04:03:06,344 epoch 2 - iter 6/38 - loss 0.42831131 - time (sec): 77.24 - samples/sec: 420.15 - lr: 0.000079 - momentum: 0.000000
2023-07-08 04:03:45,244 epoch 2 - iter 9/38 - loss 0.40508914 - time (sec): 116.14 - samples/sec: 419.14 - lr: 0.000078 - momentum: 0.000000
2023-07-08 04:04:22,464 epoch 2 - iter 12/38 - loss 0.38907657 - time (sec): 153.36 - samples/sec: 425.61 - lr: 0.000077 - momentum: 0.000000
2023-07-08 04:05:00,842 epoch 2 - iter 15/38 - loss 0.37028140 - time (sec): 191.74 - samples/sec: 423.18 - lr: 0.000077 - momentum: 0.000000
2023-07-08 04:05:39,759 epoch 2 - iter 18/38 - loss 0.35763557 - time (sec): 230.66 - samples/sec: 424.07 - lr: 0.000076 - momentum: 0.000000
2023-07-08 04:06:17,133 epoch 2 - iter 21/38 - loss 0.33976465 - time (sec): 268.03 - samples/sec: 427.39 - lr: 0.000075 - momentum: 0.000000
2023-07-08 04:06:53,477 epoch 2 - iter 24/38 - loss 0.32369244 - time (sec): 304.38 - samples/sec: 428.99 - lr: 0.000075 - momentum: 0.000000
2023-07-08 04:07:28,157 epoch 2 - iter 27/38 - loss 0.30890690 - time (sec): 339.06 - samples/sec: 432.57 - lr: 0.000074 - momentum: 0.000000
2023-07-08 04:08:03,472 epoch 2 - iter 30/38 - loss 0.29207756 - time (sec): 374.37 - samples/sec: 436.51 - lr: 0.000073 - momentum: 0.000000
2023-07-08 04:08:37,726 epoch 2 - iter 33/38 - loss 0.27719269 - time (sec): 408.63 - samples/sec: 440.44 - lr: 0.000073 - momentum: 0.000000
2023-07-08 04:09:13,789 epoch 2 - iter 36/38 - loss 0.26353453 - time (sec): 444.69 - samples/sec: 441.80 - lr: 0.000072 - momentum: 0.000000
2023-07-08 04:09:30,883 ----------------------------------------------------------------------------------------------------
2023-07-08 04:09:30,883 EPOCH 2 done: loss 0.2577 - lr: 0.000072
2023-07-08 04:10:13,359 DEV : loss 0.2237062007188797 - f1-score (micro avg)  0.6751
2023-07-08 04:10:57,416 TEST : loss 0.1106957420706749 - f1-score (micro avg)  0.8955
2023-07-08 04:10:57,600 ----------------------------------------------------------------------------------------------------
2023-07-08 04:11:32,851 epoch 3 - iter 3/38 - loss 0.10533034 - time (sec): 35.25 - samples/sec: 460.13 - lr: 0.000071 - momentum: 0.000000
2023-07-08 04:12:08,482 epoch 3 - iter 6/38 - loss 0.09978912 - time (sec): 70.88 - samples/sec: 461.87 - lr: 0.000070 - momentum: 0.000000
2023-07-08 04:12:45,047 epoch 3 - iter 9/38 - loss 0.09867653 - time (sec): 107.44 - samples/sec: 457.60 - lr: 0.000069 - momentum: 0.000000
2023-07-08 04:13:21,116 epoch 3 - iter 12/38 - loss 0.09668935 - time (sec): 143.51 - samples/sec: 455.99 - lr: 0.000069 - momentum: 0.000000
2023-07-08 04:13:56,436 epoch 3 - iter 15/38 - loss 0.09733774 - time (sec): 178.83 - samples/sec: 458.00 - lr: 0.000068 - momentum: 0.000000
2023-07-08 04:14:34,939 epoch 3 - iter 18/38 - loss 0.09316275 - time (sec): 217.33 - samples/sec: 453.02 - lr: 0.000067 - momentum: 0.000000
2023-07-08 04:15:14,761 epoch 3 - iter 21/38 - loss 0.09017700 - time (sec): 257.16 - samples/sec: 448.04 - lr: 0.000067 - momentum: 0.000000
2023-07-08 04:15:53,039 epoch 3 - iter 24/38 - loss 0.08747835 - time (sec): 295.43 - samples/sec: 446.10 - lr: 0.000066 - momentum: 0.000000
2023-07-08 04:16:30,465 epoch 3 - iter 27/38 - loss 0.08750493 - time (sec): 332.86 - samples/sec: 444.10 - lr: 0.000065 - momentum: 0.000000
2023-07-08 04:17:08,243 epoch 3 - iter 30/38 - loss 0.08491540 - time (sec): 370.64 - samples/sec: 444.09 - lr: 0.000065 - momentum: 0.000000
2023-07-08 04:17:47,070 epoch 3 - iter 33/38 - loss 0.08280007 - time (sec): 409.46 - samples/sec: 441.71 - lr: 0.000064 - momentum: 0.000000
2023-07-08 04:18:25,868 epoch 3 - iter 36/38 - loss 0.08105564 - time (sec): 448.26 - samples/sec: 439.74 - lr: 0.000063 - momentum: 0.000000
2023-07-08 04:18:44,027 ----------------------------------------------------------------------------------------------------
2023-07-08 04:18:44,028 EPOCH 3 done: loss 0.0800 - lr: 0.000063
2023-07-08 04:19:28,176 DEV : loss 0.20003783702850342 - f1-score (micro avg)  0.7171
2023-07-08 04:20:10,695 TEST : loss 0.08973414450883865 - f1-score (micro avg)  0.9196
2023-07-08 04:20:10,757 ----------------------------------------------------------------------------------------------------
2023-07-08 04:20:48,294 epoch 4 - iter 3/38 - loss 0.05562797 - time (sec): 37.53 - samples/sec: 442.34 - lr: 0.000062 - momentum: 0.000000
2023-07-08 04:21:24,837 epoch 4 - iter 6/38 - loss 0.05364643 - time (sec): 74.08 - samples/sec: 449.73 - lr: 0.000061 - momentum: 0.000000
2023-07-08 04:22:01,345 epoch 4 - iter 9/38 - loss 0.05286788 - time (sec): 110.59 - samples/sec: 451.64 - lr: 0.000061 - momentum: 0.000000
2023-07-08 04:22:37,845 epoch 4 - iter 12/38 - loss 0.05256803 - time (sec): 147.09 - samples/sec: 451.15 - lr: 0.000060 - momentum: 0.000000
2023-07-08 04:23:13,474 epoch 4 - iter 15/38 - loss 0.05031420 - time (sec): 182.71 - samples/sec: 453.70 - lr: 0.000059 - momentum: 0.000000
2023-07-08 04:23:50,358 epoch 4 - iter 18/38 - loss 0.04760865 - time (sec): 219.60 - samples/sec: 455.06 - lr: 0.000058 - momentum: 0.000000
2023-07-08 04:24:26,436 epoch 4 - iter 21/38 - loss 0.04766954 - time (sec): 255.68 - samples/sec: 454.69 - lr: 0.000058 - momentum: 0.000000
2023-07-08 04:25:01,468 epoch 4 - iter 24/38 - loss 0.04756161 - time (sec): 290.71 - samples/sec: 455.58 - lr: 0.000057 - momentum: 0.000000
2023-07-08 04:25:36,813 epoch 4 - iter 27/38 - loss 0.04744566 - time (sec): 326.05 - samples/sec: 455.67 - lr: 0.000056 - momentum: 0.000000
2023-07-08 04:26:12,814 epoch 4 - iter 30/38 - loss 0.04643546 - time (sec): 362.05 - samples/sec: 455.43 - lr: 0.000056 - momentum: 0.000000
2023-07-08 04:26:49,931 epoch 4 - iter 33/38 - loss 0.04659511 - time (sec): 399.17 - samples/sec: 452.40 - lr: 0.000055 - momentum: 0.000000
2023-07-08 04:27:27,377 epoch 4 - iter 36/38 - loss 0.04711635 - time (sec): 436.62 - samples/sec: 450.00 - lr: 0.000054 - momentum: 0.000000
2023-07-08 04:27:46,156 ----------------------------------------------------------------------------------------------------
2023-07-08 04:27:46,156 EPOCH 4 done: loss 0.0468 - lr: 0.000054
2023-07-08 04:28:36,684 DEV : loss 0.19931955635547638 - f1-score (micro avg)  0.7253
2023-07-08 04:29:23,929 TEST : loss 0.08713018149137497 - f1-score (micro avg)  0.9261
2023-07-08 04:29:23,977 ----------------------------------------------------------------------------------------------------
2023-07-08 04:30:02,553 epoch 5 - iter 3/38 - loss 0.03661382 - time (sec): 38.57 - samples/sec: 421.44 - lr: 0.000053 - momentum: 0.000000
2023-07-08 04:30:40,229 epoch 5 - iter 6/38 - loss 0.03465172 - time (sec): 76.25 - samples/sec: 425.35 - lr: 0.000052 - momentum: 0.000000
2023-07-08 04:31:17,210 epoch 5 - iter 9/38 - loss 0.03416570 - time (sec): 113.23 - samples/sec: 434.37 - lr: 0.000052 - momentum: 0.000000
2023-07-08 04:31:53,178 epoch 5 - iter 12/38 - loss 0.03346096 - time (sec): 149.20 - samples/sec: 440.44 - lr: 0.000051 - momentum: 0.000000
2023-07-08 04:32:29,267 epoch 5 - iter 15/38 - loss 0.03314016 - time (sec): 185.29 - samples/sec: 443.46 - lr: 0.000050 - momentum: 0.000000
2023-07-08 04:33:04,923 epoch 5 - iter 18/38 - loss 0.03174468 - time (sec): 220.94 - samples/sec: 446.15 - lr: 0.000050 - momentum: 0.000000
2023-07-08 04:33:41,088 epoch 5 - iter 21/38 - loss 0.03254276 - time (sec): 257.11 - samples/sec: 447.07 - lr: 0.000049 - momentum: 0.000000
2023-07-08 04:34:17,510 epoch 5 - iter 24/38 - loss 0.03245685 - time (sec): 293.53 - samples/sec: 447.89 - lr: 0.000048 - momentum: 0.000000
2023-07-08 04:34:52,799 epoch 5 - iter 27/38 - loss 0.03318987 - time (sec): 328.82 - samples/sec: 450.23 - lr: 0.000048 - momentum: 0.000000
2023-07-08 04:35:28,308 epoch 5 - iter 30/38 - loss 0.03350057 - time (sec): 364.33 - samples/sec: 451.67 - lr: 0.000047 - momentum: 0.000000
2023-07-08 04:36:05,724 epoch 5 - iter 33/38 - loss 0.03319701 - time (sec): 401.74 - samples/sec: 449.48 - lr: 0.000046 - momentum: 0.000000
2023-07-08 04:36:41,977 epoch 5 - iter 36/38 - loss 0.03308365 - time (sec): 438.00 - samples/sec: 449.31 - lr: 0.000046 - momentum: 0.000000
2023-07-08 04:36:59,741 ----------------------------------------------------------------------------------------------------
2023-07-08 04:36:59,741 EPOCH 5 done: loss 0.0331 - lr: 0.000046
2023-07-08 04:37:42,765 DEV : loss 0.1625816971063614 - f1-score (micro avg)  0.7489
2023-07-08 04:38:27,628 TEST : loss 0.08668848127126694 - f1-score (micro avg)  0.9293
2023-07-08 04:38:27,686 ----------------------------------------------------------------------------------------------------
2023-07-08 04:39:06,909 epoch 6 - iter 3/38 - loss 0.03275378 - time (sec): 39.22 - samples/sec: 427.17 - lr: 0.000044 - momentum: 0.000000
2023-07-08 04:39:44,527 epoch 6 - iter 6/38 - loss 0.03067536 - time (sec): 76.84 - samples/sec: 429.65 - lr: 0.000044 - momentum: 0.000000
2023-07-08 04:40:23,611 epoch 6 - iter 9/38 - loss 0.03419796 - time (sec): 115.92 - samples/sec: 429.70 - lr: 0.000043 - momentum: 0.000000
2023-07-08 04:41:01,910 epoch 6 - iter 12/38 - loss 0.03396695 - time (sec): 154.22 - samples/sec: 431.35 - lr: 0.000042 - momentum: 0.000000
2023-07-08 04:41:39,780 epoch 6 - iter 15/38 - loss 0.03327768 - time (sec): 192.09 - samples/sec: 428.50 - lr: 0.000042 - momentum: 0.000000
2023-07-08 04:42:17,413 epoch 6 - iter 18/38 - loss 0.03333717 - time (sec): 229.73 - samples/sec: 430.44 - lr: 0.000041 - momentum: 0.000000
2023-07-08 04:42:55,387 epoch 6 - iter 21/38 - loss 0.03368463 - time (sec): 267.70 - samples/sec: 430.32 - lr: 0.000040 - momentum: 0.000000
2023-07-08 04:43:34,056 epoch 6 - iter 24/38 - loss 0.03375597 - time (sec): 306.37 - samples/sec: 431.14 - lr: 0.000040 - momentum: 0.000000
2023-07-08 04:44:09,518 epoch 6 - iter 27/38 - loss 0.03361490 - time (sec): 341.83 - samples/sec: 435.63 - lr: 0.000039 - momentum: 0.000000
2023-07-08 04:44:44,759 epoch 6 - iter 30/38 - loss 0.03334021 - time (sec): 377.07 - samples/sec: 438.43 - lr: 0.000038 - momentum: 0.000000
2023-07-08 04:45:21,478 epoch 6 - iter 33/38 - loss 0.03288356 - time (sec): 413.79 - samples/sec: 438.23 - lr: 0.000037 - momentum: 0.000000
2023-07-08 04:45:56,557 epoch 6 - iter 36/38 - loss 0.03223002 - time (sec): 448.87 - samples/sec: 438.13 - lr: 0.000037 - momentum: 0.000000
2023-07-08 04:46:14,383 ----------------------------------------------------------------------------------------------------
2023-07-08 04:46:14,384 EPOCH 6 done: loss 0.0323 - lr: 0.000037
2023-07-08 04:46:56,817 DEV : loss 0.1644316166639328 - f1-score (micro avg)  0.7447
2023-07-08 04:47:40,575 TEST : loss 0.08652231842279434 - f1-score (micro avg)  0.9337
2023-07-08 04:47:40,643 ----------------------------------------------------------------------------------------------------
2023-07-08 04:48:16,559 epoch 7 - iter 3/38 - loss 0.02682299 - time (sec): 35.91 - samples/sec: 438.10 - lr: 0.000036 - momentum: 0.000000
2023-07-08 04:48:53,145 epoch 7 - iter 6/38 - loss 0.02674681 - time (sec): 72.50 - samples/sec: 446.25 - lr: 0.000035 - momentum: 0.000000
2023-07-08 04:49:29,329 epoch 7 - iter 9/38 - loss 0.02508905 - time (sec): 108.68 - samples/sec: 447.66 - lr: 0.000034 - momentum: 0.000000
2023-07-08 04:50:04,673 epoch 7 - iter 12/38 - loss 0.02475326 - time (sec): 144.03 - samples/sec: 449.10 - lr: 0.000034 - momentum: 0.000000
2023-07-08 04:50:40,504 epoch 7 - iter 15/38 - loss 0.02440583 - time (sec): 179.86 - samples/sec: 450.78 - lr: 0.000033 - momentum: 0.000000
2023-07-08 04:51:17,402 epoch 7 - iter 18/38 - loss 0.02363392 - time (sec): 216.76 - samples/sec: 446.06 - lr: 0.000032 - momentum: 0.000000
2023-07-08 04:51:55,639 epoch 7 - iter 21/38 - loss 0.02322642 - time (sec): 254.99 - samples/sec: 447.19 - lr: 0.000031 - momentum: 0.000000
2023-07-08 04:52:34,185 epoch 7 - iter 24/38 - loss 0.02350723 - time (sec): 293.54 - samples/sec: 444.52 - lr: 0.000031 - momentum: 0.000000
2023-07-08 04:53:12,812 epoch 7 - iter 27/38 - loss 0.02383015 - time (sec): 332.17 - samples/sec: 442.03 - lr: 0.000030 - momentum: 0.000000
2023-07-08 04:53:50,680 epoch 7 - iter 30/38 - loss 0.02422548 - time (sec): 370.04 - samples/sec: 441.46 - lr: 0.000029 - momentum: 0.000000
2023-07-08 04:54:28,459 epoch 7 - iter 33/38 - loss 0.02392886 - time (sec): 407.81 - samples/sec: 442.34 - lr: 0.000029 - momentum: 0.000000
2023-07-08 04:55:05,099 epoch 7 - iter 36/38 - loss 0.02378525 - time (sec): 444.45 - samples/sec: 442.24 - lr: 0.000028 - momentum: 0.000000
2023-07-08 04:55:23,786 ----------------------------------------------------------------------------------------------------
2023-07-08 04:55:23,786 EPOCH 7 done: loss 0.0235 - lr: 0.000028
2023-07-08 04:56:11,594 DEV : loss 0.1717415601015091 - f1-score (micro avg)  0.7384
2023-07-08 04:56:56,161 TEST : loss 0.08703241497278214 - f1-score (micro avg)  0.9328
2023-07-08 04:56:56,216 ----------------------------------------------------------------------------------------------------
2023-07-08 04:57:31,665 epoch 8 - iter 3/38 - loss 0.01969497 - time (sec): 35.45 - samples/sec: 457.49 - lr: 0.000027 - momentum: 0.000000
2023-07-08 04:58:07,354 epoch 8 - iter 6/38 - loss 0.02201591 - time (sec): 71.14 - samples/sec: 457.12 - lr: 0.000026 - momentum: 0.000000
2023-07-08 04:58:43,891 epoch 8 - iter 9/38 - loss 0.02044787 - time (sec): 107.67 - samples/sec: 452.29 - lr: 0.000025 - momentum: 0.000000
2023-07-08 04:59:19,300 epoch 8 - iter 12/38 - loss 0.01974891 - time (sec): 143.08 - samples/sec: 458.00 - lr: 0.000025 - momentum: 0.000000
2023-07-08 04:59:55,394 epoch 8 - iter 15/38 - loss 0.01956781 - time (sec): 179.18 - samples/sec: 462.08 - lr: 0.000024 - momentum: 0.000000
2023-07-08 05:00:30,547 epoch 8 - iter 18/38 - loss 0.01998370 - time (sec): 214.33 - samples/sec: 463.99 - lr: 0.000023 - momentum: 0.000000
2023-07-08 05:01:06,480 epoch 8 - iter 21/38 - loss 0.02055811 - time (sec): 250.26 - samples/sec: 460.89 - lr: 0.000023 - momentum: 0.000000
2023-07-08 05:01:41,087 epoch 8 - iter 24/38 - loss 0.01983948 - time (sec): 284.87 - samples/sec: 462.49 - lr: 0.000022 - momentum: 0.000000
2023-07-08 05:02:16,863 epoch 8 - iter 27/38 - loss 0.01961734 - time (sec): 320.65 - samples/sec: 462.32 - lr: 0.000021 - momentum: 0.000000
2023-07-08 05:02:53,001 epoch 8 - iter 30/38 - loss 0.01981849 - time (sec): 356.78 - samples/sec: 462.06 - lr: 0.000021 - momentum: 0.000000
2023-07-08 05:03:28,088 epoch 8 - iter 33/38 - loss 0.01964935 - time (sec): 391.87 - samples/sec: 460.90 - lr: 0.000020 - momentum: 0.000000
2023-07-08 05:04:06,474 epoch 8 - iter 36/38 - loss 0.01939056 - time (sec): 430.26 - samples/sec: 457.46 - lr: 0.000019 - momentum: 0.000000
2023-07-08 05:04:24,966 ----------------------------------------------------------------------------------------------------
2023-07-08 05:04:24,966 EPOCH 8 done: loss 0.0195 - lr: 0.000019
2023-07-08 05:05:13,975 DEV : loss 0.15129207074642181 - f1-score (micro avg)  0.7575
2023-07-08 05:06:00,871 TEST : loss 0.0849856436252594 - f1-score (micro avg)  0.9363
2023-07-08 05:06:00,928 ----------------------------------------------------------------------------------------------------
2023-07-08 05:06:38,488 epoch 9 - iter 3/38 - loss 0.01815673 - time (sec): 37.56 - samples/sec: 431.96 - lr: 0.000018 - momentum: 0.000000
2023-07-08 05:07:16,965 epoch 9 - iter 6/38 - loss 0.01628907 - time (sec): 76.03 - samples/sec: 428.22 - lr: 0.000017 - momentum: 0.000000
2023-07-08 05:07:54,902 epoch 9 - iter 9/38 - loss 0.01603120 - time (sec): 113.97 - samples/sec: 424.30 - lr: 0.000017 - momentum: 0.000000
2023-07-08 05:08:31,855 epoch 9 - iter 12/38 - loss 0.01548380 - time (sec): 150.92 - samples/sec: 433.43 - lr: 0.000016 - momentum: 0.000000
2023-07-08 05:09:07,586 epoch 9 - iter 15/38 - loss 0.01602800 - time (sec): 186.66 - samples/sec: 438.15 - lr: 0.000015 - momentum: 0.000000
2023-07-08 05:09:44,428 epoch 9 - iter 18/38 - loss 0.01557757 - time (sec): 223.50 - samples/sec: 438.43 - lr: 0.000015 - momentum: 0.000000
2023-07-08 05:10:21,003 epoch 9 - iter 21/38 - loss 0.01584195 - time (sec): 260.07 - samples/sec: 440.93 - lr: 0.000014 - momentum: 0.000000
2023-07-08 05:10:58,267 epoch 9 - iter 24/38 - loss 0.01588284 - time (sec): 297.34 - samples/sec: 441.07 - lr: 0.000013 - momentum: 0.000000
2023-07-08 05:11:34,391 epoch 9 - iter 27/38 - loss 0.01600247 - time (sec): 333.46 - samples/sec: 442.04 - lr: 0.000012 - momentum: 0.000000
2023-07-08 05:12:11,478 epoch 9 - iter 30/38 - loss 0.01577564 - time (sec): 370.55 - samples/sec: 443.29 - lr: 0.000012 - momentum: 0.000000
2023-07-08 05:12:47,195 epoch 9 - iter 33/38 - loss 0.01556868 - time (sec): 406.26 - samples/sec: 445.57 - lr: 0.000011 - momentum: 0.000000
2023-07-08 05:13:23,124 epoch 9 - iter 36/38 - loss 0.01593171 - time (sec): 442.19 - samples/sec: 445.37 - lr: 0.000010 - momentum: 0.000000
2023-07-08 05:13:40,717 ----------------------------------------------------------------------------------------------------
2023-07-08 05:13:40,718 EPOCH 9 done: loss 0.0159 - lr: 0.000010
2023-07-08 05:14:26,809 DEV : loss 0.16772934794425964 - f1-score (micro avg)  0.7463
2023-07-08 05:15:09,275 TEST : loss 0.0880856066942215 - f1-score (micro avg)  0.937
2023-07-08 05:15:09,339 ----------------------------------------------------------------------------------------------------
2023-07-08 05:15:44,635 epoch 10 - iter 3/38 - loss 0.01340680 - time (sec): 35.29 - samples/sec: 457.03 - lr: 0.000009 - momentum: 0.000000
2023-07-08 05:16:22,890 epoch 10 - iter 6/38 - loss 0.01432646 - time (sec): 73.55 - samples/sec: 443.01 - lr: 0.000009 - momentum: 0.000000
2023-07-08 05:17:01,263 epoch 10 - iter 9/38 - loss 0.01308493 - time (sec): 111.92 - samples/sec: 439.22 - lr: 0.000008 - momentum: 0.000000
2023-07-08 05:17:39,497 epoch 10 - iter 12/38 - loss 0.01333332 - time (sec): 150.16 - samples/sec: 437.35 - lr: 0.000007 - momentum: 0.000000
2023-07-08 05:18:18,043 epoch 10 - iter 15/38 - loss 0.01529328 - time (sec): 188.70 - samples/sec: 433.49 - lr: 0.000006 - momentum: 0.000000
2023-07-08 05:18:55,496 epoch 10 - iter 18/38 - loss 0.01515294 - time (sec): 226.16 - samples/sec: 436.79 - lr: 0.000006 - momentum: 0.000000
2023-07-08 05:19:33,707 epoch 10 - iter 21/38 - loss 0.01460295 - time (sec): 264.37 - samples/sec: 433.91 - lr: 0.000005 - momentum: 0.000000
2023-07-08 05:20:11,865 epoch 10 - iter 24/38 - loss 0.01484533 - time (sec): 302.52 - samples/sec: 433.29 - lr: 0.000004 - momentum: 0.000000
2023-07-08 05:20:50,217 epoch 10 - iter 27/38 - loss 0.01478725 - time (sec): 340.88 - samples/sec: 432.74 - lr: 0.000004 - momentum: 0.000000
2023-07-08 05:21:26,122 epoch 10 - iter 30/38 - loss 0.01470274 - time (sec): 376.78 - samples/sec: 435.26 - lr: 0.000003 - momentum: 0.000000
2023-07-08 05:22:02,374 epoch 10 - iter 33/38 - loss 0.01471861 - time (sec): 413.03 - samples/sec: 436.97 - lr: 0.000002 - momentum: 0.000000
2023-07-08 05:22:38,699 epoch 10 - iter 36/38 - loss 0.01462661 - time (sec): 449.36 - samples/sec: 437.89 - lr: 0.000002 - momentum: 0.000000
2023-07-08 05:22:56,296 ----------------------------------------------------------------------------------------------------
2023-07-08 05:22:56,296 EPOCH 10 done: loss 0.0149 - lr: 0.000002
2023-07-08 05:23:41,706 DEV : loss 0.17183025181293488 - f1-score (micro avg)  0.7462
2023-07-08 05:24:22,535 TEST : loss 0.08795011043548584 - f1-score (micro avg)  0.936
2023-07-08 05:24:33,608 ----------------------------------------------------------------------------------------------------
2023-07-08 05:24:33,615 Testing using last state of model ...
2023-07-08 05:25:17,221 
Results:
- F-score (micro) 0.936
- F-score (macro) 0.9211
- Accuracy 0.9044

By class:
              precision    recall  f1-score   support

         ORG     0.9162    0.9344    0.9252      1661
         LOC     0.9523    0.9454    0.9489      1668
         PER     0.9857    0.9814    0.9836      1617
        MISC     0.7966    0.8590    0.8266       702

   micro avg     0.9304    0.9417    0.9360      5648
   macro avg     0.9127    0.9301    0.9211      5648
weighted avg     0.9319    0.9417    0.9366      5648

2023-07-08 05:25:17,221 ----------------------------------------------------------------------------------------------------
