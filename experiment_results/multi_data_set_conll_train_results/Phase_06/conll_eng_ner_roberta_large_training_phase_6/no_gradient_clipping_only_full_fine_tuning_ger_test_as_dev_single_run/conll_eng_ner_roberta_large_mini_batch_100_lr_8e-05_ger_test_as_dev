2023-07-07 21:34:07,984 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,985 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Train:  14987 sentences
2023-07-07 21:34:07,986         (train_with_dev=False, train_with_test=False)
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Training Params:
2023-07-07 21:34:07,986  - learning_rate: "8e-05" 
2023-07-07 21:34:07,986  - mini_batch_size: "100"
2023-07-07 21:34:07,986  - max_epochs: "10"
2023-07-07 21:34:07,986  - shuffle: "True"
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Plugins:
2023-07-07 21:34:07,986  - LinearScheduler | warmup_fraction: '0.1'
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Final evaluation on model after last epoch (final-model.pt)
2023-07-07 21:34:07,986  - metric: "('micro avg', 'f1-score')"
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Computation:
2023-07-07 21:34:07,986  - compute on device: cuda:1
2023-07-07 21:34:07,986  - embedding storage: none
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_8e-05_ger_test_as_dev"
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 Removed gradient clipping
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:07,986 ----------------------------------------------------------------------------------------------------
2023-07-07 21:34:53,027 epoch 1 - iter 15/150 - loss 3.71335271 - time (sec): 45.04 - samples/sec: 447.68 - lr: 0.000007 - momentum: 0.000000
2023-07-07 21:35:38,114 epoch 1 - iter 30/150 - loss 2.66546033 - time (sec): 90.13 - samples/sec: 445.68 - lr: 0.000015 - momentum: 0.000000
2023-07-07 21:36:23,227 epoch 1 - iter 45/150 - loss 2.01304709 - time (sec): 135.24 - samples/sec: 448.83 - lr: 0.000023 - momentum: 0.000000
2023-07-07 21:37:07,474 epoch 1 - iter 60/150 - loss 1.61130040 - time (sec): 179.49 - samples/sec: 460.14 - lr: 0.000031 - momentum: 0.000000
2023-07-07 21:37:51,715 epoch 1 - iter 75/150 - loss 1.38071054 - time (sec): 223.73 - samples/sec: 460.64 - lr: 0.000039 - momentum: 0.000000
2023-07-07 21:38:37,745 epoch 1 - iter 90/150 - loss 1.21240095 - time (sec): 269.76 - samples/sec: 457.20 - lr: 0.000047 - momentum: 0.000000
2023-07-07 21:39:22,700 epoch 1 - iter 105/150 - loss 1.07859963 - time (sec): 314.71 - samples/sec: 456.90 - lr: 0.000055 - momentum: 0.000000
2023-07-07 21:40:08,557 epoch 1 - iter 120/150 - loss 0.97208422 - time (sec): 360.57 - samples/sec: 455.61 - lr: 0.000063 - momentum: 0.000000
2023-07-07 21:40:55,889 epoch 1 - iter 135/150 - loss 0.88405913 - time (sec): 407.90 - samples/sec: 452.10 - lr: 0.000071 - momentum: 0.000000
2023-07-07 21:41:43,532 epoch 1 - iter 150/150 - loss 0.80961211 - time (sec): 455.54 - samples/sec: 449.06 - lr: 0.000079 - momentum: 0.000000
2023-07-07 21:41:43,533 ----------------------------------------------------------------------------------------------------
2023-07-07 21:41:43,533 EPOCH 1 done: loss 0.8096 - lr: 0.000079
2023-07-07 21:42:32,301 DEV : loss 0.18378306925296783 - f1-score (micro avg)  0.67
2023-07-07 21:43:20,990 TEST : loss 0.10659623891115189 - f1-score (micro avg)  0.893
2023-07-07 21:43:21,045 ----------------------------------------------------------------------------------------------------
2023-07-07 21:44:09,064 epoch 2 - iter 15/150 - loss 0.09146221 - time (sec): 48.02 - samples/sec: 438.88 - lr: 0.000079 - momentum: 0.000000
2023-07-07 21:44:57,550 epoch 2 - iter 30/150 - loss 0.08030503 - time (sec): 96.50 - samples/sec: 432.56 - lr: 0.000078 - momentum: 0.000000
2023-07-07 21:45:44,662 epoch 2 - iter 45/150 - loss 0.07867911 - time (sec): 143.62 - samples/sec: 431.70 - lr: 0.000077 - momentum: 0.000000
2023-07-07 21:46:30,395 epoch 2 - iter 60/150 - loss 0.07868151 - time (sec): 189.35 - samples/sec: 434.51 - lr: 0.000077 - momentum: 0.000000
2023-07-07 21:47:16,347 epoch 2 - iter 75/150 - loss 0.07990140 - time (sec): 235.30 - samples/sec: 435.12 - lr: 0.000076 - momentum: 0.000000
2023-07-07 21:48:02,648 epoch 2 - iter 90/150 - loss 0.07822712 - time (sec): 281.60 - samples/sec: 435.31 - lr: 0.000075 - momentum: 0.000000
2023-07-07 21:48:47,824 epoch 2 - iter 105/150 - loss 0.07814043 - time (sec): 326.78 - samples/sec: 438.10 - lr: 0.000074 - momentum: 0.000000
2023-07-07 21:49:32,278 epoch 2 - iter 120/150 - loss 0.07722539 - time (sec): 371.23 - samples/sec: 440.54 - lr: 0.000073 - momentum: 0.000000
2023-07-07 21:50:18,199 epoch 2 - iter 135/150 - loss 0.07572923 - time (sec): 417.15 - samples/sec: 441.37 - lr: 0.000072 - momentum: 0.000000
2023-07-07 21:51:03,515 epoch 2 - iter 150/150 - loss 0.07605927 - time (sec): 462.47 - samples/sec: 442.34 - lr: 0.000071 - momentum: 0.000000
2023-07-07 21:51:03,516 ----------------------------------------------------------------------------------------------------
2023-07-07 21:51:03,516 EPOCH 2 done: loss 0.0761 - lr: 0.000071
2023-07-07 21:51:47,761 DEV : loss 0.19604511559009552 - f1-score (micro avg)  0.6778
2023-07-07 21:52:32,872 TEST : loss 0.09644709527492523 - f1-score (micro avg)  0.9109
2023-07-07 21:52:32,921 ----------------------------------------------------------------------------------------------------
2023-07-07 21:53:19,704 epoch 3 - iter 15/150 - loss 0.06134423 - time (sec): 46.78 - samples/sec: 430.59 - lr: 0.000070 - momentum: 0.000000
2023-07-07 21:54:07,891 epoch 3 - iter 30/150 - loss 0.05392403 - time (sec): 94.97 - samples/sec: 425.40 - lr: 0.000069 - momentum: 0.000000
2023-07-07 21:54:56,700 epoch 3 - iter 45/150 - loss 0.05059926 - time (sec): 143.78 - samples/sec: 425.29 - lr: 0.000069 - momentum: 0.000000
2023-07-07 21:55:44,545 epoch 3 - iter 60/150 - loss 0.04978266 - time (sec): 191.62 - samples/sec: 428.44 - lr: 0.000068 - momentum: 0.000000
2023-07-07 21:56:32,678 epoch 3 - iter 75/150 - loss 0.04948581 - time (sec): 239.76 - samples/sec: 425.95 - lr: 0.000067 - momentum: 0.000000
2023-07-07 21:57:20,161 epoch 3 - iter 90/150 - loss 0.04857633 - time (sec): 287.24 - samples/sec: 425.75 - lr: 0.000066 - momentum: 0.000000
2023-07-07 21:58:07,900 epoch 3 - iter 105/150 - loss 0.04822281 - time (sec): 334.98 - samples/sec: 426.39 - lr: 0.000065 - momentum: 0.000000
2023-07-07 21:58:53,497 epoch 3 - iter 120/150 - loss 0.04804425 - time (sec): 380.58 - samples/sec: 428.65 - lr: 0.000064 - momentum: 0.000000
2023-07-07 21:59:40,299 epoch 3 - iter 135/150 - loss 0.04843472 - time (sec): 427.38 - samples/sec: 432.00 - lr: 0.000063 - momentum: 0.000000
2023-07-07 22:00:26,029 epoch 3 - iter 150/150 - loss 0.04746300 - time (sec): 473.11 - samples/sec: 432.39 - lr: 0.000062 - momentum: 0.000000
2023-07-07 22:00:26,030 ----------------------------------------------------------------------------------------------------
2023-07-07 22:00:26,030 EPOCH 3 done: loss 0.0475 - lr: 0.000062
2023-07-07 22:01:09,262 DEV : loss 0.1904664784669876 - f1-score (micro avg)  0.6984
2023-07-07 22:01:49,915 TEST : loss 0.09149065613746643 - f1-score (micro avg)  0.9247
2023-07-07 22:01:49,975 ----------------------------------------------------------------------------------------------------
2023-07-07 22:02:34,344 epoch 4 - iter 15/150 - loss 0.03504142 - time (sec): 44.37 - samples/sec: 467.87 - lr: 0.000062 - momentum: 0.000000
2023-07-07 22:03:19,948 epoch 4 - iter 30/150 - loss 0.03275323 - time (sec): 89.97 - samples/sec: 458.55 - lr: 0.000061 - momentum: 0.000000
2023-07-07 22:04:06,211 epoch 4 - iter 45/150 - loss 0.03122057 - time (sec): 136.23 - samples/sec: 455.93 - lr: 0.000060 - momentum: 0.000000
2023-07-07 22:04:52,242 epoch 4 - iter 60/150 - loss 0.03002062 - time (sec): 182.27 - samples/sec: 452.84 - lr: 0.000059 - momentum: 0.000000
2023-07-07 22:05:37,083 epoch 4 - iter 75/150 - loss 0.02987363 - time (sec): 227.11 - samples/sec: 455.68 - lr: 0.000058 - momentum: 0.000000
2023-07-07 22:06:23,098 epoch 4 - iter 90/150 - loss 0.02984136 - time (sec): 273.12 - samples/sec: 450.89 - lr: 0.000057 - momentum: 0.000000
2023-07-07 22:07:10,431 epoch 4 - iter 105/150 - loss 0.03141596 - time (sec): 320.45 - samples/sec: 448.22 - lr: 0.000056 - momentum: 0.000000
2023-07-07 22:07:59,039 epoch 4 - iter 120/150 - loss 0.03247698 - time (sec): 369.06 - samples/sec: 444.00 - lr: 0.000055 - momentum: 0.000000
2023-07-07 22:08:46,734 epoch 4 - iter 135/150 - loss 0.03232881 - time (sec): 416.76 - samples/sec: 442.94 - lr: 0.000054 - momentum: 0.000000
2023-07-07 22:09:33,880 epoch 4 - iter 150/150 - loss 0.03184713 - time (sec): 463.90 - samples/sec: 440.97 - lr: 0.000054 - momentum: 0.000000
2023-07-07 22:09:33,880 ----------------------------------------------------------------------------------------------------
2023-07-07 22:09:33,880 EPOCH 4 done: loss 0.0318 - lr: 0.000054
2023-07-07 22:10:24,133 DEV : loss 0.1840432584285736 - f1-score (micro avg)  0.7209
2023-07-07 22:11:10,523 TEST : loss 0.08259983360767365 - f1-score (micro avg)  0.9342
2023-07-07 22:11:10,577 ----------------------------------------------------------------------------------------------------
2023-07-07 22:11:55,900 epoch 5 - iter 15/150 - loss 0.02547754 - time (sec): 45.32 - samples/sec: 446.58 - lr: 0.000053 - momentum: 0.000000
2023-07-07 22:12:40,305 epoch 5 - iter 30/150 - loss 0.02362321 - time (sec): 89.72 - samples/sec: 459.13 - lr: 0.000052 - momentum: 0.000000
2023-07-07 22:13:25,877 epoch 5 - iter 45/150 - loss 0.02367686 - time (sec): 135.30 - samples/sec: 456.26 - lr: 0.000051 - momentum: 0.000000
2023-07-07 22:14:10,236 epoch 5 - iter 60/150 - loss 0.02259371 - time (sec): 179.65 - samples/sec: 457.21 - lr: 0.000050 - momentum: 0.000000
2023-07-07 22:14:53,539 epoch 5 - iter 75/150 - loss 0.02334497 - time (sec): 222.96 - samples/sec: 458.24 - lr: 0.000049 - momentum: 0.000000
2023-07-07 22:15:38,342 epoch 5 - iter 90/150 - loss 0.02280279 - time (sec): 267.76 - samples/sec: 458.04 - lr: 0.000048 - momentum: 0.000000
2023-07-07 22:16:24,863 epoch 5 - iter 105/150 - loss 0.02219016 - time (sec): 314.28 - samples/sec: 455.51 - lr: 0.000047 - momentum: 0.000000
2023-07-07 22:17:10,257 epoch 5 - iter 120/150 - loss 0.02242285 - time (sec): 359.68 - samples/sec: 454.67 - lr: 0.000046 - momentum: 0.000000
2023-07-07 22:17:55,456 epoch 5 - iter 135/150 - loss 0.02193753 - time (sec): 404.87 - samples/sec: 454.09 - lr: 0.000046 - momentum: 0.000000
2023-07-07 22:18:42,510 epoch 5 - iter 150/150 - loss 0.02186938 - time (sec): 451.93 - samples/sec: 452.65 - lr: 0.000045 - momentum: 0.000000
2023-07-07 22:18:42,510 ----------------------------------------------------------------------------------------------------
2023-07-07 22:18:42,510 EPOCH 5 done: loss 0.0219 - lr: 0.000045
2023-07-07 22:19:32,507 DEV : loss 0.1382138878107071 - f1-score (micro avg)  0.7657
2023-07-07 22:20:19,407 TEST : loss 0.07980012148618698 - f1-score (micro avg)  0.9358
2023-07-07 22:20:19,461 ----------------------------------------------------------------------------------------------------
2023-07-07 22:21:07,223 epoch 6 - iter 15/150 - loss 0.01542082 - time (sec): 47.76 - samples/sec: 430.11 - lr: 0.000044 - momentum: 0.000000
2023-07-07 22:21:54,541 epoch 6 - iter 30/150 - loss 0.01487121 - time (sec): 95.08 - samples/sec: 433.99 - lr: 0.000043 - momentum: 0.000000
2023-07-07 22:22:41,413 epoch 6 - iter 45/150 - loss 0.01568636 - time (sec): 141.95 - samples/sec: 433.32 - lr: 0.000042 - momentum: 0.000000
2023-07-07 22:23:29,349 epoch 6 - iter 60/150 - loss 0.01538199 - time (sec): 189.89 - samples/sec: 430.84 - lr: 0.000041 - momentum: 0.000000
2023-07-07 22:24:14,615 epoch 6 - iter 75/150 - loss 0.01553439 - time (sec): 235.15 - samples/sec: 432.07 - lr: 0.000040 - momentum: 0.000000
2023-07-07 22:24:59,795 epoch 6 - iter 90/150 - loss 0.01591642 - time (sec): 280.33 - samples/sec: 438.70 - lr: 0.000039 - momentum: 0.000000
2023-07-07 22:25:44,570 epoch 6 - iter 105/150 - loss 0.01549525 - time (sec): 325.11 - samples/sec: 440.98 - lr: 0.000039 - momentum: 0.000000
2023-07-07 22:26:29,233 epoch 6 - iter 120/150 - loss 0.01564385 - time (sec): 369.77 - samples/sec: 443.42 - lr: 0.000038 - momentum: 0.000000
2023-07-07 22:27:13,382 epoch 6 - iter 135/150 - loss 0.01641556 - time (sec): 413.92 - samples/sec: 445.96 - lr: 0.000037 - momentum: 0.000000
2023-07-07 22:27:57,440 epoch 6 - iter 150/150 - loss 0.01620447 - time (sec): 457.98 - samples/sec: 446.68 - lr: 0.000036 - momentum: 0.000000
2023-07-07 22:27:57,440 ----------------------------------------------------------------------------------------------------
2023-07-07 22:27:57,440 EPOCH 6 done: loss 0.0162 - lr: 0.000036
2023-07-07 22:28:43,305 DEV : loss 0.1460011899471283 - f1-score (micro avg)  0.7712
2023-07-07 22:29:25,396 TEST : loss 0.08732528984546661 - f1-score (micro avg)  0.9393
2023-07-07 22:29:25,446 ----------------------------------------------------------------------------------------------------
2023-07-07 22:30:10,458 epoch 7 - iter 15/150 - loss 0.01092734 - time (sec): 45.01 - samples/sec: 450.87 - lr: 0.000035 - momentum: 0.000000
2023-07-07 22:30:56,048 epoch 7 - iter 30/150 - loss 0.01124097 - time (sec): 90.60 - samples/sec: 448.75 - lr: 0.000034 - momentum: 0.000000
2023-07-07 22:31:43,547 epoch 7 - iter 45/150 - loss 0.01079959 - time (sec): 138.10 - samples/sec: 444.66 - lr: 0.000033 - momentum: 0.000000
2023-07-07 22:32:32,404 epoch 7 - iter 60/150 - loss 0.01035738 - time (sec): 186.96 - samples/sec: 440.42 - lr: 0.000032 - momentum: 0.000000
2023-07-07 22:33:20,603 epoch 7 - iter 75/150 - loss 0.01063772 - time (sec): 235.16 - samples/sec: 437.63 - lr: 0.000031 - momentum: 0.000000
2023-07-07 22:34:09,378 epoch 7 - iter 90/150 - loss 0.01096517 - time (sec): 283.93 - samples/sec: 435.35 - lr: 0.000031 - momentum: 0.000000
2023-07-07 22:34:58,010 epoch 7 - iter 105/150 - loss 0.01144521 - time (sec): 332.56 - samples/sec: 433.21 - lr: 0.000030 - momentum: 0.000000
2023-07-07 22:35:46,606 epoch 7 - iter 120/150 - loss 0.01170685 - time (sec): 381.16 - samples/sec: 430.83 - lr: 0.000029 - momentum: 0.000000
2023-07-07 22:36:34,616 epoch 7 - iter 135/150 - loss 0.01162336 - time (sec): 429.17 - samples/sec: 430.06 - lr: 0.000028 - momentum: 0.000000
2023-07-07 22:37:20,769 epoch 7 - iter 150/150 - loss 0.01187442 - time (sec): 475.32 - samples/sec: 430.38 - lr: 0.000027 - momentum: 0.000000
2023-07-07 22:37:20,770 ----------------------------------------------------------------------------------------------------
2023-07-07 22:37:20,770 EPOCH 7 done: loss 0.0119 - lr: 0.000027
2023-07-07 22:38:04,210 DEV : loss 0.14840571582317352 - f1-score (micro avg)  0.7685
2023-07-07 22:38:48,260 TEST : loss 0.08658651262521744 - f1-score (micro avg)  0.9362
2023-07-07 22:38:48,308 ----------------------------------------------------------------------------------------------------
2023-07-07 22:39:34,520 epoch 8 - iter 15/150 - loss 0.00801865 - time (sec): 46.21 - samples/sec: 435.58 - lr: 0.000026 - momentum: 0.000000
2023-07-07 22:40:19,607 epoch 8 - iter 30/150 - loss 0.00796561 - time (sec): 91.30 - samples/sec: 451.47 - lr: 0.000025 - momentum: 0.000000
2023-07-07 22:41:04,395 epoch 8 - iter 45/150 - loss 0.00899882 - time (sec): 136.09 - samples/sec: 453.22 - lr: 0.000024 - momentum: 0.000000
2023-07-07 22:41:51,356 epoch 8 - iter 60/150 - loss 0.00887560 - time (sec): 183.05 - samples/sec: 450.01 - lr: 0.000024 - momentum: 0.000000
2023-07-07 22:42:37,217 epoch 8 - iter 75/150 - loss 0.00964092 - time (sec): 228.91 - samples/sec: 448.08 - lr: 0.000023 - momentum: 0.000000
2023-07-07 22:43:21,987 epoch 8 - iter 90/150 - loss 0.01003102 - time (sec): 273.68 - samples/sec: 449.86 - lr: 0.000022 - momentum: 0.000000
2023-07-07 22:44:06,320 epoch 8 - iter 105/150 - loss 0.01012677 - time (sec): 318.01 - samples/sec: 447.82 - lr: 0.000021 - momentum: 0.000000
2023-07-07 22:44:53,351 epoch 8 - iter 120/150 - loss 0.01007284 - time (sec): 365.04 - samples/sec: 446.65 - lr: 0.000020 - momentum: 0.000000
2023-07-07 22:45:40,548 epoch 8 - iter 135/150 - loss 0.00999683 - time (sec): 412.24 - samples/sec: 446.46 - lr: 0.000019 - momentum: 0.000000
2023-07-07 22:46:29,630 epoch 8 - iter 150/150 - loss 0.00987283 - time (sec): 461.32 - samples/sec: 443.44 - lr: 0.000018 - momentum: 0.000000
2023-07-07 22:46:29,631 ----------------------------------------------------------------------------------------------------
2023-07-07 22:46:29,631 EPOCH 8 done: loss 0.0099 - lr: 0.000018
2023-07-07 22:47:18,664 DEV : loss 0.1669970601797104 - f1-score (micro avg)  0.7541
2023-07-07 22:48:06,975 TEST : loss 0.0938108041882515 - f1-score (micro avg)  0.9372
2023-07-07 22:48:07,031 ----------------------------------------------------------------------------------------------------
2023-07-07 22:48:55,078 epoch 9 - iter 15/150 - loss 0.01059807 - time (sec): 48.05 - samples/sec: 426.57 - lr: 0.000017 - momentum: 0.000000
2023-07-07 22:49:40,046 epoch 9 - iter 30/150 - loss 0.01002636 - time (sec): 93.01 - samples/sec: 431.31 - lr: 0.000016 - momentum: 0.000000
2023-07-07 22:50:25,822 epoch 9 - iter 45/150 - loss 0.00988919 - time (sec): 138.79 - samples/sec: 438.17 - lr: 0.000016 - momentum: 0.000000
2023-07-07 22:51:11,407 epoch 9 - iter 60/150 - loss 0.00859444 - time (sec): 184.37 - samples/sec: 441.17 - lr: 0.000015 - momentum: 0.000000
2023-07-07 22:51:57,635 epoch 9 - iter 75/150 - loss 0.00791137 - time (sec): 230.60 - samples/sec: 442.05 - lr: 0.000014 - momentum: 0.000000
2023-07-07 22:52:43,736 epoch 9 - iter 90/150 - loss 0.00763959 - time (sec): 276.70 - samples/sec: 441.70 - lr: 0.000013 - momentum: 0.000000
2023-07-07 22:53:29,388 epoch 9 - iter 105/150 - loss 0.00783689 - time (sec): 322.36 - samples/sec: 443.21 - lr: 0.000012 - momentum: 0.000000
2023-07-07 22:54:14,801 epoch 9 - iter 120/150 - loss 0.00739195 - time (sec): 367.77 - samples/sec: 446.84 - lr: 0.000011 - momentum: 0.000000
2023-07-07 22:55:00,384 epoch 9 - iter 135/150 - loss 0.00703649 - time (sec): 413.35 - samples/sec: 445.58 - lr: 0.000010 - momentum: 0.000000
2023-07-07 22:55:46,102 epoch 9 - iter 150/150 - loss 0.00690954 - time (sec): 459.07 - samples/sec: 445.61 - lr: 0.000009 - momentum: 0.000000
2023-07-07 22:55:46,103 ----------------------------------------------------------------------------------------------------
2023-07-07 22:55:46,103 EPOCH 9 done: loss 0.0069 - lr: 0.000009
2023-07-07 22:56:29,902 DEV : loss 0.17953039705753326 - f1-score (micro avg)  0.7572
2023-07-07 22:57:16,019 TEST : loss 0.0991855189204216 - f1-score (micro avg)  0.9359
2023-07-07 22:57:16,074 ----------------------------------------------------------------------------------------------------
2023-07-07 22:58:04,218 epoch 10 - iter 15/150 - loss 0.00701367 - time (sec): 48.14 - samples/sec: 421.71 - lr: 0.000008 - momentum: 0.000000
2023-07-07 22:58:52,806 epoch 10 - iter 30/150 - loss 0.00703832 - time (sec): 96.73 - samples/sec: 429.73 - lr: 0.000008 - momentum: 0.000000
2023-07-07 22:59:41,600 epoch 10 - iter 45/150 - loss 0.00670328 - time (sec): 145.52 - samples/sec: 418.19 - lr: 0.000007 - momentum: 0.000000
2023-07-07 23:00:28,782 epoch 10 - iter 60/150 - loss 0.00679850 - time (sec): 192.71 - samples/sec: 417.48 - lr: 0.000006 - momentum: 0.000000
2023-07-07 23:01:17,437 epoch 10 - iter 75/150 - loss 0.00628306 - time (sec): 241.36 - samples/sec: 416.27 - lr: 0.000005 - momentum: 0.000000
2023-07-07 23:02:06,068 epoch 10 - iter 90/150 - loss 0.00599070 - time (sec): 289.99 - samples/sec: 417.74 - lr: 0.000004 - momentum: 0.000000
2023-07-07 23:02:52,138 epoch 10 - iter 105/150 - loss 0.00645170 - time (sec): 336.06 - samples/sec: 424.52 - lr: 0.000003 - momentum: 0.000000
2023-07-07 23:03:37,669 epoch 10 - iter 120/150 - loss 0.00642868 - time (sec): 381.59 - samples/sec: 428.42 - lr: 0.000002 - momentum: 0.000000
2023-07-07 23:04:24,212 epoch 10 - iter 135/150 - loss 0.00611534 - time (sec): 428.14 - samples/sec: 430.65 - lr: 0.000001 - momentum: 0.000000
2023-07-07 23:05:08,658 epoch 10 - iter 150/150 - loss 0.00619642 - time (sec): 472.58 - samples/sec: 432.87 - lr: 0.000001 - momentum: 0.000000
2023-07-07 23:05:08,659 ----------------------------------------------------------------------------------------------------
2023-07-07 23:05:08,659 EPOCH 10 done: loss 0.0062 - lr: 0.000001
2023-07-07 23:05:51,083 DEV : loss 0.17891232669353485 - f1-score (micro avg)  0.7569
2023-07-07 23:06:35,741 TEST : loss 0.09725954383611679 - f1-score (micro avg)  0.9364
2023-07-07 23:06:48,983 ----------------------------------------------------------------------------------------------------
2023-07-07 23:06:48,987 Testing using last state of model ...
2023-07-07 23:07:31,281 
Results:
- F-score (micro) 0.9364
- F-score (macro) 0.9233
- Accuracy 0.9057

By class:
              precision    recall  f1-score   support

         ORG     0.9090    0.9380    0.9233      1661
         LOC     0.9532    0.9394    0.9463      1668
         PER     0.9839    0.9814    0.9827      1617
        MISC     0.8200    0.8632    0.8411       702

   micro avg     0.9313    0.9416    0.9364      5648
   macro avg     0.9165    0.9305    0.9233      5648
weighted avg     0.9324    0.9416    0.9368      5648

2023-07-07 23:07:31,281 ----------------------------------------------------------------------------------------------------
