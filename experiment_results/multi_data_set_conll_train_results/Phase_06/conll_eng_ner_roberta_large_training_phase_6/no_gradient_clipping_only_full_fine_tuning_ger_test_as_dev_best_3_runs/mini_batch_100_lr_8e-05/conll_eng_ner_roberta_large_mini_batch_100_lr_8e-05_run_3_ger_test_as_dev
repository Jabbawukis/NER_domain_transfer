2023-07-12 07:32:23,567 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,569 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-12 07:32:23,569 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,569 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-12 07:32:23,569 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,569 Train:  14987 sentences
2023-07-12 07:32:23,569         (train_with_dev=False, train_with_test=False)
2023-07-12 07:32:23,569 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,569 Training Params:
2023-07-12 07:32:23,569  - learning_rate: "8e-05" 
2023-07-12 07:32:23,569  - mini_batch_size: "100"
2023-07-12 07:32:23,569  - max_epochs: "10"
2023-07-12 07:32:23,569  - shuffle: "True"
2023-07-12 07:32:23,569 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,569 Plugins:
2023-07-12 07:32:23,569  - LinearScheduler | warmup_fraction: '0.1'
2023-07-12 07:32:23,569 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,569 Final evaluation on model after last epoch (final-model.pt)
2023-07-12 07:32:23,570  - metric: "('micro avg', 'f1-score')"
2023-07-12 07:32:23,570 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,570 Computation:
2023-07-12 07:32:23,570  - compute on device: cuda:3
2023-07-12 07:32:23,570  - embedding storage: none
2023-07-12 07:32:23,570 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,570 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_8e-05_run_3_ger_test_as_dev"
2023-07-12 07:32:23,570 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,570 Removed gradient clipping
2023-07-12 07:32:23,570 ----------------------------------------------------------------------------------------------------
2023-07-12 07:32:23,570 ----------------------------------------------------------------------------------------------------
2023-07-12 07:33:08,098 epoch 1 - iter 15/150 - loss 2.76464071 - time (sec): 44.53 - samples/sec: 456.74 - lr: 0.000007 - momentum: 0.000000
2023-07-12 07:33:52,895 epoch 1 - iter 30/150 - loss 1.97160325 - time (sec): 89.32 - samples/sec: 450.97 - lr: 0.000015 - momentum: 0.000000
2023-07-12 07:34:37,433 epoch 1 - iter 45/150 - loss 1.54150279 - time (sec): 133.86 - samples/sec: 451.15 - lr: 0.000023 - momentum: 0.000000
2023-07-12 07:35:24,298 epoch 1 - iter 60/150 - loss 1.28800232 - time (sec): 180.73 - samples/sec: 450.29 - lr: 0.000031 - momentum: 0.000000
2023-07-12 07:36:08,622 epoch 1 - iter 75/150 - loss 1.11762167 - time (sec): 225.05 - samples/sec: 453.45 - lr: 0.000039 - momentum: 0.000000
2023-07-12 07:36:53,397 epoch 1 - iter 90/150 - loss 0.98554537 - time (sec): 269.83 - samples/sec: 453.57 - lr: 0.000047 - momentum: 0.000000
2023-07-12 07:37:37,750 epoch 1 - iter 105/150 - loss 0.87489126 - time (sec): 314.18 - samples/sec: 454.62 - lr: 0.000055 - momentum: 0.000000
2023-07-12 07:38:22,597 epoch 1 - iter 120/150 - loss 0.78553385 - time (sec): 359.03 - samples/sec: 456.52 - lr: 0.000063 - momentum: 0.000000
2023-07-12 07:39:08,153 epoch 1 - iter 135/150 - loss 0.73771571 - time (sec): 404.58 - samples/sec: 455.29 - lr: 0.000071 - momentum: 0.000000
2023-07-12 07:39:52,167 epoch 1 - iter 150/150 - loss 0.68210140 - time (sec): 448.60 - samples/sec: 456.02 - lr: 0.000079 - momentum: 0.000000
2023-07-12 07:39:52,168 ----------------------------------------------------------------------------------------------------
2023-07-12 07:39:52,168 EPOCH 1 done: loss 0.6821 - lr: 0.000079
2023-07-12 07:40:33,557 DEV : loss 0.19165699183940887 - f1-score (micro avg)  0.6731
2023-07-12 07:41:13,595 TEST : loss 0.1244579553604126 - f1-score (micro avg)  0.8721
2023-07-12 07:41:13,642 ----------------------------------------------------------------------------------------------------
2023-07-12 07:41:58,418 epoch 2 - iter 15/150 - loss 0.14239826 - time (sec): 44.77 - samples/sec: 461.11 - lr: 0.000079 - momentum: 0.000000
2023-07-12 07:42:43,201 epoch 2 - iter 30/150 - loss 0.13585309 - time (sec): 89.56 - samples/sec: 453.39 - lr: 0.000078 - momentum: 0.000000
2023-07-12 07:43:27,392 epoch 2 - iter 45/150 - loss 0.12812293 - time (sec): 133.75 - samples/sec: 452.78 - lr: 0.000077 - momentum: 0.000000
2023-07-12 07:44:12,234 epoch 2 - iter 60/150 - loss 0.11984017 - time (sec): 178.59 - samples/sec: 455.67 - lr: 0.000077 - momentum: 0.000000
2023-07-12 07:44:57,247 epoch 2 - iter 75/150 - loss 0.11384237 - time (sec): 223.60 - samples/sec: 455.49 - lr: 0.000076 - momentum: 0.000000
2023-07-12 07:45:42,964 epoch 2 - iter 90/150 - loss 0.10755076 - time (sec): 269.32 - samples/sec: 453.17 - lr: 0.000075 - momentum: 0.000000
2023-07-12 07:46:28,050 epoch 2 - iter 105/150 - loss 0.10459281 - time (sec): 314.41 - samples/sec: 452.98 - lr: 0.000074 - momentum: 0.000000
2023-07-12 07:47:12,675 epoch 2 - iter 120/150 - loss 0.10083555 - time (sec): 359.03 - samples/sec: 454.17 - lr: 0.000073 - momentum: 0.000000
2023-07-12 07:47:58,150 epoch 2 - iter 135/150 - loss 0.09767969 - time (sec): 404.51 - samples/sec: 455.23 - lr: 0.000072 - momentum: 0.000000
2023-07-12 07:48:42,986 epoch 2 - iter 150/150 - loss 0.09533124 - time (sec): 449.34 - samples/sec: 455.26 - lr: 0.000071 - momentum: 0.000000
2023-07-12 07:48:42,987 ----------------------------------------------------------------------------------------------------
2023-07-12 07:48:42,987 EPOCH 2 done: loss 0.0953 - lr: 0.000071
2023-07-12 07:49:25,541 DEV : loss 0.15214809775352478 - f1-score (micro avg)  0.7238
2023-07-12 07:50:05,386 TEST : loss 0.08915581554174423 - f1-score (micro avg)  0.9117
2023-07-12 07:50:05,433 ----------------------------------------------------------------------------------------------------
2023-07-12 07:50:50,605 epoch 3 - iter 15/150 - loss 0.05322474 - time (sec): 45.17 - samples/sec: 460.00 - lr: 0.000070 - momentum: 0.000000
2023-07-12 07:51:34,115 epoch 3 - iter 30/150 - loss 0.05649561 - time (sec): 88.68 - samples/sec: 469.08 - lr: 0.000069 - momentum: 0.000000
2023-07-12 07:52:16,854 epoch 3 - iter 45/150 - loss 0.05979450 - time (sec): 131.42 - samples/sec: 468.33 - lr: 0.000069 - momentum: 0.000000
2023-07-12 07:52:59,796 epoch 3 - iter 60/150 - loss 0.05743067 - time (sec): 174.36 - samples/sec: 471.40 - lr: 0.000068 - momentum: 0.000000
2023-07-12 07:53:42,383 epoch 3 - iter 75/150 - loss 0.05745160 - time (sec): 216.95 - samples/sec: 467.18 - lr: 0.000067 - momentum: 0.000000
2023-07-12 07:54:25,662 epoch 3 - iter 90/150 - loss 0.05522911 - time (sec): 260.23 - samples/sec: 467.44 - lr: 0.000066 - momentum: 0.000000
2023-07-12 07:55:10,868 epoch 3 - iter 105/150 - loss 0.05462721 - time (sec): 305.43 - samples/sec: 467.17 - lr: 0.000065 - momentum: 0.000000
2023-07-12 07:55:55,596 epoch 3 - iter 120/150 - loss 0.05460224 - time (sec): 350.16 - samples/sec: 467.43 - lr: 0.000064 - momentum: 0.000000
2023-07-12 07:56:40,423 epoch 3 - iter 135/150 - loss 0.05346738 - time (sec): 394.99 - samples/sec: 466.40 - lr: 0.000063 - momentum: 0.000000
2023-07-12 07:57:25,449 epoch 3 - iter 150/150 - loss 0.05291732 - time (sec): 440.01 - samples/sec: 464.91 - lr: 0.000062 - momentum: 0.000000
2023-07-12 07:57:25,449 ----------------------------------------------------------------------------------------------------
2023-07-12 07:57:25,449 EPOCH 3 done: loss 0.0529 - lr: 0.000062
2023-07-12 07:58:08,079 DEV : loss 0.21363234519958496 - f1-score (micro avg)  0.6427
2023-07-12 07:58:47,837 TEST : loss 0.088692806661129 - f1-score (micro avg)  0.9227
2023-07-12 07:58:47,885 ----------------------------------------------------------------------------------------------------
2023-07-12 07:59:32,752 epoch 4 - iter 15/150 - loss 0.03497295 - time (sec): 44.86 - samples/sec: 457.09 - lr: 0.000062 - momentum: 0.000000
2023-07-12 08:00:18,074 epoch 4 - iter 30/150 - loss 0.03720253 - time (sec): 90.19 - samples/sec: 455.02 - lr: 0.000061 - momentum: 0.000000
2023-07-12 08:01:02,988 epoch 4 - iter 45/150 - loss 0.03765595 - time (sec): 135.10 - samples/sec: 454.44 - lr: 0.000060 - momentum: 0.000000
2023-07-12 08:01:47,950 epoch 4 - iter 60/150 - loss 0.03619920 - time (sec): 180.06 - samples/sec: 450.04 - lr: 0.000059 - momentum: 0.000000
2023-07-12 08:02:33,059 epoch 4 - iter 75/150 - loss 0.03571901 - time (sec): 225.17 - samples/sec: 449.53 - lr: 0.000058 - momentum: 0.000000
2023-07-12 08:03:18,906 epoch 4 - iter 90/150 - loss 0.03548871 - time (sec): 271.02 - samples/sec: 452.52 - lr: 0.000057 - momentum: 0.000000
2023-07-12 08:04:03,748 epoch 4 - iter 105/150 - loss 0.03563817 - time (sec): 315.86 - samples/sec: 452.05 - lr: 0.000056 - momentum: 0.000000
2023-07-12 08:04:47,982 epoch 4 - iter 120/150 - loss 0.03564358 - time (sec): 360.10 - samples/sec: 453.29 - lr: 0.000055 - momentum: 0.000000
2023-07-12 08:05:31,916 epoch 4 - iter 135/150 - loss 0.03526125 - time (sec): 404.03 - samples/sec: 455.66 - lr: 0.000054 - momentum: 0.000000
2023-07-12 08:06:16,584 epoch 4 - iter 150/150 - loss 0.03533860 - time (sec): 448.70 - samples/sec: 455.91 - lr: 0.000054 - momentum: 0.000000
2023-07-12 08:06:16,584 ----------------------------------------------------------------------------------------------------
2023-07-12 08:06:16,585 EPOCH 4 done: loss 0.0353 - lr: 0.000054
2023-07-12 08:06:58,327 DEV : loss 0.15329128503799438 - f1-score (micro avg)  0.7177
2023-07-12 08:07:41,485 TEST : loss 0.07570119202136993 - f1-score (micro avg)  0.9305
2023-07-12 08:07:41,541 ----------------------------------------------------------------------------------------------------
2023-07-12 08:08:26,308 epoch 5 - iter 15/150 - loss 0.02176313 - time (sec): 44.77 - samples/sec: 452.54 - lr: 0.000053 - momentum: 0.000000
2023-07-12 08:09:11,440 epoch 5 - iter 30/150 - loss 0.02248694 - time (sec): 89.90 - samples/sec: 449.06 - lr: 0.000052 - momentum: 0.000000
2023-07-12 08:09:56,262 epoch 5 - iter 45/150 - loss 0.02278122 - time (sec): 134.72 - samples/sec: 446.77 - lr: 0.000051 - momentum: 0.000000
2023-07-12 08:10:41,195 epoch 5 - iter 60/150 - loss 0.02208635 - time (sec): 179.65 - samples/sec: 451.34 - lr: 0.000050 - momentum: 0.000000
2023-07-12 08:11:24,068 epoch 5 - iter 75/150 - loss 0.02260290 - time (sec): 222.53 - samples/sec: 457.22 - lr: 0.000049 - momentum: 0.000000
2023-07-12 08:12:08,127 epoch 5 - iter 90/150 - loss 0.02235829 - time (sec): 266.58 - samples/sec: 458.25 - lr: 0.000048 - momentum: 0.000000
2023-07-12 08:12:52,832 epoch 5 - iter 105/150 - loss 0.02211910 - time (sec): 311.29 - samples/sec: 460.41 - lr: 0.000047 - momentum: 0.000000
2023-07-12 08:13:36,297 epoch 5 - iter 120/150 - loss 0.02229479 - time (sec): 354.75 - samples/sec: 459.37 - lr: 0.000046 - momentum: 0.000000
2023-07-12 08:14:19,190 epoch 5 - iter 135/150 - loss 0.04248214 - time (sec): 397.65 - samples/sec: 462.05 - lr: 0.000046 - momentum: 0.000000
2023-07-12 08:15:02,799 epoch 5 - iter 150/150 - loss 0.04516455 - time (sec): 441.26 - samples/sec: 463.60 - lr: 0.000045 - momentum: 0.000000
2023-07-12 08:15:02,800 ----------------------------------------------------------------------------------------------------
2023-07-12 08:15:02,800 EPOCH 5 done: loss 0.0452 - lr: 0.000045
2023-07-12 08:15:46,916 DEV : loss 0.19697022438049316 - f1-score (micro avg)  0.6866
2023-07-12 08:16:31,250 TEST : loss 0.09407500922679901 - f1-score (micro avg)  0.9244
2023-07-12 08:16:31,307 ----------------------------------------------------------------------------------------------------
2023-07-12 08:17:15,130 epoch 6 - iter 15/150 - loss 0.03108032 - time (sec): 43.82 - samples/sec: 476.26 - lr: 0.000044 - momentum: 0.000000
2023-07-12 08:17:59,855 epoch 6 - iter 30/150 - loss 0.03179720 - time (sec): 88.55 - samples/sec: 465.73 - lr: 0.000043 - momentum: 0.000000
2023-07-12 08:18:44,661 epoch 6 - iter 45/150 - loss 0.03238307 - time (sec): 133.35 - samples/sec: 458.93 - lr: 0.000042 - momentum: 0.000000
2023-07-12 08:19:28,949 epoch 6 - iter 60/150 - loss 0.03203243 - time (sec): 177.64 - samples/sec: 459.74 - lr: 0.000041 - momentum: 0.000000
2023-07-12 08:20:13,460 epoch 6 - iter 75/150 - loss 0.03496429 - time (sec): 222.15 - samples/sec: 456.15 - lr: 0.000040 - momentum: 0.000000
2023-07-12 08:20:57,655 epoch 6 - iter 90/150 - loss 0.03713635 - time (sec): 266.35 - samples/sec: 457.47 - lr: 0.000039 - momentum: 0.000000
2023-07-12 08:21:42,626 epoch 6 - iter 105/150 - loss 0.03872183 - time (sec): 311.32 - samples/sec: 457.26 - lr: 0.000039 - momentum: 0.000000
2023-07-12 08:22:26,496 epoch 6 - iter 120/150 - loss 0.03712405 - time (sec): 355.19 - samples/sec: 460.34 - lr: 0.000038 - momentum: 0.000000
2023-07-12 08:23:09,936 epoch 6 - iter 135/150 - loss 0.03585178 - time (sec): 398.63 - samples/sec: 461.54 - lr: 0.000037 - momentum: 0.000000
2023-07-12 08:23:54,491 epoch 6 - iter 150/150 - loss 0.03495604 - time (sec): 443.18 - samples/sec: 461.59 - lr: 0.000036 - momentum: 0.000000
2023-07-12 08:23:54,492 ----------------------------------------------------------------------------------------------------
2023-07-12 08:23:54,492 EPOCH 6 done: loss 0.0350 - lr: 0.000036
2023-07-12 08:24:36,078 DEV : loss 0.22641442716121674 - f1-score (micro avg)  0.681
2023-07-12 08:25:16,917 TEST : loss 0.10099178552627563 - f1-score (micro avg)  0.9261
2023-07-12 08:25:16,987 ----------------------------------------------------------------------------------------------------
2023-07-12 08:26:03,042 epoch 7 - iter 15/150 - loss 0.01853963 - time (sec): 46.05 - samples/sec: 449.63 - lr: 0.000035 - momentum: 0.000000
2023-07-12 08:26:46,830 epoch 7 - iter 30/150 - loss 0.01894272 - time (sec): 89.84 - samples/sec: 456.58 - lr: 0.000034 - momentum: 0.000000
2023-07-12 08:27:28,722 epoch 7 - iter 45/150 - loss 0.01794023 - time (sec): 131.73 - samples/sec: 466.45 - lr: 0.000033 - momentum: 0.000000
2023-07-12 08:28:12,152 epoch 7 - iter 60/150 - loss 0.01682972 - time (sec): 175.16 - samples/sec: 468.83 - lr: 0.000032 - momentum: 0.000000
2023-07-12 08:28:56,421 epoch 7 - iter 75/150 - loss 0.01666453 - time (sec): 219.43 - samples/sec: 469.48 - lr: 0.000031 - momentum: 0.000000
2023-07-12 08:29:39,530 epoch 7 - iter 90/150 - loss 0.01702494 - time (sec): 262.54 - samples/sec: 469.83 - lr: 0.000031 - momentum: 0.000000
2023-07-12 08:30:23,147 epoch 7 - iter 105/150 - loss 0.01717573 - time (sec): 306.16 - samples/sec: 470.89 - lr: 0.000030 - momentum: 0.000000
2023-07-12 08:31:06,367 epoch 7 - iter 120/150 - loss 0.01760578 - time (sec): 349.38 - samples/sec: 470.38 - lr: 0.000029 - momentum: 0.000000
2023-07-12 08:31:50,226 epoch 7 - iter 135/150 - loss 0.01742625 - time (sec): 393.24 - samples/sec: 469.54 - lr: 0.000028 - momentum: 0.000000
2023-07-12 08:32:34,067 epoch 7 - iter 150/150 - loss 0.01710940 - time (sec): 437.08 - samples/sec: 468.03 - lr: 0.000027 - momentum: 0.000000
2023-07-12 08:32:34,068 ----------------------------------------------------------------------------------------------------
2023-07-12 08:32:34,068 EPOCH 7 done: loss 0.0171 - lr: 0.000027
2023-07-12 08:33:18,241 DEV : loss 0.16372528672218323 - f1-score (micro avg)  0.7498
2023-07-12 08:34:00,918 TEST : loss 0.09078097343444824 - f1-score (micro avg)  0.9324
2023-07-12 08:34:00,992 ----------------------------------------------------------------------------------------------------
2023-07-12 08:34:44,762 epoch 8 - iter 15/150 - loss 0.01801633 - time (sec): 43.77 - samples/sec: 473.39 - lr: 0.000026 - momentum: 0.000000
2023-07-12 08:35:28,670 epoch 8 - iter 30/150 - loss 0.01463283 - time (sec): 87.68 - samples/sec: 475.18 - lr: 0.000025 - momentum: 0.000000
2023-07-12 08:36:13,012 epoch 8 - iter 45/150 - loss 0.01292842 - time (sec): 132.02 - samples/sec: 468.74 - lr: 0.000024 - momentum: 0.000000
2023-07-12 08:36:57,468 epoch 8 - iter 60/150 - loss 0.01362727 - time (sec): 176.47 - samples/sec: 467.57 - lr: 0.000024 - momentum: 0.000000
2023-07-12 08:37:41,233 epoch 8 - iter 75/150 - loss 0.01380556 - time (sec): 220.24 - samples/sec: 466.11 - lr: 0.000023 - momentum: 0.000000
2023-07-12 08:38:26,389 epoch 8 - iter 90/150 - loss 0.01336671 - time (sec): 265.39 - samples/sec: 464.15 - lr: 0.000022 - momentum: 0.000000
2023-07-12 08:39:10,125 epoch 8 - iter 105/150 - loss 0.01325955 - time (sec): 309.13 - samples/sec: 464.87 - lr: 0.000021 - momentum: 0.000000
2023-07-12 08:39:54,445 epoch 8 - iter 120/150 - loss 0.01324320 - time (sec): 353.45 - samples/sec: 463.50 - lr: 0.000020 - momentum: 0.000000
2023-07-12 08:40:39,750 epoch 8 - iter 135/150 - loss 0.01287714 - time (sec): 398.76 - samples/sec: 461.53 - lr: 0.000019 - momentum: 0.000000
2023-07-12 08:41:24,590 epoch 8 - iter 150/150 - loss 0.01290246 - time (sec): 443.60 - samples/sec: 461.16 - lr: 0.000018 - momentum: 0.000000
2023-07-12 08:41:24,590 ----------------------------------------------------------------------------------------------------
2023-07-12 08:41:24,590 EPOCH 8 done: loss 0.0129 - lr: 0.000018
2023-07-12 08:42:07,761 DEV : loss 0.1546040177345276 - f1-score (micro avg)  0.7616
2023-07-12 08:42:48,177 TEST : loss 0.09176981449127197 - f1-score (micro avg)  0.9324
2023-07-12 08:42:48,232 ----------------------------------------------------------------------------------------------------
2023-07-12 08:43:32,749 epoch 9 - iter 15/150 - loss 0.01169620 - time (sec): 44.51 - samples/sec: 455.67 - lr: 0.000017 - momentum: 0.000000
2023-07-12 08:44:17,145 epoch 9 - iter 30/150 - loss 0.01201317 - time (sec): 88.91 - samples/sec: 457.32 - lr: 0.000016 - momentum: 0.000000
2023-07-12 08:45:01,637 epoch 9 - iter 45/150 - loss 0.01092962 - time (sec): 133.40 - samples/sec: 457.92 - lr: 0.000016 - momentum: 0.000000
2023-07-12 08:45:47,085 epoch 9 - iter 60/150 - loss 0.01122875 - time (sec): 178.85 - samples/sec: 455.98 - lr: 0.000015 - momentum: 0.000000
2023-07-12 08:46:31,854 epoch 9 - iter 75/150 - loss 0.01054328 - time (sec): 223.62 - samples/sec: 452.24 - lr: 0.000014 - momentum: 0.000000
2023-07-12 08:47:16,986 epoch 9 - iter 90/150 - loss 0.01042483 - time (sec): 268.75 - samples/sec: 450.96 - lr: 0.000013 - momentum: 0.000000
2023-07-12 08:48:02,464 epoch 9 - iter 105/150 - loss 0.01278378 - time (sec): 314.23 - samples/sec: 452.61 - lr: 0.000012 - momentum: 0.000000
2023-07-12 08:48:48,051 epoch 9 - iter 120/150 - loss 0.01552452 - time (sec): 359.82 - samples/sec: 453.43 - lr: 0.000011 - momentum: 0.000000
2023-07-12 08:49:33,072 epoch 9 - iter 135/150 - loss 0.01606575 - time (sec): 404.84 - samples/sec: 455.84 - lr: 0.000010 - momentum: 0.000000
2023-07-12 08:50:17,664 epoch 9 - iter 150/150 - loss 0.01635940 - time (sec): 449.43 - samples/sec: 455.17 - lr: 0.000009 - momentum: 0.000000
2023-07-12 08:50:17,664 ----------------------------------------------------------------------------------------------------
2023-07-12 08:50:17,664 EPOCH 9 done: loss 0.0164 - lr: 0.000009
2023-07-12 08:51:00,304 DEV : loss 0.21544204652309418 - f1-score (micro avg)  0.7034
2023-07-12 08:51:40,241 TEST : loss 0.09839658439159393 - f1-score (micro avg)  0.9288
2023-07-12 08:51:40,288 ----------------------------------------------------------------------------------------------------
2023-07-12 08:52:24,646 epoch 10 - iter 15/150 - loss 0.01939827 - time (sec): 44.36 - samples/sec: 459.58 - lr: 0.000008 - momentum: 0.000000
2023-07-12 08:53:09,064 epoch 10 - iter 30/150 - loss 0.01775624 - time (sec): 88.77 - samples/sec: 463.38 - lr: 0.000008 - momentum: 0.000000
2023-07-12 08:53:53,821 epoch 10 - iter 45/150 - loss 0.01684805 - time (sec): 133.53 - samples/sec: 462.39 - lr: 0.000007 - momentum: 0.000000
2023-07-12 08:54:38,262 epoch 10 - iter 60/150 - loss 0.01585931 - time (sec): 177.97 - samples/sec: 460.03 - lr: 0.000006 - momentum: 0.000000
2023-07-12 08:55:23,251 epoch 10 - iter 75/150 - loss 0.01569355 - time (sec): 222.96 - samples/sec: 458.91 - lr: 0.000005 - momentum: 0.000000
2023-07-12 08:56:09,149 epoch 10 - iter 90/150 - loss 0.01512094 - time (sec): 268.86 - samples/sec: 454.47 - lr: 0.000004 - momentum: 0.000000
2023-07-12 08:56:54,805 epoch 10 - iter 105/150 - loss 0.01471442 - time (sec): 314.51 - samples/sec: 451.32 - lr: 0.000003 - momentum: 0.000000
2023-07-12 08:57:40,407 epoch 10 - iter 120/150 - loss 0.01434207 - time (sec): 360.12 - samples/sec: 451.29 - lr: 0.000002 - momentum: 0.000000
2023-07-12 08:58:25,797 epoch 10 - iter 135/150 - loss 0.01403905 - time (sec): 405.51 - samples/sec: 453.07 - lr: 0.000001 - momentum: 0.000000
2023-07-12 08:59:11,442 epoch 10 - iter 150/150 - loss 0.01359303 - time (sec): 451.15 - samples/sec: 453.43 - lr: 0.000001 - momentum: 0.000000
2023-07-12 08:59:11,443 ----------------------------------------------------------------------------------------------------
2023-07-12 08:59:11,443 EPOCH 10 done: loss 0.0136 - lr: 0.000001
2023-07-12 08:59:58,806 DEV : loss 0.18158255517482758 - f1-score (micro avg)  0.7422
2023-07-12 09:00:42,475 TEST : loss 0.09542097896337509 - f1-score (micro avg)  0.9328
2023-07-12 09:00:57,560 ----------------------------------------------------------------------------------------------------
2023-07-12 09:00:57,564 Testing using last state of model ...
2023-07-12 09:01:40,963 
Results:
- F-score (micro) 0.9328
- F-score (macro) 0.9184
- Accuracy 0.8998

By class:
              precision    recall  f1-score   support

         ORG     0.9070    0.9398    0.9231      1661
         LOC     0.9484    0.9371    0.9427      1668
         PER     0.9802    0.9796    0.9799      1617
        MISC     0.8005    0.8575    0.8281       702

   micro avg     0.9256    0.9402    0.9328      5648
   macro avg     0.9090    0.9285    0.9184      5648
weighted avg     0.9270    0.9402    0.9333      5648

2023-07-12 09:01:40,963 ----------------------------------------------------------------------------------------------------
