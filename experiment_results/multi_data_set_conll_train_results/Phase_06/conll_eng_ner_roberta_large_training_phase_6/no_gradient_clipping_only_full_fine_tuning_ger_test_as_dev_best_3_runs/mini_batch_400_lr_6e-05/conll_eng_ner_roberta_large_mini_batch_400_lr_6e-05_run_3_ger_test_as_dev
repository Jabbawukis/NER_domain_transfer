2023-07-12 03:06:38,262 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,263 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-12 03:06:38,263 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,263 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-12 03:06:38,263 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,263 Train:  14987 sentences
2023-07-12 03:06:38,263         (train_with_dev=False, train_with_test=False)
2023-07-12 03:06:38,263 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,263 Training Params:
2023-07-12 03:06:38,263  - learning_rate: "6e-05" 
2023-07-12 03:06:38,263  - mini_batch_size: "400"
2023-07-12 03:06:38,263  - max_epochs: "10"
2023-07-12 03:06:38,263  - shuffle: "True"
2023-07-12 03:06:38,263 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,263 Plugins:
2023-07-12 03:06:38,263  - LinearScheduler | warmup_fraction: '0.1'
2023-07-12 03:06:38,263 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,263 Final evaluation on model after last epoch (final-model.pt)
2023-07-12 03:06:38,263  - metric: "('micro avg', 'f1-score')"
2023-07-12 03:06:38,263 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,264 Computation:
2023-07-12 03:06:38,264  - compute on device: cuda:3
2023-07-12 03:06:38,264  - embedding storage: none
2023-07-12 03:06:38,264 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,264 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_400_lr_6e-05_run_3_ger_test_as_dev"
2023-07-12 03:06:38,264 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,264 Removed gradient clipping
2023-07-12 03:06:38,264 ----------------------------------------------------------------------------------------------------
2023-07-12 03:06:38,264 ----------------------------------------------------------------------------------------------------
2023-07-12 03:07:12,472 epoch 1 - iter 3/38 - loss 4.06056533 - time (sec): 34.21 - samples/sec: 476.92 - lr: 0.000003 - momentum: 0.000000
2023-07-12 03:07:47,757 epoch 1 - iter 6/38 - loss 3.98125147 - time (sec): 69.49 - samples/sec: 471.62 - lr: 0.000008 - momentum: 0.000000
2023-07-12 03:08:24,925 epoch 1 - iter 9/38 - loss 3.81058783 - time (sec): 106.66 - samples/sec: 463.33 - lr: 0.000013 - momentum: 0.000000
2023-07-12 03:09:00,599 epoch 1 - iter 12/38 - loss 3.53136583 - time (sec): 142.33 - samples/sec: 465.90 - lr: 0.000017 - momentum: 0.000000
2023-07-12 03:09:36,225 epoch 1 - iter 15/38 - loss 3.10343377 - time (sec): 177.96 - samples/sec: 463.61 - lr: 0.000022 - momentum: 0.000000
2023-07-12 03:10:11,703 epoch 1 - iter 18/38 - loss 2.77335822 - time (sec): 213.44 - samples/sec: 464.20 - lr: 0.000027 - momentum: 0.000000
2023-07-12 03:10:47,401 epoch 1 - iter 21/38 - loss 2.51319631 - time (sec): 249.14 - samples/sec: 461.22 - lr: 0.000032 - momentum: 0.000000
2023-07-12 03:11:22,841 epoch 1 - iter 24/38 - loss 2.31118187 - time (sec): 284.58 - samples/sec: 458.99 - lr: 0.000036 - momentum: 0.000000
2023-07-12 03:11:58,129 epoch 1 - iter 27/38 - loss 2.12955372 - time (sec): 319.86 - samples/sec: 459.20 - lr: 0.000041 - momentum: 0.000000
2023-07-12 03:12:33,513 epoch 1 - iter 30/38 - loss 1.97528226 - time (sec): 355.25 - samples/sec: 460.82 - lr: 0.000046 - momentum: 0.000000
2023-07-12 03:13:08,444 epoch 1 - iter 33/38 - loss 1.85389983 - time (sec): 390.18 - samples/sec: 459.72 - lr: 0.000051 - momentum: 0.000000
2023-07-12 03:13:43,170 epoch 1 - iter 36/38 - loss 1.74236685 - time (sec): 424.91 - samples/sec: 461.87 - lr: 0.000055 - momentum: 0.000000
2023-07-12 03:14:00,277 ----------------------------------------------------------------------------------------------------
2023-07-12 03:14:00,277 EPOCH 1 done: loss 1.6927 - lr: 0.000055
2023-07-12 03:14:41,763 DEV : loss 0.3286901116371155 - f1-score (micro avg)  0.3561
2023-07-12 03:15:21,758 TEST : loss 0.5052391886711121 - f1-score (micro avg)  0.3975
2023-07-12 03:15:21,805 ----------------------------------------------------------------------------------------------------
2023-07-12 03:15:55,831 epoch 2 - iter 3/38 - loss 0.52946826 - time (sec): 34.02 - samples/sec: 469.89 - lr: 0.000060 - momentum: 0.000000
2023-07-12 03:16:29,903 epoch 2 - iter 6/38 - loss 0.52618276 - time (sec): 68.10 - samples/sec: 480.93 - lr: 0.000059 - momentum: 0.000000
2023-07-12 03:17:03,590 epoch 2 - iter 9/38 - loss 0.51891532 - time (sec): 101.78 - samples/sec: 485.48 - lr: 0.000059 - momentum: 0.000000
2023-07-12 03:17:36,922 epoch 2 - iter 12/38 - loss 0.51224139 - time (sec): 135.12 - samples/sec: 488.48 - lr: 0.000058 - momentum: 0.000000
2023-07-12 03:18:10,809 epoch 2 - iter 15/38 - loss 0.50677416 - time (sec): 169.00 - samples/sec: 492.48 - lr: 0.000058 - momentum: 0.000000
2023-07-12 03:18:43,657 epoch 2 - iter 18/38 - loss 0.50115646 - time (sec): 201.85 - samples/sec: 492.41 - lr: 0.000057 - momentum: 0.000000
2023-07-12 03:19:17,113 epoch 2 - iter 21/38 - loss 0.48495904 - time (sec): 235.31 - samples/sec: 493.11 - lr: 0.000057 - momentum: 0.000000
2023-07-12 03:19:50,770 epoch 2 - iter 24/38 - loss 0.47272688 - time (sec): 268.96 - samples/sec: 489.86 - lr: 0.000056 - momentum: 0.000000
2023-07-12 03:20:24,644 epoch 2 - iter 27/38 - loss 0.45586753 - time (sec): 302.84 - samples/sec: 489.69 - lr: 0.000055 - momentum: 0.000000
2023-07-12 03:20:57,918 epoch 2 - iter 30/38 - loss 0.43947874 - time (sec): 336.11 - samples/sec: 489.71 - lr: 0.000055 - momentum: 0.000000
2023-07-12 03:21:31,950 epoch 2 - iter 33/38 - loss 0.42667113 - time (sec): 370.14 - samples/sec: 487.05 - lr: 0.000054 - momentum: 0.000000
2023-07-12 03:22:04,741 epoch 2 - iter 36/38 - loss 0.41314118 - time (sec): 402.94 - samples/sec: 487.95 - lr: 0.000054 - momentum: 0.000000
2023-07-12 03:22:21,387 ----------------------------------------------------------------------------------------------------
2023-07-12 03:22:21,388 EPOCH 2 done: loss 0.4068 - lr: 0.000054
2023-07-12 03:23:04,152 DEV : loss 0.24764804542064667 - f1-score (micro avg)  0.5699
2023-07-12 03:23:44,038 TEST : loss 0.1960638463497162 - f1-score (micro avg)  0.8089
2023-07-12 03:23:44,085 ----------------------------------------------------------------------------------------------------
2023-07-12 03:24:16,738 epoch 3 - iter 3/38 - loss 0.25765953 - time (sec): 32.65 - samples/sec: 501.59 - lr: 0.000053 - momentum: 0.000000
2023-07-12 03:24:50,492 epoch 3 - iter 6/38 - loss 0.23605084 - time (sec): 66.41 - samples/sec: 493.21 - lr: 0.000053 - momentum: 0.000000
2023-07-12 03:25:23,662 epoch 3 - iter 9/38 - loss 0.21848699 - time (sec): 99.58 - samples/sec: 488.56 - lr: 0.000052 - momentum: 0.000000
2023-07-12 03:25:57,057 epoch 3 - iter 12/38 - loss 0.20989136 - time (sec): 132.97 - samples/sec: 486.18 - lr: 0.000052 - momentum: 0.000000
2023-07-12 03:26:30,547 epoch 3 - iter 15/38 - loss 0.20088007 - time (sec): 166.46 - samples/sec: 489.95 - lr: 0.000051 - momentum: 0.000000
2023-07-12 03:27:03,713 epoch 3 - iter 18/38 - loss 0.19538172 - time (sec): 199.63 - samples/sec: 493.09 - lr: 0.000050 - momentum: 0.000000
2023-07-12 03:27:37,151 epoch 3 - iter 21/38 - loss 0.18788434 - time (sec): 233.07 - samples/sec: 494.34 - lr: 0.000050 - momentum: 0.000000
2023-07-12 03:28:11,877 epoch 3 - iter 24/38 - loss 0.18249964 - time (sec): 267.79 - samples/sec: 491.32 - lr: 0.000049 - momentum: 0.000000
2023-07-12 03:28:46,921 epoch 3 - iter 27/38 - loss 0.17565995 - time (sec): 302.84 - samples/sec: 490.65 - lr: 0.000049 - momentum: 0.000000
2023-07-12 03:29:22,423 epoch 3 - iter 30/38 - loss 0.17028921 - time (sec): 338.34 - samples/sec: 487.29 - lr: 0.000048 - momentum: 0.000000
2023-07-12 03:29:58,045 epoch 3 - iter 33/38 - loss 0.16445696 - time (sec): 373.96 - samples/sec: 483.98 - lr: 0.000048 - momentum: 0.000000
2023-07-12 03:30:33,078 epoch 3 - iter 36/38 - loss 0.16026410 - time (sec): 408.99 - samples/sec: 480.76 - lr: 0.000047 - momentum: 0.000000
2023-07-12 03:30:51,084 ----------------------------------------------------------------------------------------------------
2023-07-12 03:30:51,084 EPOCH 3 done: loss 0.1580 - lr: 0.000047
2023-07-12 03:31:32,495 DEV : loss 0.18557879328727722 - f1-score (micro avg)  0.717
2023-07-12 03:32:13,699 TEST : loss 0.09804993122816086 - f1-score (micro avg)  0.9054
2023-07-12 03:32:13,745 ----------------------------------------------------------------------------------------------------
2023-07-12 03:32:48,839 epoch 4 - iter 3/38 - loss 0.09548092 - time (sec): 35.09 - samples/sec: 465.75 - lr: 0.000046 - momentum: 0.000000
2023-07-12 03:33:24,142 epoch 4 - iter 6/38 - loss 0.08987321 - time (sec): 70.40 - samples/sec: 470.29 - lr: 0.000046 - momentum: 0.000000
2023-07-12 03:33:59,951 epoch 4 - iter 9/38 - loss 0.08276156 - time (sec): 106.20 - samples/sec: 466.03 - lr: 0.000045 - momentum: 0.000000
2023-07-12 03:34:35,928 epoch 4 - iter 12/38 - loss 0.08041029 - time (sec): 142.18 - samples/sec: 463.32 - lr: 0.000045 - momentum: 0.000000
2023-07-12 03:35:10,905 epoch 4 - iter 15/38 - loss 0.07838313 - time (sec): 177.16 - samples/sec: 461.43 - lr: 0.000044 - momentum: 0.000000
2023-07-12 03:35:45,732 epoch 4 - iter 18/38 - loss 0.07826100 - time (sec): 211.99 - samples/sec: 460.52 - lr: 0.000044 - momentum: 0.000000
2023-07-12 03:36:21,178 epoch 4 - iter 21/38 - loss 0.07916550 - time (sec): 247.43 - samples/sec: 461.75 - lr: 0.000043 - momentum: 0.000000
2023-07-12 03:36:56,599 epoch 4 - iter 24/38 - loss 0.07870088 - time (sec): 282.85 - samples/sec: 463.04 - lr: 0.000043 - momentum: 0.000000
2023-07-12 03:37:31,703 epoch 4 - iter 27/38 - loss 0.07726237 - time (sec): 317.96 - samples/sec: 461.89 - lr: 0.000042 - momentum: 0.000000
2023-07-12 03:38:06,667 epoch 4 - iter 30/38 - loss 0.07635574 - time (sec): 352.92 - samples/sec: 462.95 - lr: 0.000042 - momentum: 0.000000
2023-07-12 03:38:41,787 epoch 4 - iter 33/38 - loss 0.07607073 - time (sec): 388.04 - samples/sec: 463.67 - lr: 0.000041 - momentum: 0.000000
2023-07-12 03:39:16,880 epoch 4 - iter 36/38 - loss 0.07437507 - time (sec): 423.13 - samples/sec: 463.72 - lr: 0.000041 - momentum: 0.000000
2023-07-12 03:39:34,431 ----------------------------------------------------------------------------------------------------
2023-07-12 03:39:34,432 EPOCH 4 done: loss 0.0744 - lr: 0.000041
2023-07-12 03:40:15,627 DEV : loss 0.1933886557817459 - f1-score (micro avg)  0.7147
2023-07-12 03:40:56,793 TEST : loss 0.10073322802782059 - f1-score (micro avg)  0.9139
2023-07-12 03:40:56,842 ----------------------------------------------------------------------------------------------------
2023-07-12 03:41:31,915 epoch 5 - iter 3/38 - loss 0.06370914 - time (sec): 35.07 - samples/sec: 439.12 - lr: 0.000040 - momentum: 0.000000
2023-07-12 03:42:07,233 epoch 5 - iter 6/38 - loss 0.05829007 - time (sec): 70.39 - samples/sec: 452.88 - lr: 0.000039 - momentum: 0.000000
2023-07-12 03:42:42,240 epoch 5 - iter 9/38 - loss 0.05945800 - time (sec): 105.40 - samples/sec: 455.82 - lr: 0.000039 - momentum: 0.000000
2023-07-12 03:43:17,782 epoch 5 - iter 12/38 - loss 0.05882217 - time (sec): 140.94 - samples/sec: 464.36 - lr: 0.000038 - momentum: 0.000000
2023-07-12 03:43:53,701 epoch 5 - iter 15/38 - loss 0.05979355 - time (sec): 176.86 - samples/sec: 460.05 - lr: 0.000038 - momentum: 0.000000
2023-07-12 03:44:29,227 epoch 5 - iter 18/38 - loss 0.05822633 - time (sec): 212.38 - samples/sec: 458.73 - lr: 0.000037 - momentum: 0.000000
2023-07-12 03:45:03,903 epoch 5 - iter 21/38 - loss 0.05626607 - time (sec): 247.06 - samples/sec: 462.21 - lr: 0.000037 - momentum: 0.000000
2023-07-12 03:45:39,118 epoch 5 - iter 24/38 - loss 0.05660982 - time (sec): 282.27 - samples/sec: 462.51 - lr: 0.000036 - momentum: 0.000000
2023-07-12 03:46:14,968 epoch 5 - iter 27/38 - loss 0.05539977 - time (sec): 318.13 - samples/sec: 462.32 - lr: 0.000036 - momentum: 0.000000
2023-07-12 03:46:49,856 epoch 5 - iter 30/38 - loss 0.05513110 - time (sec): 353.01 - samples/sec: 461.98 - lr: 0.000035 - momentum: 0.000000
2023-07-12 03:47:25,050 epoch 5 - iter 33/38 - loss 0.05475982 - time (sec): 388.21 - samples/sec: 463.60 - lr: 0.000035 - momentum: 0.000000
2023-07-12 03:48:00,523 epoch 5 - iter 36/38 - loss 0.05420816 - time (sec): 423.68 - samples/sec: 463.92 - lr: 0.000034 - momentum: 0.000000
2023-07-12 03:48:18,379 ----------------------------------------------------------------------------------------------------
2023-07-12 03:48:18,379 EPOCH 5 done: loss 0.0540 - lr: 0.000034
2023-07-12 03:48:59,544 DEV : loss 0.17734265327453613 - f1-score (micro avg)  0.7301
2023-07-12 03:49:39,174 TEST : loss 0.09466088563203812 - f1-score (micro avg)  0.9185
2023-07-12 03:49:39,221 ----------------------------------------------------------------------------------------------------
2023-07-12 03:50:15,896 epoch 6 - iter 3/38 - loss 0.03599213 - time (sec): 36.67 - samples/sec: 453.30 - lr: 0.000033 - momentum: 0.000000
2023-07-12 03:50:51,347 epoch 6 - iter 6/38 - loss 0.03919293 - time (sec): 72.12 - samples/sec: 450.03 - lr: 0.000033 - momentum: 0.000000
2023-07-12 03:51:28,205 epoch 6 - iter 9/38 - loss 0.04112361 - time (sec): 108.98 - samples/sec: 452.43 - lr: 0.000032 - momentum: 0.000000
2023-07-12 03:52:03,789 epoch 6 - iter 12/38 - loss 0.04187149 - time (sec): 144.57 - samples/sec: 450.43 - lr: 0.000032 - momentum: 0.000000
2023-07-12 03:52:38,724 epoch 6 - iter 15/38 - loss 0.04229081 - time (sec): 179.50 - samples/sec: 453.27 - lr: 0.000031 - momentum: 0.000000
2023-07-12 03:53:13,885 epoch 6 - iter 18/38 - loss 0.04304250 - time (sec): 214.66 - samples/sec: 459.18 - lr: 0.000031 - momentum: 0.000000
2023-07-12 03:53:50,023 epoch 6 - iter 21/38 - loss 0.04315535 - time (sec): 250.80 - samples/sec: 456.33 - lr: 0.000030 - momentum: 0.000000
2023-07-12 03:54:24,766 epoch 6 - iter 24/38 - loss 0.04315302 - time (sec): 285.54 - samples/sec: 457.52 - lr: 0.000030 - momentum: 0.000000
2023-07-12 03:54:58,937 epoch 6 - iter 27/38 - loss 0.04335476 - time (sec): 319.72 - samples/sec: 461.26 - lr: 0.000029 - momentum: 0.000000
2023-07-12 03:55:32,628 epoch 6 - iter 30/38 - loss 0.04347346 - time (sec): 353.41 - samples/sec: 463.30 - lr: 0.000029 - momentum: 0.000000
2023-07-12 03:56:06,674 epoch 6 - iter 33/38 - loss 0.04309795 - time (sec): 387.45 - samples/sec: 463.91 - lr: 0.000028 - momentum: 0.000000
2023-07-12 03:56:40,194 epoch 6 - iter 36/38 - loss 0.04271847 - time (sec): 420.97 - samples/sec: 466.62 - lr: 0.000028 - momentum: 0.000000
2023-07-12 03:56:56,556 ----------------------------------------------------------------------------------------------------
2023-07-12 03:56:56,557 EPOCH 6 done: loss 0.0429 - lr: 0.000028
2023-07-12 03:57:37,685 DEV : loss 0.1981518715620041 - f1-score (micro avg)  0.7192
2023-07-12 03:58:17,524 TEST : loss 0.09709422290325165 - f1-score (micro avg)  0.9219
2023-07-12 03:58:17,571 ----------------------------------------------------------------------------------------------------
2023-07-12 03:58:52,650 epoch 7 - iter 3/38 - loss 0.03556515 - time (sec): 35.08 - samples/sec: 460.13 - lr: 0.000027 - momentum: 0.000000
2023-07-12 03:59:28,594 epoch 7 - iter 6/38 - loss 0.03223840 - time (sec): 71.02 - samples/sec: 451.99 - lr: 0.000026 - momentum: 0.000000
2023-07-12 04:00:04,481 epoch 7 - iter 9/38 - loss 0.03486316 - time (sec): 106.91 - samples/sec: 454.05 - lr: 0.000026 - momentum: 0.000000
2023-07-12 04:00:39,959 epoch 7 - iter 12/38 - loss 0.03641099 - time (sec): 142.39 - samples/sec: 456.79 - lr: 0.000025 - momentum: 0.000000
2023-07-12 04:01:14,877 epoch 7 - iter 15/38 - loss 0.03725887 - time (sec): 177.30 - samples/sec: 457.12 - lr: 0.000025 - momentum: 0.000000
2023-07-12 04:01:50,508 epoch 7 - iter 18/38 - loss 0.03793983 - time (sec): 212.93 - samples/sec: 457.39 - lr: 0.000024 - momentum: 0.000000
2023-07-12 04:02:26,226 epoch 7 - iter 21/38 - loss 0.03811431 - time (sec): 248.65 - samples/sec: 457.90 - lr: 0.000024 - momentum: 0.000000
2023-07-12 04:03:01,261 epoch 7 - iter 24/38 - loss 0.03715125 - time (sec): 283.69 - samples/sec: 462.08 - lr: 0.000023 - momentum: 0.000000
2023-07-12 04:03:36,878 epoch 7 - iter 27/38 - loss 0.03703518 - time (sec): 319.31 - samples/sec: 462.51 - lr: 0.000023 - momentum: 0.000000
2023-07-12 04:04:11,606 epoch 7 - iter 30/38 - loss 0.03684457 - time (sec): 354.03 - samples/sec: 463.03 - lr: 0.000022 - momentum: 0.000000
2023-07-12 04:04:46,771 epoch 7 - iter 33/38 - loss 0.03676488 - time (sec): 389.20 - samples/sec: 463.28 - lr: 0.000022 - momentum: 0.000000
2023-07-12 04:05:22,049 epoch 7 - iter 36/38 - loss 0.03630786 - time (sec): 424.48 - samples/sec: 463.20 - lr: 0.000021 - momentum: 0.000000
2023-07-12 04:05:39,132 ----------------------------------------------------------------------------------------------------
2023-07-12 04:05:39,132 EPOCH 7 done: loss 0.0363 - lr: 0.000021
2023-07-12 04:06:21,550 DEV : loss 0.18306398391723633 - f1-score (micro avg)  0.7353
2023-07-12 04:07:01,115 TEST : loss 0.09398281574249268 - f1-score (micro avg)  0.9255
2023-07-12 04:07:01,161 ----------------------------------------------------------------------------------------------------
2023-07-12 04:07:36,287 epoch 8 - iter 3/38 - loss 0.02882237 - time (sec): 35.12 - samples/sec: 466.00 - lr: 0.000020 - momentum: 0.000000
2023-07-12 04:08:11,715 epoch 8 - iter 6/38 - loss 0.03100508 - time (sec): 70.55 - samples/sec: 471.59 - lr: 0.000020 - momentum: 0.000000
2023-07-12 04:08:46,997 epoch 8 - iter 9/38 - loss 0.03206835 - time (sec): 105.83 - samples/sec: 464.64 - lr: 0.000019 - momentum: 0.000000
2023-07-12 04:09:21,679 epoch 8 - iter 12/38 - loss 0.03165037 - time (sec): 140.52 - samples/sec: 466.33 - lr: 0.000019 - momentum: 0.000000
2023-07-12 04:09:57,404 epoch 8 - iter 15/38 - loss 0.03150739 - time (sec): 176.24 - samples/sec: 466.51 - lr: 0.000018 - momentum: 0.000000
2023-07-12 04:10:32,906 epoch 8 - iter 18/38 - loss 0.03104247 - time (sec): 211.74 - samples/sec: 465.18 - lr: 0.000018 - momentum: 0.000000
2023-07-12 04:11:08,125 epoch 8 - iter 21/38 - loss 0.03094855 - time (sec): 246.96 - samples/sec: 461.26 - lr: 0.000017 - momentum: 0.000000
2023-07-12 04:11:43,465 epoch 8 - iter 24/38 - loss 0.03077445 - time (sec): 282.30 - samples/sec: 463.73 - lr: 0.000016 - momentum: 0.000000
2023-07-12 04:12:18,426 epoch 8 - iter 27/38 - loss 0.03037895 - time (sec): 317.26 - samples/sec: 463.53 - lr: 0.000016 - momentum: 0.000000
2023-07-12 04:12:53,515 epoch 8 - iter 30/38 - loss 0.03059825 - time (sec): 352.35 - samples/sec: 465.28 - lr: 0.000015 - momentum: 0.000000
2023-07-12 04:13:29,301 epoch 8 - iter 33/38 - loss 0.03006945 - time (sec): 388.14 - samples/sec: 466.29 - lr: 0.000015 - momentum: 0.000000
2023-07-12 04:14:04,758 epoch 8 - iter 36/38 - loss 0.03039072 - time (sec): 423.60 - samples/sec: 465.12 - lr: 0.000014 - momentum: 0.000000
2023-07-12 04:14:22,211 ----------------------------------------------------------------------------------------------------
2023-07-12 04:14:22,212 EPOCH 8 done: loss 0.0303 - lr: 0.000014
2023-07-12 04:15:03,512 DEV : loss 0.17446692287921906 - f1-score (micro avg)  0.7428
2023-07-12 04:15:44,346 TEST : loss 0.09343922883272171 - f1-score (micro avg)  0.9259
2023-07-12 04:15:44,393 ----------------------------------------------------------------------------------------------------
2023-07-12 04:16:19,684 epoch 9 - iter 3/38 - loss 0.02915624 - time (sec): 35.29 - samples/sec: 473.85 - lr: 0.000014 - momentum: 0.000000
2023-07-12 04:16:54,938 epoch 9 - iter 6/38 - loss 0.02875755 - time (sec): 70.54 - samples/sec: 467.44 - lr: 0.000013 - momentum: 0.000000
2023-07-12 04:17:30,137 epoch 9 - iter 9/38 - loss 0.02834551 - time (sec): 105.74 - samples/sec: 463.28 - lr: 0.000012 - momentum: 0.000000
2023-07-12 04:18:05,031 epoch 9 - iter 12/38 - loss 0.02876626 - time (sec): 140.64 - samples/sec: 462.86 - lr: 0.000012 - momentum: 0.000000
2023-07-12 04:18:40,217 epoch 9 - iter 15/38 - loss 0.02855872 - time (sec): 175.82 - samples/sec: 460.62 - lr: 0.000011 - momentum: 0.000000
2023-07-12 04:19:14,994 epoch 9 - iter 18/38 - loss 0.02814600 - time (sec): 210.60 - samples/sec: 462.38 - lr: 0.000011 - momentum: 0.000000
2023-07-12 04:19:49,887 epoch 9 - iter 21/38 - loss 0.02732453 - time (sec): 245.49 - samples/sec: 465.24 - lr: 0.000010 - momentum: 0.000000
2023-07-12 04:20:25,245 epoch 9 - iter 24/38 - loss 0.02705480 - time (sec): 280.85 - samples/sec: 467.39 - lr: 0.000010 - momentum: 0.000000
2023-07-12 04:20:59,853 epoch 9 - iter 27/38 - loss 0.02676333 - time (sec): 315.46 - samples/sec: 466.59 - lr: 0.000009 - momentum: 0.000000
2023-07-12 04:21:35,271 epoch 9 - iter 30/38 - loss 0.02699372 - time (sec): 350.88 - samples/sec: 465.91 - lr: 0.000009 - momentum: 0.000000
2023-07-12 04:22:10,740 epoch 9 - iter 33/38 - loss 0.02720159 - time (sec): 386.35 - samples/sec: 465.52 - lr: 0.000008 - momentum: 0.000000
2023-07-12 04:22:45,174 epoch 9 - iter 36/38 - loss 0.02744348 - time (sec): 420.78 - samples/sec: 466.70 - lr: 0.000008 - momentum: 0.000000
2023-07-12 04:23:02,475 ----------------------------------------------------------------------------------------------------
2023-07-12 04:23:02,475 EPOCH 9 done: loss 0.0275 - lr: 0.000008
2023-07-12 04:23:43,593 DEV : loss 0.199692502617836 - f1-score (micro avg)  0.7259
2023-07-12 04:24:24,575 TEST : loss 0.09487223625183105 - f1-score (micro avg)  0.9264
2023-07-12 04:24:24,621 ----------------------------------------------------------------------------------------------------
2023-07-12 04:24:58,967 epoch 10 - iter 3/38 - loss 0.02645829 - time (sec): 34.35 - samples/sec: 469.64 - lr: 0.000007 - momentum: 0.000000
2023-07-12 04:25:34,339 epoch 10 - iter 6/38 - loss 0.02553935 - time (sec): 69.72 - samples/sec: 469.51 - lr: 0.000006 - momentum: 0.000000
2023-07-12 04:26:09,765 epoch 10 - iter 9/38 - loss 0.02527201 - time (sec): 105.14 - samples/sec: 467.63 - lr: 0.000006 - momentum: 0.000000
2023-07-12 04:26:45,198 epoch 10 - iter 12/38 - loss 0.02661079 - time (sec): 140.58 - samples/sec: 464.27 - lr: 0.000005 - momentum: 0.000000
2023-07-12 04:27:19,744 epoch 10 - iter 15/38 - loss 0.02697148 - time (sec): 175.12 - samples/sec: 467.78 - lr: 0.000005 - momentum: 0.000000
2023-07-12 04:27:54,935 epoch 10 - iter 18/38 - loss 0.02720988 - time (sec): 210.31 - samples/sec: 467.78 - lr: 0.000004 - momentum: 0.000000
2023-07-12 04:28:30,160 epoch 10 - iter 21/38 - loss 0.02704781 - time (sec): 245.54 - samples/sec: 464.14 - lr: 0.000004 - momentum: 0.000000
2023-07-12 04:29:05,553 epoch 10 - iter 24/38 - loss 0.02720203 - time (sec): 280.93 - samples/sec: 462.37 - lr: 0.000003 - momentum: 0.000000
2023-07-12 04:29:40,378 epoch 10 - iter 27/38 - loss 0.02699049 - time (sec): 315.76 - samples/sec: 462.60 - lr: 0.000003 - momentum: 0.000000
2023-07-12 04:30:16,307 epoch 10 - iter 30/38 - loss 0.02679004 - time (sec): 351.68 - samples/sec: 463.27 - lr: 0.000002 - momentum: 0.000000
2023-07-12 04:30:51,898 epoch 10 - iter 33/38 - loss 0.02631228 - time (sec): 387.28 - samples/sec: 464.49 - lr: 0.000002 - momentum: 0.000000
2023-07-12 04:31:26,589 epoch 10 - iter 36/38 - loss 0.02650681 - time (sec): 421.97 - samples/sec: 465.93 - lr: 0.000001 - momentum: 0.000000
2023-07-12 04:31:44,165 ----------------------------------------------------------------------------------------------------
2023-07-12 04:31:44,166 EPOCH 10 done: loss 0.0267 - lr: 0.000001
2023-07-12 04:32:25,645 DEV : loss 0.192914679646492 - f1-score (micro avg)  0.729
2023-07-12 04:33:05,205 TEST : loss 0.09816452860832214 - f1-score (micro avg)  0.9257
2023-07-12 04:33:18,761 ----------------------------------------------------------------------------------------------------
2023-07-12 04:33:18,766 Testing using last state of model ...
2023-07-12 04:33:58,296 
Results:
- F-score (micro) 0.9257
- F-score (macro) 0.9087
- Accuracy 0.8877

By class:
              precision    recall  f1-score   support

         ORG     0.8994    0.9308    0.9148      1661
         LOC     0.9480    0.9287    0.9382      1668
         PER     0.9838    0.9777    0.9808      1617
        MISC     0.7732    0.8305    0.8008       702

   micro avg     0.9204    0.9311    0.9257      5648
   macro avg     0.9011    0.9169    0.9087      5648
weighted avg     0.9222    0.9311    0.9264      5648

2023-07-12 04:33:58,296 ----------------------------------------------------------------------------------------------------
