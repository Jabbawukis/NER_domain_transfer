2023-07-20 15:41:04,188 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,189 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-20 15:41:04,189 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,189 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-20 15:41:04,189 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,189 Train:  14987 sentences
2023-07-20 15:41:04,189         (train_with_dev=False, train_with_test=False)
2023-07-20 15:41:04,189 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,189 Training Params:
2023-07-20 15:41:04,190  - learning_rate: "6e-05" 
2023-07-20 15:41:04,190  - mini_batch_size: "400"
2023-07-20 15:41:04,190  - max_epochs: "10"
2023-07-20 15:41:04,190  - shuffle: "True"
2023-07-20 15:41:04,190 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,190 Plugins:
2023-07-20 15:41:04,190  - LinearScheduler | warmup_fraction: '0.1'
2023-07-20 15:41:04,190 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,190 Final evaluation on model after last epoch (final-model.pt)
2023-07-20 15:41:04,190  - metric: "('micro avg', 'f1-score')"
2023-07-20 15:41:04,190 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,190 Computation:
2023-07-20 15:41:04,190  - compute on device: cuda:1
2023-07-20 15:41:04,190  - embedding storage: none
2023-07-20 15:41:04,190 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,190 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_400_lr_6e-05_run_2_ger_test_as_dev"
2023-07-20 15:41:04,190 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,190 Enabled gradient clipping
2023-07-20 15:41:04,190 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:04,190 ----------------------------------------------------------------------------------------------------
2023-07-20 15:41:58,060 epoch 1 - iter 3/38 - loss 2.64982255 - time (sec): 53.87 - samples/sec: 297.91 - lr: 0.000003 - momentum: 0.000000
2023-07-20 15:42:48,952 epoch 1 - iter 6/38 - loss 2.56547878 - time (sec): 104.76 - samples/sec: 306.61 - lr: 0.000008 - momentum: 0.000000
2023-07-20 15:43:43,517 epoch 1 - iter 9/38 - loss 2.43271450 - time (sec): 159.33 - samples/sec: 310.08 - lr: 0.000013 - momentum: 0.000000
2023-07-20 15:44:33,375 epoch 1 - iter 12/38 - loss 2.22714416 - time (sec): 209.18 - samples/sec: 314.15 - lr: 0.000017 - momentum: 0.000000
2023-07-20 15:45:30,393 epoch 1 - iter 15/38 - loss 2.01218870 - time (sec): 266.20 - samples/sec: 308.60 - lr: 0.000022 - momentum: 0.000000
2023-07-20 15:46:23,876 epoch 1 - iter 18/38 - loss 1.84943269 - time (sec): 319.68 - samples/sec: 308.90 - lr: 0.000027 - momentum: 0.000000
2023-07-20 15:47:14,499 epoch 1 - iter 21/38 - loss 1.72247903 - time (sec): 370.31 - samples/sec: 312.84 - lr: 0.000032 - momentum: 0.000000
2023-07-20 15:48:02,359 epoch 1 - iter 24/38 - loss 1.62089249 - time (sec): 418.17 - samples/sec: 316.33 - lr: 0.000036 - momentum: 0.000000
2023-07-20 15:48:56,081 epoch 1 - iter 27/38 - loss 1.53224200 - time (sec): 471.89 - samples/sec: 314.44 - lr: 0.000041 - momentum: 0.000000
2023-07-20 15:49:49,442 epoch 1 - iter 30/38 - loss 1.45190682 - time (sec): 525.25 - samples/sec: 314.03 - lr: 0.000046 - momentum: 0.000000
2023-07-20 15:50:41,340 epoch 1 - iter 33/38 - loss 1.37547655 - time (sec): 577.15 - samples/sec: 314.24 - lr: 0.000051 - momentum: 0.000000
2023-07-20 15:51:33,982 epoch 1 - iter 36/38 - loss 1.31334012 - time (sec): 629.79 - samples/sec: 312.76 - lr: 0.000055 - momentum: 0.000000
2023-07-20 15:51:59,168 ----------------------------------------------------------------------------------------------------
2023-07-20 15:51:59,168 EPOCH 1 done: loss 1.2855 - lr: 0.000055
2023-07-20 15:53:05,415 DEV : loss 0.4048256278038025 - f1-score (micro avg)  0.2567
2023-07-20 15:54:11,756 TEST : loss 0.43071842193603516 - f1-score (micro avg)  0.4318
2023-07-20 15:54:11,841 ----------------------------------------------------------------------------------------------------
2023-07-20 15:55:05,346 epoch 2 - iter 3/38 - loss 0.55677650 - time (sec): 53.50 - samples/sec: 309.80 - lr: 0.000060 - momentum: 0.000000
2023-07-20 15:55:54,718 epoch 2 - iter 6/38 - loss 0.51247514 - time (sec): 102.87 - samples/sec: 323.84 - lr: 0.000059 - momentum: 0.000000
2023-07-20 15:56:39,940 epoch 2 - iter 9/38 - loss 0.46883535 - time (sec): 148.10 - samples/sec: 334.03 - lr: 0.000059 - momentum: 0.000000
2023-07-20 15:57:32,434 epoch 2 - iter 12/38 - loss 0.43314937 - time (sec): 200.59 - samples/sec: 324.97 - lr: 0.000058 - momentum: 0.000000
2023-07-20 15:58:25,867 epoch 2 - iter 15/38 - loss 0.39967166 - time (sec): 254.02 - samples/sec: 322.71 - lr: 0.000058 - momentum: 0.000000
2023-07-20 15:59:15,824 epoch 2 - iter 18/38 - loss 0.37564220 - time (sec): 303.98 - samples/sec: 325.57 - lr: 0.000057 - momentum: 0.000000
2023-07-20 16:00:01,260 epoch 2 - iter 21/38 - loss 0.35824804 - time (sec): 349.42 - samples/sec: 328.80 - lr: 0.000057 - momentum: 0.000000
2023-07-20 16:00:53,481 epoch 2 - iter 24/38 - loss 0.33522185 - time (sec): 401.64 - samples/sec: 327.08 - lr: 0.000056 - momentum: 0.000000
2023-07-20 16:01:46,111 epoch 2 - iter 27/38 - loss 0.31511655 - time (sec): 454.27 - samples/sec: 323.68 - lr: 0.000055 - momentum: 0.000000
2023-07-20 16:02:33,100 epoch 2 - iter 30/38 - loss 0.29795524 - time (sec): 501.26 - samples/sec: 326.61 - lr: 0.000055 - momentum: 0.000000
2023-07-20 16:03:20,480 epoch 2 - iter 33/38 - loss 0.28310343 - time (sec): 548.64 - samples/sec: 328.45 - lr: 0.000054 - momentum: 0.000000
2023-07-20 16:04:14,432 epoch 2 - iter 36/38 - loss 0.27023501 - time (sec): 602.59 - samples/sec: 326.41 - lr: 0.000054 - momentum: 0.000000
2023-07-20 16:04:39,926 ----------------------------------------------------------------------------------------------------
2023-07-20 16:04:39,927 EPOCH 2 done: loss 0.2637 - lr: 0.000054
2023-07-20 16:05:37,473 DEV : loss 0.200968936085701 - f1-score (micro avg)  0.6835
2023-07-20 16:06:36,940 TEST : loss 0.09915890544652939 - f1-score (micro avg)  0.9002
2023-07-20 16:06:37,005 ----------------------------------------------------------------------------------------------------
2023-07-20 16:07:27,718 epoch 3 - iter 3/38 - loss 0.08334184 - time (sec): 50.71 - samples/sec: 325.69 - lr: 0.000053 - momentum: 0.000000
2023-07-20 16:08:18,348 epoch 3 - iter 6/38 - loss 0.08457587 - time (sec): 101.34 - samples/sec: 316.53 - lr: 0.000053 - momentum: 0.000000
2023-07-20 16:09:08,280 epoch 3 - iter 9/38 - loss 0.08423020 - time (sec): 151.27 - samples/sec: 316.75 - lr: 0.000052 - momentum: 0.000000
2023-07-20 16:09:57,355 epoch 3 - iter 12/38 - loss 0.08136953 - time (sec): 200.35 - samples/sec: 320.97 - lr: 0.000052 - momentum: 0.000000
2023-07-20 16:10:49,825 epoch 3 - iter 15/38 - loss 0.07791712 - time (sec): 252.82 - samples/sec: 317.93 - lr: 0.000051 - momentum: 0.000000
2023-07-20 16:11:41,487 epoch 3 - iter 18/38 - loss 0.07657657 - time (sec): 304.48 - samples/sec: 319.38 - lr: 0.000050 - momentum: 0.000000
2023-07-20 16:12:31,871 epoch 3 - iter 21/38 - loss 0.07527142 - time (sec): 354.86 - samples/sec: 319.85 - lr: 0.000050 - momentum: 0.000000
2023-07-20 16:13:19,677 epoch 3 - iter 24/38 - loss 0.07411269 - time (sec): 402.67 - samples/sec: 324.87 - lr: 0.000049 - momentum: 0.000000
2023-07-20 16:14:11,219 epoch 3 - iter 27/38 - loss 0.07252054 - time (sec): 454.21 - samples/sec: 324.34 - lr: 0.000049 - momentum: 0.000000
2023-07-20 16:14:59,151 epoch 3 - iter 30/38 - loss 0.07221786 - time (sec): 502.14 - samples/sec: 324.96 - lr: 0.000048 - momentum: 0.000000
2023-07-20 16:15:50,402 epoch 3 - iter 33/38 - loss 0.07051113 - time (sec): 553.39 - samples/sec: 324.64 - lr: 0.000048 - momentum: 0.000000
2023-07-20 16:16:39,601 epoch 3 - iter 36/38 - loss 0.07006562 - time (sec): 602.59 - samples/sec: 325.98 - lr: 0.000047 - momentum: 0.000000
2023-07-20 16:17:03,796 ----------------------------------------------------------------------------------------------------
2023-07-20 16:17:03,796 EPOCH 3 done: loss 0.0696 - lr: 0.000047
2023-07-20 16:18:07,375 DEV : loss 0.17908070981502533 - f1-score (micro avg)  0.7092
2023-07-20 16:19:10,422 TEST : loss 0.08910926431417465 - f1-score (micro avg)  0.9226
2023-07-20 16:19:10,507 ----------------------------------------------------------------------------------------------------
2023-07-20 16:20:00,482 epoch 4 - iter 3/38 - loss 0.04314941 - time (sec): 49.97 - samples/sec: 320.65 - lr: 0.000046 - momentum: 0.000000
2023-07-20 16:20:51,254 epoch 4 - iter 6/38 - loss 0.04645449 - time (sec): 100.74 - samples/sec: 323.38 - lr: 0.000046 - momentum: 0.000000
2023-07-20 16:21:40,473 epoch 4 - iter 9/38 - loss 0.04818534 - time (sec): 149.96 - samples/sec: 329.08 - lr: 0.000045 - momentum: 0.000000
2023-07-20 16:22:26,756 epoch 4 - iter 12/38 - loss 0.04870320 - time (sec): 196.25 - samples/sec: 331.26 - lr: 0.000045 - momentum: 0.000000
2023-07-20 16:23:14,161 epoch 4 - iter 15/38 - loss 0.04782285 - time (sec): 243.65 - samples/sec: 333.38 - lr: 0.000044 - momentum: 0.000000
2023-07-20 16:24:04,761 epoch 4 - iter 18/38 - loss 0.04699536 - time (sec): 294.25 - samples/sec: 334.61 - lr: 0.000044 - momentum: 0.000000
2023-07-20 16:24:52,122 epoch 4 - iter 21/38 - loss 0.04649227 - time (sec): 341.61 - samples/sec: 337.50 - lr: 0.000043 - momentum: 0.000000
2023-07-20 16:25:42,454 epoch 4 - iter 24/38 - loss 0.04485415 - time (sec): 391.94 - samples/sec: 334.48 - lr: 0.000043 - momentum: 0.000000
2023-07-20 16:26:29,869 epoch 4 - iter 27/38 - loss 0.04460988 - time (sec): 439.36 - samples/sec: 336.48 - lr: 0.000042 - momentum: 0.000000
2023-07-20 16:27:20,004 epoch 4 - iter 30/38 - loss 0.04418962 - time (sec): 489.49 - samples/sec: 335.68 - lr: 0.000042 - momentum: 0.000000
2023-07-20 16:28:07,120 epoch 4 - iter 33/38 - loss 0.04374287 - time (sec): 536.61 - samples/sec: 335.89 - lr: 0.000041 - momentum: 0.000000
2023-07-20 16:28:55,581 epoch 4 - iter 36/38 - loss 0.04361746 - time (sec): 585.07 - samples/sec: 336.12 - lr: 0.000041 - momentum: 0.000000
2023-07-20 16:29:18,611 ----------------------------------------------------------------------------------------------------
2023-07-20 16:29:18,611 EPOCH 4 done: loss 0.0432 - lr: 0.000041
2023-07-20 16:30:20,943 DEV : loss 0.1511383354663849 - f1-score (micro avg)  0.742
2023-07-20 16:31:19,839 TEST : loss 0.09412708878517151 - f1-score (micro avg)  0.9272
2023-07-20 16:31:19,904 ----------------------------------------------------------------------------------------------------
2023-07-20 16:32:07,886 epoch 5 - iter 3/38 - loss 0.03837159 - time (sec): 47.98 - samples/sec: 330.49 - lr: 0.000040 - momentum: 0.000000
2023-07-20 16:32:57,782 epoch 5 - iter 6/38 - loss 0.03460882 - time (sec): 97.88 - samples/sec: 323.84 - lr: 0.000039 - momentum: 0.000000
2023-07-20 16:33:43,615 epoch 5 - iter 9/38 - loss 0.03262213 - time (sec): 143.71 - samples/sec: 330.00 - lr: 0.000039 - momentum: 0.000000
2023-07-20 16:34:32,803 epoch 5 - iter 12/38 - loss 0.03178011 - time (sec): 192.90 - samples/sec: 330.36 - lr: 0.000038 - momentum: 0.000000
2023-07-20 16:35:22,649 epoch 5 - iter 15/38 - loss 0.03054192 - time (sec): 242.74 - samples/sec: 330.10 - lr: 0.000038 - momentum: 0.000000
2023-07-20 16:36:10,453 epoch 5 - iter 18/38 - loss 0.03020788 - time (sec): 290.55 - samples/sec: 332.07 - lr: 0.000037 - momentum: 0.000000
2023-07-20 16:37:02,342 epoch 5 - iter 21/38 - loss 0.03069953 - time (sec): 342.44 - samples/sec: 331.15 - lr: 0.000037 - momentum: 0.000000
2023-07-20 16:37:52,567 epoch 5 - iter 24/38 - loss 0.03085940 - time (sec): 392.66 - samples/sec: 330.86 - lr: 0.000036 - momentum: 0.000000
2023-07-20 16:38:43,936 epoch 5 - iter 27/38 - loss 0.03022393 - time (sec): 444.03 - samples/sec: 330.91 - lr: 0.000036 - momentum: 0.000000
2023-07-20 16:39:35,998 epoch 5 - iter 30/38 - loss 0.03001317 - time (sec): 496.09 - samples/sec: 330.14 - lr: 0.000035 - momentum: 0.000000
2023-07-20 16:40:24,489 epoch 5 - iter 33/38 - loss 0.03044376 - time (sec): 544.58 - samples/sec: 332.26 - lr: 0.000035 - momentum: 0.000000
2023-07-20 16:41:13,468 epoch 5 - iter 36/38 - loss 0.03069031 - time (sec): 593.56 - samples/sec: 331.65 - lr: 0.000034 - momentum: 0.000000
2023-07-20 16:41:37,428 ----------------------------------------------------------------------------------------------------
2023-07-20 16:41:37,428 EPOCH 5 done: loss 0.0308 - lr: 0.000034
2023-07-20 16:42:40,571 DEV : loss 0.12246155738830566 - f1-score (micro avg)  0.7765
2023-07-20 16:43:43,043 TEST : loss 0.08016953617334366 - f1-score (micro avg)  0.9353
2023-07-20 16:43:43,116 ----------------------------------------------------------------------------------------------------
2023-07-20 16:44:34,516 epoch 6 - iter 3/38 - loss 0.02014295 - time (sec): 51.40 - samples/sec: 318.59 - lr: 0.000033 - momentum: 0.000000
2023-07-20 16:45:25,327 epoch 6 - iter 6/38 - loss 0.01960920 - time (sec): 102.21 - samples/sec: 320.02 - lr: 0.000033 - momentum: 0.000000
2023-07-20 16:46:16,040 epoch 6 - iter 9/38 - loss 0.01918238 - time (sec): 152.92 - samples/sec: 325.50 - lr: 0.000032 - momentum: 0.000000
2023-07-20 16:47:06,581 epoch 6 - iter 12/38 - loss 0.01963661 - time (sec): 203.46 - samples/sec: 325.72 - lr: 0.000032 - momentum: 0.000000
2023-07-20 16:47:51,471 epoch 6 - iter 15/38 - loss 0.02110464 - time (sec): 248.35 - samples/sec: 332.36 - lr: 0.000031 - momentum: 0.000000
2023-07-20 16:48:39,625 epoch 6 - iter 18/38 - loss 0.02155067 - time (sec): 296.51 - samples/sec: 334.04 - lr: 0.000031 - momentum: 0.000000
2023-07-20 16:49:28,509 epoch 6 - iter 21/38 - loss 0.02202047 - time (sec): 345.39 - samples/sec: 331.88 - lr: 0.000030 - momentum: 0.000000
2023-07-20 16:50:15,760 epoch 6 - iter 24/38 - loss 0.02163958 - time (sec): 392.64 - samples/sec: 333.03 - lr: 0.000030 - momentum: 0.000000
2023-07-20 16:51:05,996 epoch 6 - iter 27/38 - loss 0.02169600 - time (sec): 442.88 - samples/sec: 331.80 - lr: 0.000029 - momentum: 0.000000
2023-07-20 16:51:56,066 epoch 6 - iter 30/38 - loss 0.02223873 - time (sec): 492.95 - samples/sec: 330.87 - lr: 0.000029 - momentum: 0.000000
2023-07-20 16:52:44,225 epoch 6 - iter 33/38 - loss 0.02206623 - time (sec): 541.11 - samples/sec: 331.88 - lr: 0.000028 - momentum: 0.000000
2023-07-20 16:53:34,571 epoch 6 - iter 36/38 - loss 0.02134359 - time (sec): 591.45 - samples/sec: 332.23 - lr: 0.000028 - momentum: 0.000000
2023-07-20 16:53:57,820 ----------------------------------------------------------------------------------------------------
2023-07-20 16:53:57,821 EPOCH 6 done: loss 0.0211 - lr: 0.000028
2023-07-20 16:54:56,140 DEV : loss 0.1884872317314148 - f1-score (micro avg)  0.7205
2023-07-20 16:55:56,669 TEST : loss 0.0955975279211998 - f1-score (micro avg)  0.9336
2023-07-20 16:55:56,741 ----------------------------------------------------------------------------------------------------
2023-07-20 16:56:46,639 epoch 7 - iter 3/38 - loss 0.01835419 - time (sec): 49.89 - samples/sec: 338.99 - lr: 0.000027 - momentum: 0.000000
2023-07-20 16:57:33,987 epoch 7 - iter 6/38 - loss 0.01894966 - time (sec): 97.24 - samples/sec: 341.80 - lr: 0.000026 - momentum: 0.000000
2023-07-20 16:58:24,940 epoch 7 - iter 9/38 - loss 0.01855784 - time (sec): 148.20 - samples/sec: 336.37 - lr: 0.000026 - momentum: 0.000000
2023-07-20 16:59:12,330 epoch 7 - iter 12/38 - loss 0.01841341 - time (sec): 195.59 - samples/sec: 338.12 - lr: 0.000025 - momentum: 0.000000
2023-07-20 17:00:00,714 epoch 7 - iter 15/38 - loss 0.01730117 - time (sec): 243.97 - samples/sec: 339.25 - lr: 0.000025 - momentum: 0.000000
2023-07-20 17:00:48,601 epoch 7 - iter 18/38 - loss 0.01757843 - time (sec): 291.86 - samples/sec: 340.33 - lr: 0.000024 - momentum: 0.000000
2023-07-20 17:01:36,509 epoch 7 - iter 21/38 - loss 0.01728175 - time (sec): 339.77 - samples/sec: 339.51 - lr: 0.000024 - momentum: 0.000000
2023-07-20 17:02:26,524 epoch 7 - iter 24/38 - loss 0.01726266 - time (sec): 389.78 - samples/sec: 338.12 - lr: 0.000023 - momentum: 0.000000
2023-07-20 17:03:11,418 epoch 7 - iter 27/38 - loss 0.01723997 - time (sec): 434.67 - samples/sec: 340.22 - lr: 0.000023 - momentum: 0.000000
2023-07-20 17:04:02,072 epoch 7 - iter 30/38 - loss 0.01707249 - time (sec): 485.33 - samples/sec: 339.28 - lr: 0.000022 - momentum: 0.000000
2023-07-20 17:04:49,558 epoch 7 - iter 33/38 - loss 0.01743688 - time (sec): 532.81 - samples/sec: 338.81 - lr: 0.000022 - momentum: 0.000000
2023-07-20 17:05:41,121 epoch 7 - iter 36/38 - loss 0.01734104 - time (sec): 584.38 - samples/sec: 336.91 - lr: 0.000021 - momentum: 0.000000
2023-07-20 17:06:02,816 ----------------------------------------------------------------------------------------------------
2023-07-20 17:06:02,816 EPOCH 7 done: loss 0.0171 - lr: 0.000021
2023-07-20 17:07:08,747 DEV : loss 0.15238486230373383 - f1-score (micro avg)  0.7525
2023-07-20 17:08:09,815 TEST : loss 0.09114475548267365 - f1-score (micro avg)  0.9346
2023-07-20 17:08:09,882 ----------------------------------------------------------------------------------------------------
2023-07-20 17:08:58,644 epoch 8 - iter 3/38 - loss 0.01431582 - time (sec): 48.76 - samples/sec: 344.88 - lr: 0.000020 - momentum: 0.000000
2023-07-20 17:09:47,246 epoch 8 - iter 6/38 - loss 0.01443943 - time (sec): 97.36 - samples/sec: 340.50 - lr: 0.000020 - momentum: 0.000000
2023-07-20 17:10:37,189 epoch 8 - iter 9/38 - loss 0.01364785 - time (sec): 147.30 - samples/sec: 337.22 - lr: 0.000019 - momentum: 0.000000
2023-07-20 17:11:24,668 epoch 8 - iter 12/38 - loss 0.01297117 - time (sec): 194.78 - samples/sec: 336.74 - lr: 0.000019 - momentum: 0.000000
2023-07-20 17:12:15,458 epoch 8 - iter 15/38 - loss 0.01310122 - time (sec): 245.57 - samples/sec: 334.63 - lr: 0.000018 - momentum: 0.000000
2023-07-20 17:13:03,673 epoch 8 - iter 18/38 - loss 0.01344628 - time (sec): 293.79 - samples/sec: 332.56 - lr: 0.000018 - momentum: 0.000000
2023-07-20 17:13:53,543 epoch 8 - iter 21/38 - loss 0.01294192 - time (sec): 343.66 - samples/sec: 333.05 - lr: 0.000017 - momentum: 0.000000
2023-07-20 17:14:40,748 epoch 8 - iter 24/38 - loss 0.01393596 - time (sec): 390.86 - samples/sec: 336.14 - lr: 0.000016 - momentum: 0.000000
2023-07-20 17:15:30,979 epoch 8 - iter 27/38 - loss 0.01426158 - time (sec): 441.09 - samples/sec: 335.08 - lr: 0.000016 - momentum: 0.000000
2023-07-20 17:16:19,754 epoch 8 - iter 30/38 - loss 0.01424825 - time (sec): 489.87 - samples/sec: 333.68 - lr: 0.000015 - momentum: 0.000000
2023-07-20 17:17:07,670 epoch 8 - iter 33/38 - loss 0.01416883 - time (sec): 537.79 - samples/sec: 334.52 - lr: 0.000015 - momentum: 0.000000
2023-07-20 17:17:55,685 epoch 8 - iter 36/38 - loss 0.01393751 - time (sec): 585.80 - samples/sec: 334.80 - lr: 0.000014 - momentum: 0.000000
2023-07-20 17:18:18,813 ----------------------------------------------------------------------------------------------------
2023-07-20 17:18:18,814 EPOCH 8 done: loss 0.0140 - lr: 0.000014
2023-07-20 17:19:20,270 DEV : loss 0.1726647913455963 - f1-score (micro avg)  0.7404
2023-07-20 17:20:20,035 TEST : loss 0.0910540223121643 - f1-score (micro avg)  0.9345
2023-07-20 17:20:20,113 ----------------------------------------------------------------------------------------------------
2023-07-20 17:21:10,492 epoch 9 - iter 3/38 - loss 0.01149466 - time (sec): 50.38 - samples/sec: 319.77 - lr: 0.000014 - momentum: 0.000000
2023-07-20 17:21:57,216 epoch 9 - iter 6/38 - loss 0.01008269 - time (sec): 97.10 - samples/sec: 336.08 - lr: 0.000013 - momentum: 0.000000
2023-07-20 17:22:45,870 epoch 9 - iter 9/38 - loss 0.00954670 - time (sec): 145.75 - samples/sec: 334.02 - lr: 0.000012 - momentum: 0.000000
2023-07-20 17:23:31,934 epoch 9 - iter 12/38 - loss 0.01113267 - time (sec): 191.82 - samples/sec: 340.57 - lr: 0.000012 - momentum: 0.000000
2023-07-20 17:24:22,436 epoch 9 - iter 15/38 - loss 0.01079131 - time (sec): 242.32 - samples/sec: 337.09 - lr: 0.000011 - momentum: 0.000000
2023-07-20 17:25:08,491 epoch 9 - iter 18/38 - loss 0.01001349 - time (sec): 288.38 - samples/sec: 339.35 - lr: 0.000011 - momentum: 0.000000
2023-07-20 17:25:57,291 epoch 9 - iter 21/38 - loss 0.01028017 - time (sec): 337.18 - samples/sec: 337.39 - lr: 0.000010 - momentum: 0.000000
2023-07-20 17:26:45,368 epoch 9 - iter 24/38 - loss 0.01031367 - time (sec): 385.25 - samples/sec: 339.33 - lr: 0.000010 - momentum: 0.000000
2023-07-20 17:27:32,877 epoch 9 - iter 27/38 - loss 0.01013870 - time (sec): 432.76 - samples/sec: 339.87 - lr: 0.000009 - momentum: 0.000000
2023-07-20 17:28:25,359 epoch 9 - iter 30/38 - loss 0.01011081 - time (sec): 485.24 - samples/sec: 336.93 - lr: 0.000009 - momentum: 0.000000
2023-07-20 17:29:13,066 epoch 9 - iter 33/38 - loss 0.00988138 - time (sec): 532.95 - samples/sec: 338.64 - lr: 0.000008 - momentum: 0.000000
2023-07-20 17:30:04,818 epoch 9 - iter 36/38 - loss 0.01003419 - time (sec): 584.70 - samples/sec: 336.63 - lr: 0.000008 - momentum: 0.000000
2023-07-20 17:30:26,670 ----------------------------------------------------------------------------------------------------
2023-07-20 17:30:26,670 EPOCH 9 done: loss 0.0101 - lr: 0.000008
2023-07-20 17:31:33,802 DEV : loss 0.163955956697464 - f1-score (micro avg)  0.7606
2023-07-20 17:32:36,405 TEST : loss 0.10208500921726227 - f1-score (micro avg)  0.9359
2023-07-20 17:32:36,485 ----------------------------------------------------------------------------------------------------
2023-07-20 17:33:24,875 epoch 10 - iter 3/38 - loss 0.00946499 - time (sec): 48.39 - samples/sec: 348.79 - lr: 0.000007 - momentum: 0.000000
2023-07-20 17:34:15,895 epoch 10 - iter 6/38 - loss 0.00985428 - time (sec): 99.41 - samples/sec: 330.33 - lr: 0.000006 - momentum: 0.000000
2023-07-20 17:35:04,973 epoch 10 - iter 9/38 - loss 0.00996019 - time (sec): 148.49 - samples/sec: 334.83 - lr: 0.000006 - momentum: 0.000000
2023-07-20 17:35:56,144 epoch 10 - iter 12/38 - loss 0.01056575 - time (sec): 199.66 - samples/sec: 331.53 - lr: 0.000005 - momentum: 0.000000
2023-07-20 17:36:43,489 epoch 10 - iter 15/38 - loss 0.00994367 - time (sec): 247.00 - samples/sec: 335.03 - lr: 0.000005 - momentum: 0.000000
2023-07-20 17:37:33,988 epoch 10 - iter 18/38 - loss 0.00921777 - time (sec): 297.50 - samples/sec: 333.81 - lr: 0.000004 - momentum: 0.000000
2023-07-20 17:38:22,033 epoch 10 - iter 21/38 - loss 0.00869944 - time (sec): 345.55 - samples/sec: 332.83 - lr: 0.000004 - momentum: 0.000000
2023-07-20 17:39:12,585 epoch 10 - iter 24/38 - loss 0.00865802 - time (sec): 396.10 - samples/sec: 331.71 - lr: 0.000003 - momentum: 0.000000
2023-07-20 17:40:03,113 epoch 10 - iter 27/38 - loss 0.00879826 - time (sec): 446.63 - samples/sec: 330.72 - lr: 0.000003 - momentum: 0.000000
2023-07-20 17:40:53,614 epoch 10 - iter 30/38 - loss 0.00862708 - time (sec): 497.13 - samples/sec: 329.37 - lr: 0.000002 - momentum: 0.000000
2023-07-20 17:41:43,321 epoch 10 - iter 33/38 - loss 0.00870236 - time (sec): 546.83 - samples/sec: 329.17 - lr: 0.000002 - momentum: 0.000000
2023-07-20 17:42:28,588 epoch 10 - iter 36/38 - loss 0.00844894 - time (sec): 592.10 - samples/sec: 331.53 - lr: 0.000001 - momentum: 0.000000
2023-07-20 17:42:53,225 ----------------------------------------------------------------------------------------------------
2023-07-20 17:42:53,225 EPOCH 10 done: loss 0.0087 - lr: 0.000001
2023-07-20 17:43:53,290 DEV : loss 0.1808851808309555 - f1-score (micro avg)  0.7511
2023-07-20 17:44:53,714 TEST : loss 0.09860328584909439 - f1-score (micro avg)  0.9363
2023-07-20 17:45:04,253 ----------------------------------------------------------------------------------------------------
2023-07-20 17:45:04,256 Testing using last state of model ...
2023-07-20 17:46:04,819 
Results:
- F-score (micro) 0.9363
- F-score (macro) 0.921
- Accuracy 0.9038

By class:
              precision    recall  f1-score   support

         ORG     0.9130    0.9416    0.9271      1661
         LOC     0.9539    0.9436    0.9488      1668
         PER     0.9869    0.9814    0.9842      1617
        MISC     0.7913    0.8590    0.8238       702

   micro avg     0.9294    0.9433    0.9363      5648
   macro avg     0.9113    0.9314    0.9210      5648
weighted avg     0.9311    0.9433    0.9370      5648

2023-07-20 17:46:04,819 ----------------------------------------------------------------------------------------------------
