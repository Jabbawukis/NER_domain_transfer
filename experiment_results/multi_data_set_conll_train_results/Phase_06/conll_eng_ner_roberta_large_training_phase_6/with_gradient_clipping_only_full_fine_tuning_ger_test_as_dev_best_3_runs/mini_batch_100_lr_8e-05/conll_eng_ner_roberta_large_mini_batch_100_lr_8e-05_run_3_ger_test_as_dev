2023-07-20 23:47:15,556 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,557 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-20 23:47:15,557 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,557 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-20 23:47:15,557 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,557 Train:  14987 sentences
2023-07-20 23:47:15,557         (train_with_dev=False, train_with_test=False)
2023-07-20 23:47:15,557 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,557 Training Params:
2023-07-20 23:47:15,557  - learning_rate: "8e-05" 
2023-07-20 23:47:15,557  - mini_batch_size: "100"
2023-07-20 23:47:15,557  - max_epochs: "10"
2023-07-20 23:47:15,557  - shuffle: "True"
2023-07-20 23:47:15,558 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,558 Plugins:
2023-07-20 23:47:15,558  - LinearScheduler | warmup_fraction: '0.1'
2023-07-20 23:47:15,558 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,558 Final evaluation on model after last epoch (final-model.pt)
2023-07-20 23:47:15,558  - metric: "('micro avg', 'f1-score')"
2023-07-20 23:47:15,558 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,558 Computation:
2023-07-20 23:47:15,558  - compute on device: cuda:1
2023-07-20 23:47:15,558  - embedding storage: none
2023-07-20 23:47:15,558 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,558 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_8e-05_run_3_ger_test_as_dev"
2023-07-20 23:47:15,558 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,558 Enabled gradient clipping
2023-07-20 23:47:15,558 ----------------------------------------------------------------------------------------------------
2023-07-20 23:47:15,558 ----------------------------------------------------------------------------------------------------
2023-07-20 23:48:16,819 epoch 1 - iter 15/150 - loss 3.10255953 - time (sec): 61.26 - samples/sec: 332.53 - lr: 0.000007 - momentum: 0.000000
2023-07-20 23:49:14,847 epoch 1 - iter 30/150 - loss 2.23541684 - time (sec): 119.29 - samples/sec: 346.86 - lr: 0.000015 - momentum: 0.000000
2023-07-20 23:50:18,937 epoch 1 - iter 45/150 - loss 1.72347631 - time (sec): 183.38 - samples/sec: 335.61 - lr: 0.000023 - momentum: 0.000000
2023-07-20 23:51:19,572 epoch 1 - iter 60/150 - loss 1.41096906 - time (sec): 244.01 - samples/sec: 334.06 - lr: 0.000031 - momentum: 0.000000
2023-07-20 23:52:22,570 epoch 1 - iter 75/150 - loss 1.17900577 - time (sec): 307.01 - samples/sec: 332.14 - lr: 0.000039 - momentum: 0.000000
2023-07-20 23:53:23,843 epoch 1 - iter 90/150 - loss 1.00806945 - time (sec): 368.28 - samples/sec: 333.70 - lr: 0.000047 - momentum: 0.000000
2023-07-20 23:54:23,844 epoch 1 - iter 105/150 - loss 0.87804934 - time (sec): 428.28 - samples/sec: 336.39 - lr: 0.000055 - momentum: 0.000000
2023-07-20 23:55:27,587 epoch 1 - iter 120/150 - loss 0.78178966 - time (sec): 492.03 - samples/sec: 334.27 - lr: 0.000063 - momentum: 0.000000
2023-07-20 23:56:26,719 epoch 1 - iter 135/150 - loss 0.70974211 - time (sec): 551.16 - samples/sec: 335.19 - lr: 0.000071 - momentum: 0.000000
2023-07-20 23:57:30,731 epoch 1 - iter 150/150 - loss 0.65200127 - time (sec): 615.17 - samples/sec: 332.54 - lr: 0.000079 - momentum: 0.000000
2023-07-20 23:57:30,731 ----------------------------------------------------------------------------------------------------
2023-07-20 23:57:30,731 EPOCH 1 done: loss 0.6520 - lr: 0.000079
2023-07-20 23:58:30,592 DEV : loss 0.25105684995651245 - f1-score (micro avg)  0.6565
2023-07-20 23:59:35,077 TEST : loss 0.11354529857635498 - f1-score (micro avg)  0.8968
2023-07-20 23:59:35,166 ----------------------------------------------------------------------------------------------------
2023-07-21 00:00:36,254 epoch 2 - iter 15/150 - loss 0.10871202 - time (sec): 61.08 - samples/sec: 331.88 - lr: 0.000079 - momentum: 0.000000
2023-07-21 00:01:41,255 epoch 2 - iter 30/150 - loss 0.09516031 - time (sec): 126.09 - samples/sec: 329.78 - lr: 0.000078 - momentum: 0.000000
2023-07-21 00:02:43,839 epoch 2 - iter 45/150 - loss 0.08714111 - time (sec): 188.67 - samples/sec: 328.52 - lr: 0.000077 - momentum: 0.000000
2023-07-21 00:03:44,589 epoch 2 - iter 60/150 - loss 0.08283272 - time (sec): 249.42 - samples/sec: 328.55 - lr: 0.000077 - momentum: 0.000000
2023-07-21 00:04:49,874 epoch 2 - iter 75/150 - loss 0.07987278 - time (sec): 314.70 - samples/sec: 324.82 - lr: 0.000076 - momentum: 0.000000
2023-07-21 00:05:52,513 epoch 2 - iter 90/150 - loss 0.07995115 - time (sec): 377.34 - samples/sec: 323.65 - lr: 0.000075 - momentum: 0.000000
2023-07-21 00:06:57,411 epoch 2 - iter 105/150 - loss 0.07660122 - time (sec): 442.24 - samples/sec: 323.18 - lr: 0.000074 - momentum: 0.000000
2023-07-21 00:08:00,501 epoch 2 - iter 120/150 - loss 0.07557163 - time (sec): 505.33 - samples/sec: 324.02 - lr: 0.000073 - momentum: 0.000000
2023-07-21 00:09:06,261 epoch 2 - iter 135/150 - loss 0.07440951 - time (sec): 571.09 - samples/sec: 322.33 - lr: 0.000072 - momentum: 0.000000
2023-07-21 00:10:07,284 epoch 2 - iter 150/150 - loss 0.07280579 - time (sec): 632.11 - samples/sec: 323.62 - lr: 0.000071 - momentum: 0.000000
2023-07-21 00:10:07,284 ----------------------------------------------------------------------------------------------------
2023-07-21 00:10:07,284 EPOCH 2 done: loss 0.0728 - lr: 0.000071
2023-07-21 00:11:09,618 DEV : loss 0.18083614110946655 - f1-score (micro avg)  0.6745
2023-07-21 00:12:11,161 TEST : loss 0.1003432646393776 - f1-score (micro avg)  0.9062
2023-07-21 00:12:11,208 ----------------------------------------------------------------------------------------------------
2023-07-21 00:13:11,940 epoch 3 - iter 15/150 - loss 0.05483877 - time (sec): 60.73 - samples/sec: 336.39 - lr: 0.000070 - momentum: 0.000000
2023-07-21 00:14:16,208 epoch 3 - iter 30/150 - loss 0.04938672 - time (sec): 125.00 - samples/sec: 325.15 - lr: 0.000069 - momentum: 0.000000
2023-07-21 00:15:16,792 epoch 3 - iter 45/150 - loss 0.04637162 - time (sec): 185.58 - samples/sec: 333.02 - lr: 0.000069 - momentum: 0.000000
2023-07-21 00:16:20,481 epoch 3 - iter 60/150 - loss 0.04847727 - time (sec): 249.27 - samples/sec: 328.53 - lr: 0.000068 - momentum: 0.000000
2023-07-21 00:17:22,367 epoch 3 - iter 75/150 - loss 0.06947212 - time (sec): 311.16 - samples/sec: 328.04 - lr: 0.000067 - momentum: 0.000000
2023-07-21 00:18:26,009 epoch 3 - iter 90/150 - loss 0.07150253 - time (sec): 374.80 - samples/sec: 327.94 - lr: 0.000066 - momentum: 0.000000
2023-07-21 00:19:26,192 epoch 3 - iter 105/150 - loss 0.06790545 - time (sec): 434.98 - samples/sec: 327.90 - lr: 0.000065 - momentum: 0.000000
2023-07-21 00:20:30,357 epoch 3 - iter 120/150 - loss 0.06354980 - time (sec): 499.15 - samples/sec: 327.81 - lr: 0.000064 - momentum: 0.000000
2023-07-21 00:21:26,238 epoch 3 - iter 135/150 - loss 0.06069718 - time (sec): 555.03 - samples/sec: 332.30 - lr: 0.000063 - momentum: 0.000000
2023-07-21 00:22:26,539 epoch 3 - iter 150/150 - loss 0.05850195 - time (sec): 615.33 - samples/sec: 332.45 - lr: 0.000062 - momentum: 0.000000
2023-07-21 00:22:26,540 ----------------------------------------------------------------------------------------------------
2023-07-21 00:22:26,540 EPOCH 3 done: loss 0.0585 - lr: 0.000062
2023-07-21 00:23:28,474 DEV : loss 0.19959503412246704 - f1-score (micro avg)  0.6768
2023-07-21 00:24:30,705 TEST : loss 0.09146071970462799 - f1-score (micro avg)  0.923
2023-07-21 00:24:30,768 ----------------------------------------------------------------------------------------------------
2023-07-21 00:25:35,719 epoch 4 - iter 15/150 - loss 0.03493752 - time (sec): 64.95 - samples/sec: 324.87 - lr: 0.000062 - momentum: 0.000000
2023-07-21 00:26:35,376 epoch 4 - iter 30/150 - loss 0.03424973 - time (sec): 124.61 - samples/sec: 332.63 - lr: 0.000061 - momentum: 0.000000
2023-07-21 00:27:39,246 epoch 4 - iter 45/150 - loss 0.03394578 - time (sec): 188.48 - samples/sec: 328.82 - lr: 0.000060 - momentum: 0.000000
2023-07-21 00:28:42,886 epoch 4 - iter 60/150 - loss 0.03574847 - time (sec): 252.12 - samples/sec: 325.96 - lr: 0.000059 - momentum: 0.000000
2023-07-21 00:29:48,300 epoch 4 - iter 75/150 - loss 0.03586863 - time (sec): 317.53 - samples/sec: 322.75 - lr: 0.000058 - momentum: 0.000000
2023-07-21 00:30:53,133 epoch 4 - iter 90/150 - loss 0.03557962 - time (sec): 382.36 - samples/sec: 322.01 - lr: 0.000057 - momentum: 0.000000
2023-07-21 00:31:57,471 epoch 4 - iter 105/150 - loss 0.03457385 - time (sec): 446.70 - samples/sec: 322.57 - lr: 0.000056 - momentum: 0.000000
2023-07-21 00:33:00,902 epoch 4 - iter 120/150 - loss 0.03441180 - time (sec): 510.13 - samples/sec: 322.18 - lr: 0.000055 - momentum: 0.000000
2023-07-21 00:34:01,567 epoch 4 - iter 135/150 - loss 0.03477673 - time (sec): 570.80 - samples/sec: 323.44 - lr: 0.000054 - momentum: 0.000000
2023-07-21 00:35:06,341 epoch 4 - iter 150/150 - loss 0.03500110 - time (sec): 635.57 - samples/sec: 321.86 - lr: 0.000054 - momentum: 0.000000
2023-07-21 00:35:06,342 ----------------------------------------------------------------------------------------------------
2023-07-21 00:35:06,342 EPOCH 4 done: loss 0.0350 - lr: 0.000054
2023-07-21 00:36:07,332 DEV : loss 0.20584701001644135 - f1-score (micro avg)  0.6657
2023-07-21 00:37:11,143 TEST : loss 0.10035499185323715 - f1-score (micro avg)  0.9222
2023-07-21 00:37:11,210 ----------------------------------------------------------------------------------------------------
2023-07-21 00:38:13,197 epoch 5 - iter 15/150 - loss 0.02864328 - time (sec): 61.98 - samples/sec: 336.28 - lr: 0.000053 - momentum: 0.000000
2023-07-21 00:39:14,220 epoch 5 - iter 30/150 - loss 0.02583928 - time (sec): 123.01 - samples/sec: 328.18 - lr: 0.000052 - momentum: 0.000000
2023-07-21 00:40:15,071 epoch 5 - iter 45/150 - loss 0.02480474 - time (sec): 183.86 - samples/sec: 326.09 - lr: 0.000051 - momentum: 0.000000
2023-07-21 00:41:16,871 epoch 5 - iter 60/150 - loss 0.02475963 - time (sec): 245.66 - samples/sec: 329.76 - lr: 0.000050 - momentum: 0.000000
2023-07-21 00:42:22,222 epoch 5 - iter 75/150 - loss 0.02461312 - time (sec): 311.01 - samples/sec: 329.68 - lr: 0.000049 - momentum: 0.000000
2023-07-21 00:43:20,687 epoch 5 - iter 90/150 - loss 0.02484328 - time (sec): 369.47 - samples/sec: 332.89 - lr: 0.000048 - momentum: 0.000000
2023-07-21 00:44:25,072 epoch 5 - iter 105/150 - loss 0.02541662 - time (sec): 433.86 - samples/sec: 330.42 - lr: 0.000047 - momentum: 0.000000
2023-07-21 00:45:23,478 epoch 5 - iter 120/150 - loss 0.02503450 - time (sec): 492.27 - samples/sec: 332.55 - lr: 0.000046 - momentum: 0.000000
2023-07-21 00:46:26,884 epoch 5 - iter 135/150 - loss 0.02461615 - time (sec): 555.67 - samples/sec: 331.43 - lr: 0.000046 - momentum: 0.000000
2023-07-21 00:47:24,297 epoch 5 - iter 150/150 - loss 0.02513479 - time (sec): 613.08 - samples/sec: 333.67 - lr: 0.000045 - momentum: 0.000000
2023-07-21 00:47:24,297 ----------------------------------------------------------------------------------------------------
2023-07-21 00:47:24,297 EPOCH 5 done: loss 0.0251 - lr: 0.000045
2023-07-21 00:48:30,263 DEV : loss 0.18263351917266846 - f1-score (micro avg)  0.7015
2023-07-21 00:49:31,492 TEST : loss 0.08931785076856613 - f1-score (micro avg)  0.9286
2023-07-21 00:49:31,555 ----------------------------------------------------------------------------------------------------
2023-07-21 00:50:33,475 epoch 6 - iter 15/150 - loss 0.01856091 - time (sec): 61.92 - samples/sec: 325.93 - lr: 0.000044 - momentum: 0.000000
2023-07-21 00:51:36,908 epoch 6 - iter 30/150 - loss 0.01913549 - time (sec): 125.35 - samples/sec: 321.53 - lr: 0.000043 - momentum: 0.000000
2023-07-21 00:52:37,592 epoch 6 - iter 45/150 - loss 0.01921958 - time (sec): 186.03 - samples/sec: 324.90 - lr: 0.000042 - momentum: 0.000000
2023-07-21 00:53:42,786 epoch 6 - iter 60/150 - loss 0.01880787 - time (sec): 251.23 - samples/sec: 322.21 - lr: 0.000041 - momentum: 0.000000
2023-07-21 00:54:42,808 epoch 6 - iter 75/150 - loss 0.01802701 - time (sec): 311.25 - samples/sec: 325.82 - lr: 0.000040 - momentum: 0.000000
2023-07-21 00:55:48,118 epoch 6 - iter 90/150 - loss 0.01787144 - time (sec): 376.56 - samples/sec: 325.59 - lr: 0.000039 - momentum: 0.000000
2023-07-21 00:56:50,055 epoch 6 - iter 105/150 - loss 0.01705082 - time (sec): 438.50 - samples/sec: 327.67 - lr: 0.000039 - momentum: 0.000000
2023-07-21 00:57:52,002 epoch 6 - iter 120/150 - loss 0.01714949 - time (sec): 500.45 - samples/sec: 327.35 - lr: 0.000038 - momentum: 0.000000
2023-07-21 00:58:55,924 epoch 6 - iter 135/150 - loss 0.01688889 - time (sec): 564.37 - samples/sec: 325.99 - lr: 0.000037 - momentum: 0.000000
2023-07-21 00:59:59,621 epoch 6 - iter 150/150 - loss 0.01673089 - time (sec): 628.06 - samples/sec: 325.71 - lr: 0.000036 - momentum: 0.000000
2023-07-21 00:59:59,622 ----------------------------------------------------------------------------------------------------
2023-07-21 00:59:59,622 EPOCH 6 done: loss 0.0167 - lr: 0.000036
2023-07-21 01:01:02,731 DEV : loss 0.20263592898845673 - f1-score (micro avg)  0.6953
2023-07-21 01:02:05,784 TEST : loss 0.09313549101352692 - f1-score (micro avg)  0.9312
2023-07-21 01:02:05,848 ----------------------------------------------------------------------------------------------------
2023-07-21 01:03:04,570 epoch 7 - iter 15/150 - loss 0.01409211 - time (sec): 58.72 - samples/sec: 349.12 - lr: 0.000035 - momentum: 0.000000
2023-07-21 01:04:09,987 epoch 7 - iter 30/150 - loss 0.01228070 - time (sec): 124.14 - samples/sec: 332.40 - lr: 0.000034 - momentum: 0.000000
2023-07-21 01:05:12,547 epoch 7 - iter 45/150 - loss 0.01365015 - time (sec): 186.70 - samples/sec: 331.78 - lr: 0.000033 - momentum: 0.000000
2023-07-21 01:06:08,993 epoch 7 - iter 60/150 - loss 0.01367577 - time (sec): 243.14 - samples/sec: 339.25 - lr: 0.000032 - momentum: 0.000000
2023-07-21 01:07:12,474 epoch 7 - iter 75/150 - loss 0.01303323 - time (sec): 306.62 - samples/sec: 335.60 - lr: 0.000031 - momentum: 0.000000
2023-07-21 01:08:14,968 epoch 7 - iter 90/150 - loss 0.01380113 - time (sec): 369.12 - samples/sec: 335.53 - lr: 0.000031 - momentum: 0.000000
2023-07-21 01:09:16,372 epoch 7 - iter 105/150 - loss 0.01405750 - time (sec): 430.52 - samples/sec: 335.11 - lr: 0.000030 - momentum: 0.000000
2023-07-21 01:10:20,227 epoch 7 - iter 120/150 - loss 0.01372114 - time (sec): 494.38 - samples/sec: 332.00 - lr: 0.000029 - momentum: 0.000000
2023-07-21 01:11:22,207 epoch 7 - iter 135/150 - loss 0.01344165 - time (sec): 556.36 - samples/sec: 331.72 - lr: 0.000028 - momentum: 0.000000
2023-07-21 01:12:21,893 epoch 7 - iter 150/150 - loss 0.01316175 - time (sec): 616.04 - samples/sec: 332.07 - lr: 0.000027 - momentum: 0.000000
2023-07-21 01:12:21,893 ----------------------------------------------------------------------------------------------------
2023-07-21 01:12:21,893 EPOCH 7 done: loss 0.0132 - lr: 0.000027
2023-07-21 01:13:22,793 DEV : loss 0.21193578839302063 - f1-score (micro avg)  0.7099
2023-07-21 01:14:26,057 TEST : loss 0.10915275663137436 - f1-score (micro avg)  0.9317
2023-07-21 01:14:26,128 ----------------------------------------------------------------------------------------------------
2023-07-21 01:15:31,820 epoch 8 - iter 15/150 - loss 0.00831993 - time (sec): 65.69 - samples/sec: 311.48 - lr: 0.000026 - momentum: 0.000000
2023-07-21 01:16:38,116 epoch 8 - iter 30/150 - loss 0.01072592 - time (sec): 131.99 - samples/sec: 310.39 - lr: 0.000025 - momentum: 0.000000
2023-07-21 01:17:40,752 epoch 8 - iter 45/150 - loss 0.01090330 - time (sec): 194.62 - samples/sec: 313.52 - lr: 0.000024 - momentum: 0.000000
2023-07-21 01:18:40,934 epoch 8 - iter 60/150 - loss 0.01070054 - time (sec): 254.80 - samples/sec: 322.42 - lr: 0.000024 - momentum: 0.000000
2023-07-21 01:19:46,006 epoch 8 - iter 75/150 - loss 0.01039099 - time (sec): 319.88 - samples/sec: 320.97 - lr: 0.000023 - momentum: 0.000000
2023-07-21 01:20:46,460 epoch 8 - iter 90/150 - loss 0.00978524 - time (sec): 380.33 - samples/sec: 324.02 - lr: 0.000022 - momentum: 0.000000
2023-07-21 01:21:51,231 epoch 8 - iter 105/150 - loss 0.00951283 - time (sec): 445.10 - samples/sec: 322.14 - lr: 0.000021 - momentum: 0.000000
2023-07-21 01:22:56,096 epoch 8 - iter 120/150 - loss 0.00944920 - time (sec): 509.97 - samples/sec: 322.20 - lr: 0.000020 - momentum: 0.000000
2023-07-21 01:23:56,789 epoch 8 - iter 135/150 - loss 0.00975440 - time (sec): 570.66 - samples/sec: 323.45 - lr: 0.000019 - momentum: 0.000000
2023-07-21 01:25:02,362 epoch 8 - iter 150/150 - loss 0.00956039 - time (sec): 636.23 - samples/sec: 321.53 - lr: 0.000018 - momentum: 0.000000
2023-07-21 01:25:02,362 ----------------------------------------------------------------------------------------------------
2023-07-21 01:25:02,362 EPOCH 8 done: loss 0.0096 - lr: 0.000018
2023-07-21 01:26:04,514 DEV : loss 0.25966161489486694 - f1-score (micro avg)  0.6784
2023-07-21 01:27:13,677 TEST : loss 0.1106371283531189 - f1-score (micro avg)  0.9329
2023-07-21 01:27:13,760 ----------------------------------------------------------------------------------------------------
2023-07-21 01:28:18,255 epoch 9 - iter 15/150 - loss 0.00456079 - time (sec): 64.49 - samples/sec: 333.88 - lr: 0.000017 - momentum: 0.000000
2023-07-21 01:29:20,442 epoch 9 - iter 30/150 - loss 0.00424224 - time (sec): 126.68 - samples/sec: 333.28 - lr: 0.000016 - momentum: 0.000000
2023-07-21 01:30:27,585 epoch 9 - iter 45/150 - loss 0.00461148 - time (sec): 193.82 - samples/sec: 319.38 - lr: 0.000016 - momentum: 0.000000
2023-07-21 01:31:29,765 epoch 9 - iter 60/150 - loss 0.00585505 - time (sec): 256.00 - samples/sec: 320.64 - lr: 0.000015 - momentum: 0.000000
2023-07-21 01:32:29,777 epoch 9 - iter 75/150 - loss 0.00581227 - time (sec): 316.01 - samples/sec: 324.58 - lr: 0.000014 - momentum: 0.000000
2023-07-21 01:33:36,248 epoch 9 - iter 90/150 - loss 0.00591621 - time (sec): 382.49 - samples/sec: 320.93 - lr: 0.000013 - momentum: 0.000000
2023-07-21 01:34:39,439 epoch 9 - iter 105/150 - loss 0.00659592 - time (sec): 445.68 - samples/sec: 320.79 - lr: 0.000012 - momentum: 0.000000
2023-07-21 01:35:39,358 epoch 9 - iter 120/150 - loss 0.00635508 - time (sec): 505.60 - samples/sec: 323.12 - lr: 0.000011 - momentum: 0.000000
2023-07-21 01:36:45,370 epoch 9 - iter 135/150 - loss 0.00653957 - time (sec): 571.61 - samples/sec: 321.38 - lr: 0.000010 - momentum: 0.000000
2023-07-21 01:37:46,536 epoch 9 - iter 150/150 - loss 0.00642844 - time (sec): 632.77 - samples/sec: 323.29 - lr: 0.000009 - momentum: 0.000000
2023-07-21 01:37:46,536 ----------------------------------------------------------------------------------------------------
2023-07-21 01:37:46,537 EPOCH 9 done: loss 0.0064 - lr: 0.000009
2023-07-21 01:38:50,438 DEV : loss 0.242453932762146 - f1-score (micro avg)  0.7054
2023-07-21 01:39:55,485 TEST : loss 0.11690268665552139 - f1-score (micro avg)  0.9347
2023-07-21 01:39:55,536 ----------------------------------------------------------------------------------------------------
2023-07-21 01:40:58,850 epoch 10 - iter 15/150 - loss 0.00468988 - time (sec): 63.31 - samples/sec: 307.08 - lr: 0.000008 - momentum: 0.000000
2023-07-21 01:41:56,114 epoch 10 - iter 30/150 - loss 0.00449127 - time (sec): 120.58 - samples/sec: 329.26 - lr: 0.000008 - momentum: 0.000000
2023-07-21 01:43:03,037 epoch 10 - iter 45/150 - loss 0.00503680 - time (sec): 187.50 - samples/sec: 322.15 - lr: 0.000007 - momentum: 0.000000
2023-07-21 01:44:08,485 epoch 10 - iter 60/150 - loss 0.00504646 - time (sec): 252.95 - samples/sec: 319.64 - lr: 0.000006 - momentum: 0.000000
2023-07-21 01:45:11,831 epoch 10 - iter 75/150 - loss 0.00453960 - time (sec): 316.29 - samples/sec: 320.19 - lr: 0.000005 - momentum: 0.000000
2023-07-21 01:46:19,071 epoch 10 - iter 90/150 - loss 0.00505148 - time (sec): 383.53 - samples/sec: 317.45 - lr: 0.000004 - momentum: 0.000000
2023-07-21 01:47:21,768 epoch 10 - iter 105/150 - loss 0.00488328 - time (sec): 446.23 - samples/sec: 320.11 - lr: 0.000003 - momentum: 0.000000
2023-07-21 01:48:28,071 epoch 10 - iter 120/150 - loss 0.00459377 - time (sec): 512.53 - samples/sec: 319.32 - lr: 0.000002 - momentum: 0.000000
2023-07-21 01:49:36,569 epoch 10 - iter 135/150 - loss 0.00472315 - time (sec): 581.03 - samples/sec: 316.41 - lr: 0.000001 - momentum: 0.000000
2023-07-21 01:50:40,112 epoch 10 - iter 150/150 - loss 0.00444297 - time (sec): 644.57 - samples/sec: 317.37 - lr: 0.000001 - momentum: 0.000000
2023-07-21 01:50:40,112 ----------------------------------------------------------------------------------------------------
2023-07-21 01:50:40,112 EPOCH 10 done: loss 0.0044 - lr: 0.000001
2023-07-21 01:51:43,105 DEV : loss 0.23815591633319855 - f1-score (micro avg)  0.7322
2023-07-21 01:52:50,723 TEST : loss 0.12346852570772171 - f1-score (micro avg)  0.9362
2023-07-21 01:53:01,517 ----------------------------------------------------------------------------------------------------
2023-07-21 01:53:01,519 Testing using last state of model ...
2023-07-21 01:54:09,044 
Results:
- F-score (micro) 0.9362
- F-score (macro) 0.9222
- Accuracy 0.9029

By class:
              precision    recall  f1-score   support

         ORG     0.9185    0.9368    0.9276      1661
         LOC     0.9449    0.9454    0.9452      1668
         PER     0.9832    0.9796    0.9814      1617
        MISC     0.8107    0.8604    0.8348       702

   micro avg     0.9304    0.9421    0.9362      5648
   macro avg     0.9143    0.9306    0.9222      5648
weighted avg     0.9314    0.9421    0.9367      5648

2023-07-21 01:54:09,045 ----------------------------------------------------------------------------------------------------
