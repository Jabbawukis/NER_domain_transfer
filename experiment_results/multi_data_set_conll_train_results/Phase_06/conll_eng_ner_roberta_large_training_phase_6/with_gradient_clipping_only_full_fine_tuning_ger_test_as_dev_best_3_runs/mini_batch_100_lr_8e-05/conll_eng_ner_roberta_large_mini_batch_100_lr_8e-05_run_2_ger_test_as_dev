2023-07-20 21:43:14,907 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,911 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-20 21:43:14,911 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,911 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-20 21:43:14,911 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,911 Train:  14987 sentences
2023-07-20 21:43:14,911         (train_with_dev=False, train_with_test=False)
2023-07-20 21:43:14,911 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,911 Training Params:
2023-07-20 21:43:14,911  - learning_rate: "8e-05" 
2023-07-20 21:43:14,912  - mini_batch_size: "100"
2023-07-20 21:43:14,912  - max_epochs: "10"
2023-07-20 21:43:14,912  - shuffle: "True"
2023-07-20 21:43:14,912 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,912 Plugins:
2023-07-20 21:43:14,912  - LinearScheduler | warmup_fraction: '0.1'
2023-07-20 21:43:14,912 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,912 Final evaluation on model after last epoch (final-model.pt)
2023-07-20 21:43:14,912  - metric: "('micro avg', 'f1-score')"
2023-07-20 21:43:14,912 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,912 Computation:
2023-07-20 21:43:14,912  - compute on device: cuda:1
2023-07-20 21:43:14,912  - embedding storage: none
2023-07-20 21:43:14,912 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,912 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_8e-05_run_2_ger_test_as_dev"
2023-07-20 21:43:14,912 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,913 Enabled gradient clipping
2023-07-20 21:43:14,913 ----------------------------------------------------------------------------------------------------
2023-07-20 21:43:14,913 ----------------------------------------------------------------------------------------------------
2023-07-20 21:44:13,995 epoch 1 - iter 15/150 - loss 3.41969351 - time (sec): 59.08 - samples/sec: 344.13 - lr: 0.000007 - momentum: 0.000000
2023-07-20 21:45:16,712 epoch 1 - iter 30/150 - loss 2.49378656 - time (sec): 121.80 - samples/sec: 339.57 - lr: 0.000015 - momentum: 0.000000
2023-07-20 21:46:19,136 epoch 1 - iter 45/150 - loss 1.96840928 - time (sec): 184.22 - samples/sec: 330.54 - lr: 0.000023 - momentum: 0.000000
2023-07-20 21:47:19,223 epoch 1 - iter 60/150 - loss 1.60717149 - time (sec): 244.31 - samples/sec: 333.91 - lr: 0.000031 - momentum: 0.000000
2023-07-20 21:48:21,250 epoch 1 - iter 75/150 - loss 1.35867901 - time (sec): 306.34 - samples/sec: 333.29 - lr: 0.000039 - momentum: 0.000000
2023-07-20 21:49:23,520 epoch 1 - iter 90/150 - loss 1.17777024 - time (sec): 368.60 - samples/sec: 332.36 - lr: 0.000047 - momentum: 0.000000
2023-07-20 21:50:27,286 epoch 1 - iter 105/150 - loss 1.04279113 - time (sec): 432.37 - samples/sec: 329.71 - lr: 0.000055 - momentum: 0.000000
2023-07-20 21:51:26,737 epoch 1 - iter 120/150 - loss 0.93010535 - time (sec): 491.82 - samples/sec: 331.19 - lr: 0.000063 - momentum: 0.000000
2023-07-20 21:52:27,614 epoch 1 - iter 135/150 - loss 0.84110612 - time (sec): 552.70 - samples/sec: 331.89 - lr: 0.000071 - momentum: 0.000000
2023-07-20 21:53:29,471 epoch 1 - iter 150/150 - loss 0.76463763 - time (sec): 614.56 - samples/sec: 332.87 - lr: 0.000079 - momentum: 0.000000
2023-07-20 21:53:29,471 ----------------------------------------------------------------------------------------------------
2023-07-20 21:53:29,471 EPOCH 1 done: loss 0.7646 - lr: 0.000079
2023-07-20 21:54:26,408 DEV : loss 0.2693959176540375 - f1-score (micro avg)  0.6173
2023-07-20 21:55:23,135 TEST : loss 0.13600848615169525 - f1-score (micro avg)  0.8624
2023-07-20 21:55:23,183 ----------------------------------------------------------------------------------------------------
2023-07-20 21:56:24,899 epoch 2 - iter 15/150 - loss 0.10375431 - time (sec): 61.71 - samples/sec: 327.19 - lr: 0.000079 - momentum: 0.000000
2023-07-20 21:57:25,956 epoch 2 - iter 30/150 - loss 0.09603371 - time (sec): 122.77 - samples/sec: 327.16 - lr: 0.000078 - momentum: 0.000000
2023-07-20 21:58:25,157 epoch 2 - iter 45/150 - loss 0.09229224 - time (sec): 181.97 - samples/sec: 333.71 - lr: 0.000077 - momentum: 0.000000
2023-07-20 21:59:25,035 epoch 2 - iter 60/150 - loss 0.09045415 - time (sec): 241.85 - samples/sec: 336.50 - lr: 0.000077 - momentum: 0.000000
2023-07-20 22:00:26,928 epoch 2 - iter 75/150 - loss 0.08640232 - time (sec): 303.74 - samples/sec: 336.48 - lr: 0.000076 - momentum: 0.000000
2023-07-20 22:01:30,698 epoch 2 - iter 90/150 - loss 0.08535243 - time (sec): 367.51 - samples/sec: 334.93 - lr: 0.000075 - momentum: 0.000000
2023-07-20 22:02:29,472 epoch 2 - iter 105/150 - loss 0.08367014 - time (sec): 426.29 - samples/sec: 334.77 - lr: 0.000074 - momentum: 0.000000
2023-07-20 22:03:30,810 epoch 2 - iter 120/150 - loss 0.08220029 - time (sec): 487.63 - samples/sec: 334.65 - lr: 0.000073 - momentum: 0.000000
2023-07-20 22:04:34,922 epoch 2 - iter 135/150 - loss 0.08034587 - time (sec): 551.74 - samples/sec: 333.04 - lr: 0.000072 - momentum: 0.000000
2023-07-20 22:05:34,350 epoch 2 - iter 150/150 - loss 0.07943588 - time (sec): 611.17 - samples/sec: 334.72 - lr: 0.000071 - momentum: 0.000000
2023-07-20 22:05:34,350 ----------------------------------------------------------------------------------------------------
2023-07-20 22:05:34,350 EPOCH 2 done: loss 0.0794 - lr: 0.000071
2023-07-20 22:06:31,173 DEV : loss 0.19394062459468842 - f1-score (micro avg)  0.6658
2023-07-20 22:07:30,119 TEST : loss 0.09566272795200348 - f1-score (micro avg)  0.9119
2023-07-20 22:07:30,189 ----------------------------------------------------------------------------------------------------
2023-07-20 22:08:34,089 epoch 3 - iter 15/150 - loss 0.04490691 - time (sec): 63.90 - samples/sec: 321.89 - lr: 0.000070 - momentum: 0.000000
2023-07-20 22:09:37,494 epoch 3 - iter 30/150 - loss 0.04989890 - time (sec): 127.30 - samples/sec: 320.91 - lr: 0.000069 - momentum: 0.000000
2023-07-20 22:10:34,369 epoch 3 - iter 45/150 - loss 0.04895109 - time (sec): 184.18 - samples/sec: 335.36 - lr: 0.000069 - momentum: 0.000000
2023-07-20 22:11:36,368 epoch 3 - iter 60/150 - loss 0.05265876 - time (sec): 246.18 - samples/sec: 332.44 - lr: 0.000068 - momentum: 0.000000
2023-07-20 22:12:40,443 epoch 3 - iter 75/150 - loss 0.05350236 - time (sec): 310.25 - samples/sec: 328.07 - lr: 0.000067 - momentum: 0.000000
2023-07-20 22:13:41,514 epoch 3 - iter 90/150 - loss 0.05360092 - time (sec): 371.32 - samples/sec: 330.24 - lr: 0.000066 - momentum: 0.000000
2023-07-20 22:14:41,441 epoch 3 - iter 105/150 - loss 0.05216278 - time (sec): 431.25 - samples/sec: 331.37 - lr: 0.000065 - momentum: 0.000000
2023-07-20 22:15:44,151 epoch 3 - iter 120/150 - loss 0.05228334 - time (sec): 493.96 - samples/sec: 329.80 - lr: 0.000064 - momentum: 0.000000
2023-07-20 22:16:42,374 epoch 3 - iter 135/150 - loss 0.05276207 - time (sec): 552.18 - samples/sec: 331.84 - lr: 0.000063 - momentum: 0.000000
2023-07-20 22:17:42,132 epoch 3 - iter 150/150 - loss 0.05188012 - time (sec): 611.94 - samples/sec: 334.29 - lr: 0.000062 - momentum: 0.000000
2023-07-20 22:17:42,133 ----------------------------------------------------------------------------------------------------
2023-07-20 22:17:42,133 EPOCH 3 done: loss 0.0519 - lr: 0.000062
2023-07-20 22:18:40,672 DEV : loss 0.18051637709140778 - f1-score (micro avg)  0.6723
2023-07-20 22:19:38,090 TEST : loss 0.08831361681222916 - f1-score (micro avg)  0.917
2023-07-20 22:19:38,139 ----------------------------------------------------------------------------------------------------
2023-07-20 22:20:38,312 epoch 4 - iter 15/150 - loss 0.03942727 - time (sec): 60.17 - samples/sec: 338.62 - lr: 0.000062 - momentum: 0.000000
2023-07-20 22:21:35,958 epoch 4 - iter 30/150 - loss 0.04007833 - time (sec): 117.82 - samples/sec: 346.99 - lr: 0.000061 - momentum: 0.000000
2023-07-20 22:22:41,818 epoch 4 - iter 45/150 - loss 0.03976590 - time (sec): 183.68 - samples/sec: 336.88 - lr: 0.000060 - momentum: 0.000000
2023-07-20 22:23:42,537 epoch 4 - iter 60/150 - loss 0.03856292 - time (sec): 244.40 - samples/sec: 334.77 - lr: 0.000059 - momentum: 0.000000
2023-07-20 22:24:43,520 epoch 4 - iter 75/150 - loss 0.03786654 - time (sec): 305.38 - samples/sec: 335.07 - lr: 0.000058 - momentum: 0.000000
2023-07-20 22:25:47,561 epoch 4 - iter 90/150 - loss 0.03771167 - time (sec): 369.42 - samples/sec: 332.41 - lr: 0.000057 - momentum: 0.000000
2023-07-20 22:26:49,083 epoch 4 - iter 105/150 - loss 0.03716913 - time (sec): 430.94 - samples/sec: 333.12 - lr: 0.000056 - momentum: 0.000000
2023-07-20 22:27:51,033 epoch 4 - iter 120/150 - loss 0.03652989 - time (sec): 492.89 - samples/sec: 332.43 - lr: 0.000055 - momentum: 0.000000
2023-07-20 22:28:51,147 epoch 4 - iter 135/150 - loss 0.03655004 - time (sec): 553.01 - samples/sec: 333.49 - lr: 0.000054 - momentum: 0.000000
2023-07-20 22:29:53,230 epoch 4 - iter 150/150 - loss 0.03620214 - time (sec): 615.09 - samples/sec: 332.58 - lr: 0.000054 - momentum: 0.000000
2023-07-20 22:29:53,231 ----------------------------------------------------------------------------------------------------
2023-07-20 22:29:53,231 EPOCH 4 done: loss 0.0362 - lr: 0.000054
2023-07-20 22:30:51,358 DEV : loss 0.17894059419631958 - f1-score (micro avg)  0.7089
2023-07-20 22:31:45,851 TEST : loss 0.09442368149757385 - f1-score (micro avg)  0.9251
2023-07-20 22:31:45,905 ----------------------------------------------------------------------------------------------------
2023-07-20 22:32:48,673 epoch 5 - iter 15/150 - loss 0.02174824 - time (sec): 62.77 - samples/sec: 331.50 - lr: 0.000053 - momentum: 0.000000
2023-07-20 22:33:51,575 epoch 5 - iter 30/150 - loss 0.02517369 - time (sec): 125.67 - samples/sec: 321.75 - lr: 0.000052 - momentum: 0.000000
2023-07-20 22:34:52,310 epoch 5 - iter 45/150 - loss 0.02610943 - time (sec): 186.40 - samples/sec: 326.01 - lr: 0.000051 - momentum: 0.000000
2023-07-20 22:35:52,230 epoch 5 - iter 60/150 - loss 0.02558178 - time (sec): 246.32 - samples/sec: 332.19 - lr: 0.000050 - momentum: 0.000000
2023-07-20 22:36:54,098 epoch 5 - iter 75/150 - loss 0.02595421 - time (sec): 308.19 - samples/sec: 330.17 - lr: 0.000049 - momentum: 0.000000
2023-07-20 22:37:54,282 epoch 5 - iter 90/150 - loss 0.02526285 - time (sec): 368.38 - samples/sec: 332.57 - lr: 0.000048 - momentum: 0.000000
2023-07-20 22:38:56,660 epoch 5 - iter 105/150 - loss 0.02479991 - time (sec): 430.75 - samples/sec: 333.52 - lr: 0.000047 - momentum: 0.000000
2023-07-20 22:39:59,009 epoch 5 - iter 120/150 - loss 0.02487736 - time (sec): 493.10 - samples/sec: 331.66 - lr: 0.000046 - momentum: 0.000000
2023-07-20 22:41:02,583 epoch 5 - iter 135/150 - loss 0.02967394 - time (sec): 556.68 - samples/sec: 330.66 - lr: 0.000046 - momentum: 0.000000
2023-07-20 22:42:04,624 epoch 5 - iter 150/150 - loss 0.03344567 - time (sec): 618.72 - samples/sec: 330.63 - lr: 0.000045 - momentum: 0.000000
2023-07-20 22:42:04,624 ----------------------------------------------------------------------------------------------------
2023-07-20 22:42:04,624 EPOCH 5 done: loss 0.0334 - lr: 0.000045
2023-07-20 22:43:01,794 DEV : loss 0.18925529718399048 - f1-score (micro avg)  0.6797
2023-07-20 22:43:59,566 TEST : loss 0.08449307829141617 - f1-score (micro avg)  0.927
2023-07-20 22:43:59,614 ----------------------------------------------------------------------------------------------------
2023-07-20 22:44:59,937 epoch 6 - iter 15/150 - loss 0.02292239 - time (sec): 60.32 - samples/sec: 348.62 - lr: 0.000044 - momentum: 0.000000
2023-07-20 22:46:00,599 epoch 6 - iter 30/150 - loss 0.01978103 - time (sec): 120.98 - samples/sec: 348.63 - lr: 0.000043 - momentum: 0.000000
2023-07-20 22:47:04,425 epoch 6 - iter 45/150 - loss 0.01941070 - time (sec): 184.81 - samples/sec: 342.41 - lr: 0.000042 - momentum: 0.000000
2023-07-20 22:48:07,076 epoch 6 - iter 60/150 - loss 0.01957227 - time (sec): 247.46 - samples/sec: 337.30 - lr: 0.000041 - momentum: 0.000000
2023-07-20 22:49:08,726 epoch 6 - iter 75/150 - loss 0.01942190 - time (sec): 309.11 - samples/sec: 334.93 - lr: 0.000040 - momentum: 0.000000
2023-07-20 22:50:09,416 epoch 6 - iter 90/150 - loss 0.01916872 - time (sec): 369.80 - samples/sec: 332.04 - lr: 0.000039 - momentum: 0.000000
2023-07-20 22:51:12,695 epoch 6 - iter 105/150 - loss 0.01892582 - time (sec): 433.08 - samples/sec: 331.57 - lr: 0.000039 - momentum: 0.000000
2023-07-20 22:52:13,142 epoch 6 - iter 120/150 - loss 0.01878199 - time (sec): 493.52 - samples/sec: 332.71 - lr: 0.000038 - momentum: 0.000000
2023-07-20 22:53:12,345 epoch 6 - iter 135/150 - loss 0.01866220 - time (sec): 552.73 - samples/sec: 334.08 - lr: 0.000037 - momentum: 0.000000
2023-07-20 22:54:12,774 epoch 6 - iter 150/150 - loss 0.01856439 - time (sec): 613.15 - samples/sec: 333.63 - lr: 0.000036 - momentum: 0.000000
2023-07-20 22:54:12,774 ----------------------------------------------------------------------------------------------------
2023-07-20 22:54:12,774 EPOCH 6 done: loss 0.0186 - lr: 0.000036
2023-07-20 22:55:13,894 DEV : loss 0.1826009303331375 - f1-score (micro avg)  0.694
2023-07-20 22:56:07,361 TEST : loss 0.09026329964399338 - f1-score (micro avg)  0.9275
2023-07-20 22:56:07,418 ----------------------------------------------------------------------------------------------------
2023-07-20 22:57:09,743 epoch 7 - iter 15/150 - loss 0.01156220 - time (sec): 62.32 - samples/sec: 340.95 - lr: 0.000035 - momentum: 0.000000
2023-07-20 22:58:10,926 epoch 7 - iter 30/150 - loss 0.01547615 - time (sec): 123.51 - samples/sec: 333.53 - lr: 0.000034 - momentum: 0.000000
2023-07-20 22:59:13,053 epoch 7 - iter 45/150 - loss 0.01449524 - time (sec): 185.63 - samples/sec: 333.97 - lr: 0.000033 - momentum: 0.000000
2023-07-20 23:00:16,130 epoch 7 - iter 60/150 - loss 0.01425120 - time (sec): 248.71 - samples/sec: 331.78 - lr: 0.000032 - momentum: 0.000000
2023-07-20 23:01:17,066 epoch 7 - iter 75/150 - loss 0.01433658 - time (sec): 309.65 - samples/sec: 332.04 - lr: 0.000031 - momentum: 0.000000
2023-07-20 23:02:20,298 epoch 7 - iter 90/150 - loss 0.01416701 - time (sec): 372.88 - samples/sec: 330.76 - lr: 0.000031 - momentum: 0.000000
2023-07-20 23:03:23,728 epoch 7 - iter 105/150 - loss 0.01382976 - time (sec): 436.31 - samples/sec: 329.83 - lr: 0.000030 - momentum: 0.000000
2023-07-20 23:04:23,820 epoch 7 - iter 120/150 - loss 0.01445825 - time (sec): 496.40 - samples/sec: 330.72 - lr: 0.000029 - momentum: 0.000000
2023-07-20 23:05:28,205 epoch 7 - iter 135/150 - loss 0.01425825 - time (sec): 560.79 - samples/sec: 329.01 - lr: 0.000028 - momentum: 0.000000
2023-07-20 23:06:32,458 epoch 7 - iter 150/150 - loss 0.01411087 - time (sec): 625.04 - samples/sec: 327.29 - lr: 0.000027 - momentum: 0.000000
2023-07-20 23:06:32,459 ----------------------------------------------------------------------------------------------------
2023-07-20 23:06:32,459 EPOCH 7 done: loss 0.0141 - lr: 0.000027
2023-07-20 23:07:38,810 DEV : loss 0.17882297933101654 - f1-score (micro avg)  0.6994
2023-07-20 23:08:36,688 TEST : loss 0.10162442922592163 - f1-score (micro avg)  0.9247
2023-07-20 23:08:36,737 ----------------------------------------------------------------------------------------------------
2023-07-20 23:09:39,662 epoch 8 - iter 15/150 - loss 0.00952951 - time (sec): 62.92 - samples/sec: 327.68 - lr: 0.000026 - momentum: 0.000000
2023-07-20 23:10:42,474 epoch 8 - iter 30/150 - loss 0.01054903 - time (sec): 125.73 - samples/sec: 326.58 - lr: 0.000025 - momentum: 0.000000
2023-07-20 23:11:43,853 epoch 8 - iter 45/150 - loss 0.01075664 - time (sec): 187.11 - samples/sec: 328.22 - lr: 0.000024 - momentum: 0.000000
2023-07-20 23:12:44,807 epoch 8 - iter 60/150 - loss 0.01080489 - time (sec): 248.07 - samples/sec: 327.12 - lr: 0.000024 - momentum: 0.000000
2023-07-20 23:13:51,171 epoch 8 - iter 75/150 - loss 0.01082472 - time (sec): 314.43 - samples/sec: 323.57 - lr: 0.000023 - momentum: 0.000000
2023-07-20 23:14:54,801 epoch 8 - iter 90/150 - loss 0.01067595 - time (sec): 378.06 - samples/sec: 321.34 - lr: 0.000022 - momentum: 0.000000
2023-07-20 23:15:58,393 epoch 8 - iter 105/150 - loss 0.01063461 - time (sec): 441.65 - samples/sec: 322.85 - lr: 0.000021 - momentum: 0.000000
2023-07-20 23:17:02,594 epoch 8 - iter 120/150 - loss 0.01030981 - time (sec): 505.86 - samples/sec: 323.41 - lr: 0.000020 - momentum: 0.000000
2023-07-20 23:18:02,132 epoch 8 - iter 135/150 - loss 0.01061109 - time (sec): 565.39 - samples/sec: 325.76 - lr: 0.000019 - momentum: 0.000000
2023-07-20 23:19:07,802 epoch 8 - iter 150/150 - loss 0.01017797 - time (sec): 631.06 - samples/sec: 324.16 - lr: 0.000018 - momentum: 0.000000
2023-07-20 23:19:07,803 ----------------------------------------------------------------------------------------------------
2023-07-20 23:19:07,803 EPOCH 8 done: loss 0.0102 - lr: 0.000018
2023-07-20 23:20:06,883 DEV : loss 0.2190442830324173 - f1-score (micro avg)  0.7054
2023-07-20 23:21:07,406 TEST : loss 0.11226185411214828 - f1-score (micro avg)  0.9255
2023-07-20 23:21:07,469 ----------------------------------------------------------------------------------------------------
2023-07-20 23:22:07,607 epoch 9 - iter 15/150 - loss 0.00532279 - time (sec): 60.14 - samples/sec: 343.19 - lr: 0.000017 - momentum: 0.000000
2023-07-20 23:23:10,307 epoch 9 - iter 30/150 - loss 0.00679979 - time (sec): 122.84 - samples/sec: 327.09 - lr: 0.000016 - momentum: 0.000000
2023-07-20 23:24:12,513 epoch 9 - iter 45/150 - loss 0.00684711 - time (sec): 185.04 - samples/sec: 326.49 - lr: 0.000016 - momentum: 0.000000
2023-07-20 23:25:09,727 epoch 9 - iter 60/150 - loss 0.00698333 - time (sec): 242.26 - samples/sec: 333.78 - lr: 0.000015 - momentum: 0.000000
2023-07-20 23:26:11,989 epoch 9 - iter 75/150 - loss 0.00635494 - time (sec): 304.52 - samples/sec: 331.48 - lr: 0.000014 - momentum: 0.000000
2023-07-20 23:27:09,408 epoch 9 - iter 90/150 - loss 0.00621080 - time (sec): 361.94 - samples/sec: 337.04 - lr: 0.000013 - momentum: 0.000000
2023-07-20 23:28:13,672 epoch 9 - iter 105/150 - loss 0.00593047 - time (sec): 426.20 - samples/sec: 334.10 - lr: 0.000012 - momentum: 0.000000
2023-07-20 23:29:15,682 epoch 9 - iter 120/150 - loss 0.00595916 - time (sec): 488.21 - samples/sec: 333.88 - lr: 0.000011 - momentum: 0.000000
2023-07-20 23:30:17,209 epoch 9 - iter 135/150 - loss 0.00626122 - time (sec): 549.74 - samples/sec: 335.44 - lr: 0.000010 - momentum: 0.000000
2023-07-20 23:31:17,129 epoch 9 - iter 150/150 - loss 0.00660206 - time (sec): 609.66 - samples/sec: 335.54 - lr: 0.000009 - momentum: 0.000000
2023-07-20 23:31:17,130 ----------------------------------------------------------------------------------------------------
2023-07-20 23:31:17,130 EPOCH 9 done: loss 0.0066 - lr: 0.000009
2023-07-20 23:32:19,632 DEV : loss 0.21297422051429749 - f1-score (micro avg)  0.7444
2023-07-20 23:33:24,754 TEST : loss 0.11709372699260712 - f1-score (micro avg)  0.9322
2023-07-20 23:33:24,803 ----------------------------------------------------------------------------------------------------
2023-07-20 23:34:27,369 epoch 10 - iter 15/150 - loss 0.00425757 - time (sec): 62.56 - samples/sec: 321.73 - lr: 0.000008 - momentum: 0.000000
2023-07-20 23:35:33,170 epoch 10 - iter 30/150 - loss 0.00363646 - time (sec): 128.37 - samples/sec: 314.90 - lr: 0.000008 - momentum: 0.000000
2023-07-20 23:36:36,339 epoch 10 - iter 45/150 - loss 0.00419934 - time (sec): 191.53 - samples/sec: 321.79 - lr: 0.000007 - momentum: 0.000000
2023-07-20 23:37:40,522 epoch 10 - iter 60/150 - loss 0.00439053 - time (sec): 255.72 - samples/sec: 320.18 - lr: 0.000006 - momentum: 0.000000
2023-07-20 23:38:43,521 epoch 10 - iter 75/150 - loss 0.00443530 - time (sec): 318.72 - samples/sec: 323.84 - lr: 0.000005 - momentum: 0.000000
2023-07-20 23:39:42,209 epoch 10 - iter 90/150 - loss 0.00438784 - time (sec): 377.40 - samples/sec: 328.10 - lr: 0.000004 - momentum: 0.000000
2023-07-20 23:40:47,471 epoch 10 - iter 105/150 - loss 0.00459706 - time (sec): 442.67 - samples/sec: 325.86 - lr: 0.000003 - momentum: 0.000000
2023-07-20 23:41:47,020 epoch 10 - iter 120/150 - loss 0.00449902 - time (sec): 502.22 - samples/sec: 326.73 - lr: 0.000002 - momentum: 0.000000
2023-07-20 23:42:54,566 epoch 10 - iter 135/150 - loss 0.00454618 - time (sec): 569.76 - samples/sec: 323.62 - lr: 0.000001 - momentum: 0.000000
2023-07-20 23:43:56,107 epoch 10 - iter 150/150 - loss 0.00462459 - time (sec): 631.30 - samples/sec: 324.04 - lr: 0.000001 - momentum: 0.000000
2023-07-20 23:43:56,108 ----------------------------------------------------------------------------------------------------
2023-07-20 23:43:56,108 EPOCH 10 done: loss 0.0046 - lr: 0.000001
2023-07-20 23:44:59,121 DEV : loss 0.27809470891952515 - f1-score (micro avg)  0.7038
2023-07-20 23:45:59,872 TEST : loss 0.13068468868732452 - f1-score (micro avg)  0.9309
2023-07-20 23:46:10,989 ----------------------------------------------------------------------------------------------------
2023-07-20 23:46:10,994 Testing using last state of model ...
2023-07-20 23:47:08,664 
Results:
- F-score (micro) 0.9309
- F-score (macro) 0.9161
- Accuracy 0.898

By class:
              precision    recall  f1-score   support

         ORG     0.9087    0.9284    0.9184      1661
         LOC     0.9458    0.9424    0.9441      1668
         PER     0.9838    0.9746    0.9792      1617
        MISC     0.7918    0.8561    0.8227       702

   micro avg     0.9250    0.9368    0.9309      5648
   macro avg     0.9075    0.9254    0.9161      5648
weighted avg     0.9266    0.9368    0.9315      5648

2023-07-20 23:47:08,665 ----------------------------------------------------------------------------------------------------
