2023-07-20 19:39:29,511 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,512 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-20 19:39:29,512 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,512 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-20 19:39:29,512 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,512 Train:  14987 sentences
2023-07-20 19:39:29,512         (train_with_dev=False, train_with_test=False)
2023-07-20 19:39:29,512 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,512 Training Params:
2023-07-20 19:39:29,512  - learning_rate: "8e-05" 
2023-07-20 19:39:29,512  - mini_batch_size: "100"
2023-07-20 19:39:29,512  - max_epochs: "10"
2023-07-20 19:39:29,512  - shuffle: "True"
2023-07-20 19:39:29,513 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,513 Plugins:
2023-07-20 19:39:29,513  - LinearScheduler | warmup_fraction: '0.1'
2023-07-20 19:39:29,513 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,513 Final evaluation on model after last epoch (final-model.pt)
2023-07-20 19:39:29,513  - metric: "('micro avg', 'f1-score')"
2023-07-20 19:39:29,513 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,513 Computation:
2023-07-20 19:39:29,513  - compute on device: cuda:1
2023-07-20 19:39:29,513  - embedding storage: none
2023-07-20 19:39:29,513 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,513 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_8e-05_run_1_ger_test_as_dev"
2023-07-20 19:39:29,513 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,513 Enabled gradient clipping
2023-07-20 19:39:29,513 ----------------------------------------------------------------------------------------------------
2023-07-20 19:39:29,513 ----------------------------------------------------------------------------------------------------
2023-07-20 19:40:31,531 epoch 1 - iter 15/150 - loss 2.39296157 - time (sec): 62.02 - samples/sec: 345.65 - lr: 0.000007 - momentum: 0.000000
2023-07-20 19:41:32,208 epoch 1 - iter 30/150 - loss 1.77057344 - time (sec): 122.69 - samples/sec: 336.63 - lr: 0.000015 - momentum: 0.000000
2023-07-20 19:42:36,404 epoch 1 - iter 45/150 - loss 1.36999298 - time (sec): 186.89 - samples/sec: 330.10 - lr: 0.000023 - momentum: 0.000000
2023-07-20 19:43:40,018 epoch 1 - iter 60/150 - loss 1.12645214 - time (sec): 250.50 - samples/sec: 327.00 - lr: 0.000031 - momentum: 0.000000
2023-07-20 19:44:39,638 epoch 1 - iter 75/150 - loss 0.95507153 - time (sec): 310.12 - samples/sec: 327.61 - lr: 0.000039 - momentum: 0.000000
2023-07-20 19:45:43,567 epoch 1 - iter 90/150 - loss 0.81956675 - time (sec): 374.05 - samples/sec: 328.51 - lr: 0.000047 - momentum: 0.000000
2023-07-20 19:46:44,980 epoch 1 - iter 105/150 - loss 0.72307657 - time (sec): 435.47 - samples/sec: 327.79 - lr: 0.000055 - momentum: 0.000000
2023-07-20 19:47:44,456 epoch 1 - iter 120/150 - loss 0.64636215 - time (sec): 494.94 - samples/sec: 329.92 - lr: 0.000063 - momentum: 0.000000
2023-07-20 19:48:44,699 epoch 1 - iter 135/150 - loss 0.58794712 - time (sec): 555.18 - samples/sec: 331.42 - lr: 0.000071 - momentum: 0.000000
2023-07-20 19:49:47,586 epoch 1 - iter 150/150 - loss 0.53835262 - time (sec): 618.07 - samples/sec: 330.98 - lr: 0.000079 - momentum: 0.000000
2023-07-20 19:49:47,586 ----------------------------------------------------------------------------------------------------
2023-07-20 19:49:47,586 EPOCH 1 done: loss 0.5384 - lr: 0.000079
2023-07-20 19:50:50,623 DEV : loss 0.18805114924907684 - f1-score (micro avg)  0.6907
2023-07-20 19:51:48,504 TEST : loss 0.10668940842151642 - f1-score (micro avg)  0.8894
2023-07-20 19:51:48,558 ----------------------------------------------------------------------------------------------------
2023-07-20 19:52:48,476 epoch 2 - iter 15/150 - loss 0.09975791 - time (sec): 59.92 - samples/sec: 350.18 - lr: 0.000079 - momentum: 0.000000
2023-07-20 19:53:50,509 epoch 2 - iter 30/150 - loss 0.09412234 - time (sec): 121.95 - samples/sec: 335.76 - lr: 0.000078 - momentum: 0.000000
2023-07-20 19:54:53,034 epoch 2 - iter 45/150 - loss 0.08764719 - time (sec): 184.47 - samples/sec: 332.08 - lr: 0.000077 - momentum: 0.000000
2023-07-20 19:55:52,747 epoch 2 - iter 60/150 - loss 0.08526044 - time (sec): 244.19 - samples/sec: 333.34 - lr: 0.000077 - momentum: 0.000000
2023-07-20 19:56:53,501 epoch 2 - iter 75/150 - loss 0.08435357 - time (sec): 304.94 - samples/sec: 335.03 - lr: 0.000076 - momentum: 0.000000
2023-07-20 19:57:55,323 epoch 2 - iter 90/150 - loss 0.08165222 - time (sec): 366.76 - samples/sec: 334.60 - lr: 0.000075 - momentum: 0.000000
2023-07-20 19:58:58,563 epoch 2 - iter 105/150 - loss 0.08028967 - time (sec): 430.00 - samples/sec: 331.81 - lr: 0.000074 - momentum: 0.000000
2023-07-20 19:59:58,434 epoch 2 - iter 120/150 - loss 0.07833455 - time (sec): 489.87 - samples/sec: 331.62 - lr: 0.000073 - momentum: 0.000000
2023-07-20 20:00:59,947 epoch 2 - iter 135/150 - loss 0.07712536 - time (sec): 551.39 - samples/sec: 333.62 - lr: 0.000072 - momentum: 0.000000
2023-07-20 20:02:03,889 epoch 2 - iter 150/150 - loss 0.07545138 - time (sec): 615.33 - samples/sec: 332.45 - lr: 0.000071 - momentum: 0.000000
2023-07-20 20:02:03,890 ----------------------------------------------------------------------------------------------------
2023-07-20 20:02:03,890 EPOCH 2 done: loss 0.0755 - lr: 0.000071
2023-07-20 20:03:05,833 DEV : loss 0.17549298703670502 - f1-score (micro avg)  0.7261
2023-07-20 20:04:10,125 TEST : loss 0.09331773221492767 - f1-score (micro avg)  0.914
2023-07-20 20:04:10,175 ----------------------------------------------------------------------------------------------------
2023-07-20 20:05:14,584 epoch 3 - iter 15/150 - loss 0.04249744 - time (sec): 64.40 - samples/sec: 329.74 - lr: 0.000070 - momentum: 0.000000
2023-07-20 20:06:18,378 epoch 3 - iter 30/150 - loss 0.04519425 - time (sec): 128.20 - samples/sec: 327.06 - lr: 0.000069 - momentum: 0.000000
2023-07-20 20:07:21,269 epoch 3 - iter 45/150 - loss 0.04673282 - time (sec): 191.09 - samples/sec: 323.70 - lr: 0.000069 - momentum: 0.000000
2023-07-20 20:08:24,630 epoch 3 - iter 60/150 - loss 0.04827400 - time (sec): 254.45 - samples/sec: 320.86 - lr: 0.000068 - momentum: 0.000000
2023-07-20 20:09:27,450 epoch 3 - iter 75/150 - loss 0.04848137 - time (sec): 317.27 - samples/sec: 324.45 - lr: 0.000067 - momentum: 0.000000
2023-07-20 20:10:28,388 epoch 3 - iter 90/150 - loss 0.04918745 - time (sec): 378.21 - samples/sec: 325.34 - lr: 0.000066 - momentum: 0.000000
2023-07-20 20:11:29,617 epoch 3 - iter 105/150 - loss 0.04847425 - time (sec): 439.44 - samples/sec: 326.40 - lr: 0.000065 - momentum: 0.000000
2023-07-20 20:12:33,686 epoch 3 - iter 120/150 - loss 0.04892314 - time (sec): 503.50 - samples/sec: 325.14 - lr: 0.000064 - momentum: 0.000000
2023-07-20 20:13:33,874 epoch 3 - iter 135/150 - loss 0.04806072 - time (sec): 563.69 - samples/sec: 327.32 - lr: 0.000063 - momentum: 0.000000
2023-07-20 20:14:32,770 epoch 3 - iter 150/150 - loss 0.04784606 - time (sec): 622.59 - samples/sec: 328.58 - lr: 0.000062 - momentum: 0.000000
2023-07-20 20:14:32,770 ----------------------------------------------------------------------------------------------------
2023-07-20 20:14:32,770 EPOCH 3 done: loss 0.0478 - lr: 0.000062
2023-07-20 20:15:33,142 DEV : loss 0.1693732887506485 - f1-score (micro avg)  0.7066
2023-07-20 20:16:34,797 TEST : loss 0.09787040203809738 - f1-score (micro avg)  0.9226
2023-07-20 20:16:34,847 ----------------------------------------------------------------------------------------------------
2023-07-20 20:17:35,294 epoch 4 - iter 15/150 - loss 0.03975100 - time (sec): 60.44 - samples/sec: 340.49 - lr: 0.000062 - momentum: 0.000000
2023-07-20 20:18:34,932 epoch 4 - iter 30/150 - loss 0.03610499 - time (sec): 120.08 - samples/sec: 336.66 - lr: 0.000061 - momentum: 0.000000
2023-07-20 20:19:37,008 epoch 4 - iter 45/150 - loss 0.03647643 - time (sec): 182.16 - samples/sec: 335.60 - lr: 0.000060 - momentum: 0.000000
2023-07-20 20:20:37,432 epoch 4 - iter 60/150 - loss 0.03488052 - time (sec): 242.58 - samples/sec: 336.22 - lr: 0.000059 - momentum: 0.000000
2023-07-20 20:21:35,888 epoch 4 - iter 75/150 - loss 0.03531330 - time (sec): 301.04 - samples/sec: 338.71 - lr: 0.000058 - momentum: 0.000000
2023-07-20 20:22:36,734 epoch 4 - iter 90/150 - loss 0.03617005 - time (sec): 361.88 - samples/sec: 338.84 - lr: 0.000057 - momentum: 0.000000
2023-07-20 20:23:36,574 epoch 4 - iter 105/150 - loss 0.03555091 - time (sec): 421.72 - samples/sec: 340.38 - lr: 0.000056 - momentum: 0.000000
2023-07-20 20:24:38,020 epoch 4 - iter 120/150 - loss 0.03469495 - time (sec): 483.17 - samples/sec: 339.92 - lr: 0.000055 - momentum: 0.000000
2023-07-20 20:25:40,842 epoch 4 - iter 135/150 - loss 0.03439912 - time (sec): 545.99 - samples/sec: 338.12 - lr: 0.000054 - momentum: 0.000000
2023-07-20 20:26:41,385 epoch 4 - iter 150/150 - loss 0.03475585 - time (sec): 606.54 - samples/sec: 337.27 - lr: 0.000054 - momentum: 0.000000
2023-07-20 20:26:41,385 ----------------------------------------------------------------------------------------------------
2023-07-20 20:26:41,385 EPOCH 4 done: loss 0.0348 - lr: 0.000054
2023-07-20 20:27:46,225 DEV : loss 0.14655829966068268 - f1-score (micro avg)  0.7318
2023-07-20 20:28:47,662 TEST : loss 0.08234965056180954 - f1-score (micro avg)  0.9316
2023-07-20 20:28:47,725 ----------------------------------------------------------------------------------------------------
2023-07-20 20:29:53,516 epoch 5 - iter 15/150 - loss 0.02028140 - time (sec): 65.79 - samples/sec: 318.81 - lr: 0.000053 - momentum: 0.000000
2023-07-20 20:30:53,490 epoch 5 - iter 30/150 - loss 0.02532778 - time (sec): 125.76 - samples/sec: 330.91 - lr: 0.000052 - momentum: 0.000000
2023-07-20 20:31:54,026 epoch 5 - iter 45/150 - loss 0.02701855 - time (sec): 186.30 - samples/sec: 329.56 - lr: 0.000051 - momentum: 0.000000
2023-07-20 20:32:55,071 epoch 5 - iter 60/150 - loss 0.02760206 - time (sec): 247.34 - samples/sec: 329.83 - lr: 0.000050 - momentum: 0.000000
2023-07-20 20:33:59,154 epoch 5 - iter 75/150 - loss 0.02719167 - time (sec): 311.43 - samples/sec: 328.28 - lr: 0.000049 - momentum: 0.000000
2023-07-20 20:35:01,321 epoch 5 - iter 90/150 - loss 0.02666270 - time (sec): 373.59 - samples/sec: 330.20 - lr: 0.000048 - momentum: 0.000000
2023-07-20 20:36:03,337 epoch 5 - iter 105/150 - loss 0.02643077 - time (sec): 435.61 - samples/sec: 329.91 - lr: 0.000047 - momentum: 0.000000
2023-07-20 20:37:04,061 epoch 5 - iter 120/150 - loss 0.02583070 - time (sec): 496.33 - samples/sec: 329.69 - lr: 0.000046 - momentum: 0.000000
2023-07-20 20:38:07,167 epoch 5 - iter 135/150 - loss 0.02551726 - time (sec): 559.44 - samples/sec: 329.85 - lr: 0.000046 - momentum: 0.000000
2023-07-20 20:39:07,700 epoch 5 - iter 150/150 - loss 0.02479160 - time (sec): 619.97 - samples/sec: 329.96 - lr: 0.000045 - momentum: 0.000000
2023-07-20 20:39:07,700 ----------------------------------------------------------------------------------------------------
2023-07-20 20:39:07,700 EPOCH 5 done: loss 0.0248 - lr: 0.000045
2023-07-20 20:40:04,851 DEV : loss 0.15623050928115845 - f1-score (micro avg)  0.7187
2023-07-20 20:41:00,159 TEST : loss 0.09736610949039459 - f1-score (micro avg)  0.9272
2023-07-20 20:41:00,213 ----------------------------------------------------------------------------------------------------
2023-07-20 20:42:04,576 epoch 6 - iter 15/150 - loss 0.01659322 - time (sec): 64.36 - samples/sec: 309.09 - lr: 0.000044 - momentum: 0.000000
2023-07-20 20:43:05,368 epoch 6 - iter 30/150 - loss 0.01813429 - time (sec): 125.15 - samples/sec: 323.31 - lr: 0.000043 - momentum: 0.000000
2023-07-20 20:44:08,156 epoch 6 - iter 45/150 - loss 0.01668493 - time (sec): 187.94 - samples/sec: 326.23 - lr: 0.000042 - momentum: 0.000000
2023-07-20 20:45:08,052 epoch 6 - iter 60/150 - loss 0.01869817 - time (sec): 247.84 - samples/sec: 327.66 - lr: 0.000041 - momentum: 0.000000
2023-07-20 20:46:10,638 epoch 6 - iter 75/150 - loss 0.01817256 - time (sec): 310.42 - samples/sec: 326.29 - lr: 0.000040 - momentum: 0.000000
2023-07-20 20:47:11,960 epoch 6 - iter 90/150 - loss 0.01807651 - time (sec): 371.75 - samples/sec: 328.23 - lr: 0.000039 - momentum: 0.000000
2023-07-20 20:48:13,627 epoch 6 - iter 105/150 - loss 0.01748010 - time (sec): 433.41 - samples/sec: 329.81 - lr: 0.000039 - momentum: 0.000000
2023-07-20 20:49:15,853 epoch 6 - iter 120/150 - loss 0.01743987 - time (sec): 495.64 - samples/sec: 328.59 - lr: 0.000038 - momentum: 0.000000
2023-07-20 20:50:17,495 epoch 6 - iter 135/150 - loss 0.01740596 - time (sec): 557.28 - samples/sec: 329.92 - lr: 0.000037 - momentum: 0.000000
2023-07-20 20:51:21,615 epoch 6 - iter 150/150 - loss 0.01732458 - time (sec): 621.40 - samples/sec: 329.20 - lr: 0.000036 - momentum: 0.000000
2023-07-20 20:51:21,615 ----------------------------------------------------------------------------------------------------
2023-07-20 20:51:21,615 EPOCH 6 done: loss 0.0173 - lr: 0.000036
2023-07-20 20:52:20,716 DEV : loss 0.20378698408603668 - f1-score (micro avg)  0.6675
2023-07-20 20:53:14,546 TEST : loss 0.10253641754388809 - f1-score (micro avg)  0.9225
2023-07-20 20:53:14,604 ----------------------------------------------------------------------------------------------------
2023-07-20 20:54:18,637 epoch 7 - iter 15/150 - loss 0.01246612 - time (sec): 64.03 - samples/sec: 323.14 - lr: 0.000035 - momentum: 0.000000
2023-07-20 20:55:18,793 epoch 7 - iter 30/150 - loss 0.01055134 - time (sec): 124.19 - samples/sec: 327.70 - lr: 0.000034 - momentum: 0.000000
2023-07-20 20:56:19,538 epoch 7 - iter 45/150 - loss 0.01117900 - time (sec): 184.93 - samples/sec: 328.12 - lr: 0.000033 - momentum: 0.000000
2023-07-20 20:57:19,890 epoch 7 - iter 60/150 - loss 0.01144068 - time (sec): 245.28 - samples/sec: 334.71 - lr: 0.000032 - momentum: 0.000000
2023-07-20 20:58:23,969 epoch 7 - iter 75/150 - loss 0.01188958 - time (sec): 309.36 - samples/sec: 333.15 - lr: 0.000031 - momentum: 0.000000
2023-07-20 20:59:23,954 epoch 7 - iter 90/150 - loss 0.01233610 - time (sec): 369.35 - samples/sec: 336.47 - lr: 0.000031 - momentum: 0.000000
2023-07-20 21:00:26,256 epoch 7 - iter 105/150 - loss 0.01260737 - time (sec): 431.65 - samples/sec: 333.97 - lr: 0.000030 - momentum: 0.000000
2023-07-20 21:01:31,195 epoch 7 - iter 120/150 - loss 0.01296479 - time (sec): 496.59 - samples/sec: 332.28 - lr: 0.000029 - momentum: 0.000000
2023-07-20 21:02:33,219 epoch 7 - iter 135/150 - loss 0.01292395 - time (sec): 558.61 - samples/sec: 330.41 - lr: 0.000028 - momentum: 0.000000
2023-07-20 21:03:32,053 epoch 7 - iter 150/150 - loss 0.01291196 - time (sec): 617.45 - samples/sec: 331.31 - lr: 0.000027 - momentum: 0.000000
2023-07-20 21:03:32,053 ----------------------------------------------------------------------------------------------------
2023-07-20 21:03:32,053 EPOCH 7 done: loss 0.0129 - lr: 0.000027
2023-07-20 21:04:30,604 DEV : loss 0.19768385589122772 - f1-score (micro avg)  0.7211
2023-07-20 21:05:28,111 TEST : loss 0.1023310124874115 - f1-score (micro avg)  0.9286
2023-07-20 21:05:28,167 ----------------------------------------------------------------------------------------------------
2023-07-20 21:06:28,849 epoch 8 - iter 15/150 - loss 0.00919076 - time (sec): 60.68 - samples/sec: 338.10 - lr: 0.000026 - momentum: 0.000000
2023-07-20 21:07:28,901 epoch 8 - iter 30/150 - loss 0.00887924 - time (sec): 120.73 - samples/sec: 334.79 - lr: 0.000025 - momentum: 0.000000
2023-07-20 21:08:30,279 epoch 8 - iter 45/150 - loss 0.01100972 - time (sec): 182.11 - samples/sec: 334.27 - lr: 0.000024 - momentum: 0.000000
2023-07-20 21:09:31,780 epoch 8 - iter 60/150 - loss 0.01049670 - time (sec): 243.61 - samples/sec: 333.97 - lr: 0.000024 - momentum: 0.000000
2023-07-20 21:10:34,025 epoch 8 - iter 75/150 - loss 0.01052365 - time (sec): 305.86 - samples/sec: 332.07 - lr: 0.000023 - momentum: 0.000000
2023-07-20 21:11:34,231 epoch 8 - iter 90/150 - loss 0.01004271 - time (sec): 366.06 - samples/sec: 332.70 - lr: 0.000022 - momentum: 0.000000
2023-07-20 21:12:35,997 epoch 8 - iter 105/150 - loss 0.01006449 - time (sec): 427.83 - samples/sec: 333.61 - lr: 0.000021 - momentum: 0.000000
2023-07-20 21:13:38,854 epoch 8 - iter 120/150 - loss 0.00995656 - time (sec): 490.68 - samples/sec: 333.89 - lr: 0.000020 - momentum: 0.000000
2023-07-20 21:14:39,288 epoch 8 - iter 135/150 - loss 0.00965695 - time (sec): 551.12 - samples/sec: 334.44 - lr: 0.000019 - momentum: 0.000000
2023-07-20 21:15:40,800 epoch 8 - iter 150/150 - loss 0.00973828 - time (sec): 612.63 - samples/sec: 333.92 - lr: 0.000018 - momentum: 0.000000
2023-07-20 21:15:40,800 ----------------------------------------------------------------------------------------------------
2023-07-20 21:15:40,800 EPOCH 8 done: loss 0.0097 - lr: 0.000018
2023-07-20 21:16:39,406 DEV : loss 0.27300703525543213 - f1-score (micro avg)  0.6587
2023-07-20 21:17:38,821 TEST : loss 0.10889338701963425 - f1-score (micro avg)  0.9329
2023-07-20 21:17:38,876 ----------------------------------------------------------------------------------------------------
2023-07-20 21:18:37,526 epoch 9 - iter 15/150 - loss 0.00738872 - time (sec): 58.65 - samples/sec: 352.52 - lr: 0.000017 - momentum: 0.000000
2023-07-20 21:19:38,728 epoch 9 - iter 30/150 - loss 0.00696483 - time (sec): 119.85 - samples/sec: 340.27 - lr: 0.000016 - momentum: 0.000000
2023-07-20 21:20:39,937 epoch 9 - iter 45/150 - loss 0.00557176 - time (sec): 181.06 - samples/sec: 340.31 - lr: 0.000016 - momentum: 0.000000
2023-07-20 21:21:44,626 epoch 9 - iter 60/150 - loss 0.00634206 - time (sec): 245.75 - samples/sec: 333.41 - lr: 0.000015 - momentum: 0.000000
2023-07-20 21:22:47,612 epoch 9 - iter 75/150 - loss 0.00623344 - time (sec): 308.73 - samples/sec: 330.06 - lr: 0.000014 - momentum: 0.000000
2023-07-20 21:23:51,149 epoch 9 - iter 90/150 - loss 0.00647410 - time (sec): 372.27 - samples/sec: 329.25 - lr: 0.000013 - momentum: 0.000000
2023-07-20 21:24:51,128 epoch 9 - iter 105/150 - loss 0.00644800 - time (sec): 432.25 - samples/sec: 331.70 - lr: 0.000012 - momentum: 0.000000
2023-07-20 21:25:54,276 epoch 9 - iter 120/150 - loss 0.00657144 - time (sec): 495.40 - samples/sec: 329.93 - lr: 0.000011 - momentum: 0.000000
2023-07-20 21:26:55,813 epoch 9 - iter 135/150 - loss 0.00626433 - time (sec): 556.94 - samples/sec: 330.59 - lr: 0.000010 - momentum: 0.000000
2023-07-20 21:27:55,835 epoch 9 - iter 150/150 - loss 0.00613183 - time (sec): 616.96 - samples/sec: 331.57 - lr: 0.000009 - momentum: 0.000000
2023-07-20 21:27:55,836 ----------------------------------------------------------------------------------------------------
2023-07-20 21:27:55,836 EPOCH 9 done: loss 0.0061 - lr: 0.000009
2023-07-20 21:28:54,802 DEV : loss 0.241546168923378 - f1-score (micro avg)  0.7322
2023-07-20 21:29:51,763 TEST : loss 0.13225461542606354 - f1-score (micro avg)  0.9336
2023-07-20 21:29:51,810 ----------------------------------------------------------------------------------------------------
2023-07-20 21:30:51,059 epoch 10 - iter 15/150 - loss 0.00698630 - time (sec): 59.25 - samples/sec: 335.31 - lr: 0.000008 - momentum: 0.000000
2023-07-20 21:31:51,275 epoch 10 - iter 30/150 - loss 0.00398681 - time (sec): 119.46 - samples/sec: 333.48 - lr: 0.000008 - momentum: 0.000000
2023-07-20 21:32:54,248 epoch 10 - iter 45/150 - loss 0.00470782 - time (sec): 182.44 - samples/sec: 332.41 - lr: 0.000007 - momentum: 0.000000
2023-07-20 21:33:55,448 epoch 10 - iter 60/150 - loss 0.00531125 - time (sec): 243.64 - samples/sec: 336.13 - lr: 0.000006 - momentum: 0.000000
2023-07-20 21:34:55,467 epoch 10 - iter 75/150 - loss 0.00497007 - time (sec): 303.66 - samples/sec: 338.02 - lr: 0.000005 - momentum: 0.000000
2023-07-20 21:35:56,304 epoch 10 - iter 90/150 - loss 0.00462493 - time (sec): 364.49 - samples/sec: 337.28 - lr: 0.000004 - momentum: 0.000000
2023-07-20 21:36:59,607 epoch 10 - iter 105/150 - loss 0.00474514 - time (sec): 427.80 - samples/sec: 335.37 - lr: 0.000003 - momentum: 0.000000
2023-07-20 21:38:01,289 epoch 10 - iter 120/150 - loss 0.00496922 - time (sec): 489.48 - samples/sec: 335.66 - lr: 0.000002 - momentum: 0.000000
2023-07-20 21:39:01,039 epoch 10 - iter 135/150 - loss 0.00503936 - time (sec): 549.23 - samples/sec: 335.21 - lr: 0.000001 - momentum: 0.000000
2023-07-20 21:40:02,697 epoch 10 - iter 150/150 - loss 0.00510659 - time (sec): 610.89 - samples/sec: 334.87 - lr: 0.000001 - momentum: 0.000000
2023-07-20 21:40:02,697 ----------------------------------------------------------------------------------------------------
2023-07-20 21:40:02,697 EPOCH 10 done: loss 0.0051 - lr: 0.000001
2023-07-20 21:40:59,576 DEV : loss 0.2760806977748871 - f1-score (micro avg)  0.714
2023-07-20 21:41:56,136 TEST : loss 0.13800400495529175 - f1-score (micro avg)  0.9346
2023-07-20 21:42:08,246 ----------------------------------------------------------------------------------------------------
2023-07-20 21:42:08,250 Testing using last state of model ...
2023-07-20 21:43:06,278 
Results:
- F-score (micro) 0.9346
- F-score (macro) 0.9219
- Accuracy 0.9029

By class:
              precision    recall  f1-score   support

         ORG     0.8997    0.9398    0.9193      1661
         LOC     0.9492    0.9418    0.9455      1668
         PER     0.9808    0.9790    0.9799      1617
        MISC     0.8263    0.8604    0.8430       702

   micro avg     0.9275    0.9417    0.9346      5648
   macro avg     0.9140    0.9303    0.9219      5648
weighted avg     0.9284    0.9417    0.9349      5648

2023-07-20 21:43:06,278 ----------------------------------------------------------------------------------------------------
