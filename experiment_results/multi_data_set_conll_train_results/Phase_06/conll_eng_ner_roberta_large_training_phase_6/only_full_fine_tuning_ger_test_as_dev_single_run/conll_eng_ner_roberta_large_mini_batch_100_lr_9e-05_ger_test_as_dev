2023-07-07 23:07:38,719 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,723 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-07 23:07:38,723 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,723 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-07 23:07:38,723 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,723 Train:  14987 sentences
2023-07-07 23:07:38,724         (train_with_dev=False, train_with_test=False)
2023-07-07 23:07:38,724 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,724 Training Params:
2023-07-07 23:07:38,724  - learning_rate: "9e-05" 
2023-07-07 23:07:38,724  - mini_batch_size: "100"
2023-07-07 23:07:38,724  - max_epochs: "10"
2023-07-07 23:07:38,724  - shuffle: "True"
2023-07-07 23:07:38,724 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,724 Plugins:
2023-07-07 23:07:38,724  - LinearScheduler | warmup_fraction: '0.1'
2023-07-07 23:07:38,724 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,724 Final evaluation on model after last epoch (final-model.pt)
2023-07-07 23:07:38,724  - metric: "('micro avg', 'f1-score')"
2023-07-07 23:07:38,724 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,724 Computation:
2023-07-07 23:07:38,725  - compute on device: cuda:1
2023-07-07 23:07:38,725  - embedding storage: none
2023-07-07 23:07:38,725 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,725 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_9e-05_ger_test_as_dev"
2023-07-07 23:07:38,725 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,725 Removed gradient clipping
2023-07-07 23:07:38,725 ----------------------------------------------------------------------------------------------------
2023-07-07 23:07:38,725 ----------------------------------------------------------------------------------------------------
2023-07-07 23:08:24,876 epoch 1 - iter 15/150 - loss 2.93174359 - time (sec): 46.15 - samples/sec: 447.78 - lr: 0.000008 - momentum: 0.000000
2023-07-07 23:09:10,252 epoch 1 - iter 30/150 - loss 2.14457356 - time (sec): 91.52 - samples/sec: 446.45 - lr: 0.000017 - momentum: 0.000000
2023-07-07 23:09:55,249 epoch 1 - iter 45/150 - loss 1.65023068 - time (sec): 136.52 - samples/sec: 450.89 - lr: 0.000026 - momentum: 0.000000
2023-07-07 23:10:43,832 epoch 1 - iter 60/150 - loss 1.36579769 - time (sec): 185.10 - samples/sec: 443.98 - lr: 0.000035 - momentum: 0.000000
2023-07-07 23:11:31,780 epoch 1 - iter 75/150 - loss 1.17047965 - time (sec): 233.05 - samples/sec: 440.25 - lr: 0.000044 - momentum: 0.000000
2023-07-07 23:12:19,960 epoch 1 - iter 90/150 - loss 1.02227500 - time (sec): 281.23 - samples/sec: 436.10 - lr: 0.000053 - momentum: 0.000000
2023-07-07 23:13:08,682 epoch 1 - iter 105/150 - loss 0.90454157 - time (sec): 329.95 - samples/sec: 431.76 - lr: 0.000062 - momentum: 0.000000
2023-07-07 23:13:57,251 epoch 1 - iter 120/150 - loss 0.81000102 - time (sec): 378.52 - samples/sec: 429.27 - lr: 0.000071 - momentum: 0.000000
2023-07-07 23:14:45,279 epoch 1 - iter 135/150 - loss 0.73170770 - time (sec): 426.55 - samples/sec: 430.13 - lr: 0.000080 - momentum: 0.000000
2023-07-07 23:15:30,647 epoch 1 - iter 150/150 - loss 0.66590828 - time (sec): 471.92 - samples/sec: 433.48 - lr: 0.000089 - momentum: 0.000000
2023-07-07 23:15:30,648 ----------------------------------------------------------------------------------------------------
2023-07-07 23:15:30,648 EPOCH 1 done: loss 0.6659 - lr: 0.000089
2023-07-07 23:16:14,177 DEV : loss 0.22280357778072357 - f1-score (micro avg)  0.6462
2023-07-07 23:16:58,474 TEST : loss 0.121748186647892 - f1-score (micro avg)  0.8862
2023-07-07 23:16:58,527 ----------------------------------------------------------------------------------------------------
2023-07-07 23:17:44,396 epoch 2 - iter 15/150 - loss 0.09933615 - time (sec): 45.87 - samples/sec: 434.45 - lr: 0.000089 - momentum: 0.000000
2023-07-07 23:18:30,619 epoch 2 - iter 30/150 - loss 0.09717475 - time (sec): 92.09 - samples/sec: 441.37 - lr: 0.000088 - momentum: 0.000000
2023-07-07 23:19:16,533 epoch 2 - iter 45/150 - loss 0.09825890 - time (sec): 138.00 - samples/sec: 446.87 - lr: 0.000087 - momentum: 0.000000
2023-07-07 23:20:03,314 epoch 2 - iter 60/150 - loss 0.09610377 - time (sec): 184.79 - samples/sec: 446.23 - lr: 0.000086 - momentum: 0.000000
2023-07-07 23:20:49,248 epoch 2 - iter 75/150 - loss 0.10251331 - time (sec): 230.72 - samples/sec: 445.70 - lr: 0.000085 - momentum: 0.000000
2023-07-07 23:21:35,480 epoch 2 - iter 90/150 - loss 0.09955760 - time (sec): 276.95 - samples/sec: 445.18 - lr: 0.000084 - momentum: 0.000000
2023-07-07 23:22:20,900 epoch 2 - iter 105/150 - loss 0.09764678 - time (sec): 322.37 - samples/sec: 445.25 - lr: 0.000083 - momentum: 0.000000
2023-07-07 23:23:07,756 epoch 2 - iter 120/150 - loss 0.09448917 - time (sec): 369.23 - samples/sec: 443.93 - lr: 0.000082 - momentum: 0.000000
2023-07-07 23:23:55,991 epoch 2 - iter 135/150 - loss 0.09176286 - time (sec): 417.46 - samples/sec: 442.65 - lr: 0.000081 - momentum: 0.000000
2023-07-07 23:24:42,893 epoch 2 - iter 150/150 - loss 0.09197612 - time (sec): 464.36 - samples/sec: 440.53 - lr: 0.000080 - momentum: 0.000000
2023-07-07 23:24:42,894 ----------------------------------------------------------------------------------------------------
2023-07-07 23:24:42,894 EPOCH 2 done: loss 0.0920 - lr: 0.000080
2023-07-07 23:25:30,664 DEV : loss 0.1728101372718811 - f1-score (micro avg)  0.71
2023-07-07 23:26:18,808 TEST : loss 0.12040017545223236 - f1-score (micro avg)  0.8889
2023-07-07 23:26:18,861 ----------------------------------------------------------------------------------------------------
2023-07-07 23:27:07,068 epoch 3 - iter 15/150 - loss 0.07543600 - time (sec): 48.20 - samples/sec: 418.78 - lr: 0.000079 - momentum: 0.000000
2023-07-07 23:27:55,214 epoch 3 - iter 30/150 - loss 0.06920488 - time (sec): 96.35 - samples/sec: 430.42 - lr: 0.000078 - momentum: 0.000000
2023-07-07 23:28:38,528 epoch 3 - iter 45/150 - loss 0.06756324 - time (sec): 139.66 - samples/sec: 437.78 - lr: 0.000077 - momentum: 0.000000
2023-07-07 23:29:21,710 epoch 3 - iter 60/150 - loss 0.06453691 - time (sec): 182.85 - samples/sec: 444.25 - lr: 0.000076 - momentum: 0.000000
2023-07-07 23:30:06,114 epoch 3 - iter 75/150 - loss 0.06343949 - time (sec): 227.25 - samples/sec: 451.24 - lr: 0.000075 - momentum: 0.000000
2023-07-07 23:30:51,729 epoch 3 - iter 90/150 - loss 0.06959300 - time (sec): 272.87 - samples/sec: 449.80 - lr: 0.000074 - momentum: 0.000000
2023-07-07 23:31:37,881 epoch 3 - iter 105/150 - loss 0.06682176 - time (sec): 319.02 - samples/sec: 448.66 - lr: 0.000073 - momentum: 0.000000
2023-07-07 23:32:23,049 epoch 3 - iter 120/150 - loss 0.06586400 - time (sec): 364.19 - samples/sec: 447.24 - lr: 0.000072 - momentum: 0.000000
2023-07-07 23:33:09,106 epoch 3 - iter 135/150 - loss 0.06264259 - time (sec): 410.24 - samples/sec: 448.23 - lr: 0.000071 - momentum: 0.000000
2023-07-07 23:33:55,368 epoch 3 - iter 150/150 - loss 0.06020872 - time (sec): 456.51 - samples/sec: 448.12 - lr: 0.000070 - momentum: 0.000000
2023-07-07 23:33:55,369 ----------------------------------------------------------------------------------------------------
2023-07-07 23:33:55,369 EPOCH 3 done: loss 0.0602 - lr: 0.000070
2023-07-07 23:34:38,561 DEV : loss 0.1880141645669937 - f1-score (micro avg)  0.6786
2023-07-07 23:35:21,641 TEST : loss 0.08320742845535278 - f1-score (micro avg)  0.9263
2023-07-07 23:35:21,705 ----------------------------------------------------------------------------------------------------
2023-07-07 23:36:10,722 epoch 4 - iter 15/150 - loss 0.03773517 - time (sec): 49.02 - samples/sec: 408.65 - lr: 0.000069 - momentum: 0.000000
2023-07-07 23:36:59,155 epoch 4 - iter 30/150 - loss 0.03644190 - time (sec): 97.45 - samples/sec: 418.05 - lr: 0.000068 - momentum: 0.000000
2023-07-07 23:37:47,295 epoch 4 - iter 45/150 - loss 0.03785161 - time (sec): 145.59 - samples/sec: 420.99 - lr: 0.000067 - momentum: 0.000000
2023-07-07 23:38:35,374 epoch 4 - iter 60/150 - loss 0.03496410 - time (sec): 193.67 - samples/sec: 420.52 - lr: 0.000066 - momentum: 0.000000
2023-07-07 23:39:23,246 epoch 4 - iter 75/150 - loss 0.03482200 - time (sec): 241.54 - samples/sec: 417.58 - lr: 0.000065 - momentum: 0.000000
2023-07-07 23:40:11,921 epoch 4 - iter 90/150 - loss 0.03421880 - time (sec): 290.21 - samples/sec: 418.61 - lr: 0.000064 - momentum: 0.000000
2023-07-07 23:40:58,420 epoch 4 - iter 105/150 - loss 0.03423234 - time (sec): 336.71 - samples/sec: 422.43 - lr: 0.000063 - momentum: 0.000000
2023-07-07 23:41:44,206 epoch 4 - iter 120/150 - loss 0.03309272 - time (sec): 382.50 - samples/sec: 425.74 - lr: 0.000062 - momentum: 0.000000
2023-07-07 23:42:30,306 epoch 4 - iter 135/150 - loss 0.03292069 - time (sec): 428.60 - samples/sec: 428.34 - lr: 0.000061 - momentum: 0.000000
2023-07-07 23:43:15,300 epoch 4 - iter 150/150 - loss 0.03228348 - time (sec): 473.59 - samples/sec: 431.95 - lr: 0.000060 - momentum: 0.000000
2023-07-07 23:43:15,301 ----------------------------------------------------------------------------------------------------
2023-07-07 23:43:15,301 EPOCH 4 done: loss 0.0323 - lr: 0.000060
2023-07-07 23:43:58,450 DEV : loss 0.1625189632177353 - f1-score (micro avg)  0.735
2023-07-07 23:44:40,032 TEST : loss 0.08429243415594101 - f1-score (micro avg)  0.9264
2023-07-07 23:44:40,095 ----------------------------------------------------------------------------------------------------
2023-07-07 23:45:25,207 epoch 5 - iter 15/150 - loss 0.02815309 - time (sec): 45.11 - samples/sec: 445.29 - lr: 0.000059 - momentum: 0.000000
2023-07-07 23:46:09,533 epoch 5 - iter 30/150 - loss 0.02752464 - time (sec): 89.44 - samples/sec: 450.97 - lr: 0.000058 - momentum: 0.000000
2023-07-07 23:46:56,157 epoch 5 - iter 45/150 - loss 0.02527459 - time (sec): 136.06 - samples/sec: 453.29 - lr: 0.000057 - momentum: 0.000000
2023-07-07 23:47:41,685 epoch 5 - iter 60/150 - loss 0.02463146 - time (sec): 181.59 - samples/sec: 454.02 - lr: 0.000056 - momentum: 0.000000
2023-07-07 23:48:26,265 epoch 5 - iter 75/150 - loss 0.02452325 - time (sec): 226.17 - samples/sec: 455.81 - lr: 0.000055 - momentum: 0.000000
2023-07-07 23:49:14,186 epoch 5 - iter 90/150 - loss 0.02357682 - time (sec): 274.09 - samples/sec: 450.68 - lr: 0.000054 - momentum: 0.000000
2023-07-07 23:50:03,046 epoch 5 - iter 105/150 - loss 0.02340093 - time (sec): 322.95 - samples/sec: 447.02 - lr: 0.000053 - momentum: 0.000000
2023-07-07 23:50:51,188 epoch 5 - iter 120/150 - loss 0.02355690 - time (sec): 371.09 - samples/sec: 442.73 - lr: 0.000052 - momentum: 0.000000
2023-07-07 23:51:38,673 epoch 5 - iter 135/150 - loss 0.02346405 - time (sec): 418.58 - samples/sec: 443.18 - lr: 0.000051 - momentum: 0.000000
2023-07-07 23:52:27,094 epoch 5 - iter 150/150 - loss 0.02337369 - time (sec): 467.00 - samples/sec: 438.05 - lr: 0.000050 - momentum: 0.000000
2023-07-07 23:52:27,095 ----------------------------------------------------------------------------------------------------
2023-07-07 23:52:27,095 EPOCH 5 done: loss 0.0234 - lr: 0.000050
2023-07-07 23:53:16,257 DEV : loss 0.1546904742717743 - f1-score (micro avg)  0.7384
2023-07-07 23:54:00,647 TEST : loss 0.08105356991291046 - f1-score (micro avg)  0.9296
2023-07-07 23:54:00,695 ----------------------------------------------------------------------------------------------------
2023-07-07 23:54:46,423 epoch 6 - iter 15/150 - loss 0.01797761 - time (sec): 45.73 - samples/sec: 465.88 - lr: 0.000049 - momentum: 0.000000
2023-07-07 23:55:33,065 epoch 6 - iter 30/150 - loss 0.01587545 - time (sec): 92.37 - samples/sec: 455.97 - lr: 0.000048 - momentum: 0.000000
2023-07-07 23:56:18,904 epoch 6 - iter 45/150 - loss 0.01768619 - time (sec): 138.21 - samples/sec: 451.50 - lr: 0.000047 - momentum: 0.000000
2023-07-07 23:57:04,328 epoch 6 - iter 60/150 - loss 0.01717382 - time (sec): 183.63 - samples/sec: 450.46 - lr: 0.000046 - momentum: 0.000000
2023-07-07 23:57:50,092 epoch 6 - iter 75/150 - loss 0.01723627 - time (sec): 229.40 - samples/sec: 448.49 - lr: 0.000045 - momentum: 0.000000
2023-07-07 23:58:35,493 epoch 6 - iter 90/150 - loss 0.01729689 - time (sec): 274.80 - samples/sec: 446.28 - lr: 0.000044 - momentum: 0.000000
2023-07-07 23:59:21,089 epoch 6 - iter 105/150 - loss 0.01679490 - time (sec): 320.39 - samples/sec: 445.67 - lr: 0.000043 - momentum: 0.000000
2023-07-08 00:00:05,913 epoch 6 - iter 120/150 - loss 0.01635574 - time (sec): 365.22 - samples/sec: 446.10 - lr: 0.000042 - momentum: 0.000000
2023-07-08 00:00:51,125 epoch 6 - iter 135/150 - loss 0.01615416 - time (sec): 410.43 - samples/sec: 447.68 - lr: 0.000041 - momentum: 0.000000
2023-07-08 00:01:38,661 epoch 6 - iter 150/150 - loss 0.01633072 - time (sec): 457.96 - samples/sec: 446.69 - lr: 0.000040 - momentum: 0.000000
2023-07-08 00:01:38,662 ----------------------------------------------------------------------------------------------------
2023-07-08 00:01:38,662 EPOCH 6 done: loss 0.0163 - lr: 0.000040
2023-07-08 00:02:27,930 DEV : loss 0.19786043465137482 - f1-score (micro avg)  0.6719
2023-07-08 00:03:15,240 TEST : loss 0.08193574845790863 - f1-score (micro avg)  0.9338
2023-07-08 00:03:15,318 ----------------------------------------------------------------------------------------------------
2023-07-08 00:04:04,350 epoch 7 - iter 15/150 - loss 0.01279943 - time (sec): 49.03 - samples/sec: 405.40 - lr: 0.000039 - momentum: 0.000000
2023-07-08 00:04:54,199 epoch 7 - iter 30/150 - loss 0.01170684 - time (sec): 98.88 - samples/sec: 414.07 - lr: 0.000038 - momentum: 0.000000
2023-07-08 00:05:43,987 epoch 7 - iter 45/150 - loss 0.01167753 - time (sec): 148.67 - samples/sec: 413.10 - lr: 0.000037 - momentum: 0.000000
2023-07-08 00:06:29,130 epoch 7 - iter 60/150 - loss 0.01170563 - time (sec): 193.81 - samples/sec: 422.52 - lr: 0.000036 - momentum: 0.000000
2023-07-08 00:07:13,662 epoch 7 - iter 75/150 - loss 0.01183107 - time (sec): 238.34 - samples/sec: 429.08 - lr: 0.000035 - momentum: 0.000000
2023-07-08 00:07:58,847 epoch 7 - iter 90/150 - loss 0.01163980 - time (sec): 283.53 - samples/sec: 434.69 - lr: 0.000034 - momentum: 0.000000
2023-07-08 00:08:44,419 epoch 7 - iter 105/150 - loss 0.01137992 - time (sec): 329.10 - samples/sec: 435.39 - lr: 0.000033 - momentum: 0.000000
2023-07-08 00:09:30,059 epoch 7 - iter 120/150 - loss 0.01182316 - time (sec): 374.74 - samples/sec: 438.72 - lr: 0.000032 - momentum: 0.000000
2023-07-08 00:10:14,601 epoch 7 - iter 135/150 - loss 0.01197294 - time (sec): 419.28 - samples/sec: 439.70 - lr: 0.000031 - momentum: 0.000000
2023-07-08 00:10:59,676 epoch 7 - iter 150/150 - loss 0.01173866 - time (sec): 464.36 - samples/sec: 440.54 - lr: 0.000030 - momentum: 0.000000
2023-07-08 00:10:59,676 ----------------------------------------------------------------------------------------------------
2023-07-08 00:10:59,676 EPOCH 7 done: loss 0.0117 - lr: 0.000030
2023-07-08 00:11:43,354 DEV : loss 0.18835178017616272 - f1-score (micro avg)  0.7277
2023-07-08 00:12:30,443 TEST : loss 0.09148186445236206 - f1-score (micro avg)  0.9336
2023-07-08 00:12:30,516 ----------------------------------------------------------------------------------------------------
2023-07-08 00:13:15,335 epoch 8 - iter 15/150 - loss 0.00575431 - time (sec): 44.82 - samples/sec: 449.87 - lr: 0.000029 - momentum: 0.000000
2023-07-08 00:14:03,399 epoch 8 - iter 30/150 - loss 0.00820329 - time (sec): 92.88 - samples/sec: 441.64 - lr: 0.000028 - momentum: 0.000000
2023-07-08 00:14:51,565 epoch 8 - iter 45/150 - loss 0.00746595 - time (sec): 141.05 - samples/sec: 431.04 - lr: 0.000027 - momentum: 0.000000
2023-07-08 00:15:40,153 epoch 8 - iter 60/150 - loss 0.00768639 - time (sec): 189.64 - samples/sec: 429.13 - lr: 0.000026 - momentum: 0.000000
2023-07-08 00:16:28,398 epoch 8 - iter 75/150 - loss 0.00763998 - time (sec): 237.88 - samples/sec: 426.08 - lr: 0.000025 - momentum: 0.000000
2023-07-08 00:17:16,510 epoch 8 - iter 90/150 - loss 0.00779738 - time (sec): 285.99 - samples/sec: 426.48 - lr: 0.000024 - momentum: 0.000000
2023-07-08 00:18:04,706 epoch 8 - iter 105/150 - loss 0.00758499 - time (sec): 334.19 - samples/sec: 427.38 - lr: 0.000023 - momentum: 0.000000
2023-07-08 00:18:49,819 epoch 8 - iter 120/150 - loss 0.00789908 - time (sec): 379.30 - samples/sec: 430.99 - lr: 0.000022 - momentum: 0.000000
2023-07-08 00:19:33,997 epoch 8 - iter 135/150 - loss 0.00825993 - time (sec): 423.48 - samples/sec: 436.67 - lr: 0.000021 - momentum: 0.000000
2023-07-08 00:20:17,234 epoch 8 - iter 150/150 - loss 0.00828185 - time (sec): 466.72 - samples/sec: 438.31 - lr: 0.000020 - momentum: 0.000000
2023-07-08 00:20:17,234 ----------------------------------------------------------------------------------------------------
2023-07-08 00:20:17,235 EPOCH 8 done: loss 0.0083 - lr: 0.000020
2023-07-08 00:20:59,832 DEV : loss 0.1789335459470749 - f1-score (micro avg)  0.7319
2023-07-08 00:21:42,947 TEST : loss 0.09122144430875778 - f1-score (micro avg)  0.9364
2023-07-08 00:21:43,245 ----------------------------------------------------------------------------------------------------
2023-07-08 00:22:29,293 epoch 9 - iter 15/150 - loss 0.00722220 - time (sec): 46.04 - samples/sec: 450.77 - lr: 0.000019 - momentum: 0.000000
2023-07-08 00:23:14,336 epoch 9 - iter 30/150 - loss 0.00669123 - time (sec): 91.09 - samples/sec: 453.21 - lr: 0.000018 - momentum: 0.000000
2023-07-08 00:23:59,931 epoch 9 - iter 45/150 - loss 0.00681240 - time (sec): 136.68 - samples/sec: 457.37 - lr: 0.000017 - momentum: 0.000000
2023-07-08 00:24:45,213 epoch 9 - iter 60/150 - loss 0.00655552 - time (sec): 181.96 - samples/sec: 454.82 - lr: 0.000017 - momentum: 0.000000
2023-07-08 00:25:30,748 epoch 9 - iter 75/150 - loss 0.00672298 - time (sec): 227.50 - samples/sec: 450.12 - lr: 0.000016 - momentum: 0.000000
2023-07-08 00:26:16,375 epoch 9 - iter 90/150 - loss 0.00686677 - time (sec): 273.13 - samples/sec: 448.49 - lr: 0.000015 - momentum: 0.000000
2023-07-08 00:27:05,524 epoch 9 - iter 105/150 - loss 0.00679433 - time (sec): 322.27 - samples/sec: 444.96 - lr: 0.000014 - momentum: 0.000000
2023-07-08 00:27:53,961 epoch 9 - iter 120/150 - loss 0.00697626 - time (sec): 370.71 - samples/sec: 440.57 - lr: 0.000013 - momentum: 0.000000
2023-07-08 00:28:43,164 epoch 9 - iter 135/150 - loss 0.00705045 - time (sec): 419.91 - samples/sec: 440.22 - lr: 0.000012 - momentum: 0.000000
2023-07-08 00:29:29,681 epoch 9 - iter 150/150 - loss 0.00704614 - time (sec): 466.43 - samples/sec: 438.58 - lr: 0.000011 - momentum: 0.000000
2023-07-08 00:29:29,681 ----------------------------------------------------------------------------------------------------
2023-07-08 00:29:29,681 EPOCH 9 done: loss 0.0070 - lr: 0.000011
2023-07-08 00:30:17,985 DEV : loss 0.19671235978603363 - f1-score (micro avg)  0.7161
2023-07-08 00:31:06,436 TEST : loss 0.09351328015327454 - f1-score (micro avg)  0.9379
2023-07-08 00:31:06,483 ----------------------------------------------------------------------------------------------------
2023-07-08 00:31:52,876 epoch 10 - iter 15/150 - loss 0.00557079 - time (sec): 46.39 - samples/sec: 434.02 - lr: 0.000010 - momentum: 0.000000
2023-07-08 00:32:38,582 epoch 10 - iter 30/150 - loss 0.00463143 - time (sec): 92.10 - samples/sec: 431.48 - lr: 0.000009 - momentum: 0.000000
2023-07-08 00:33:24,310 epoch 10 - iter 45/150 - loss 0.00478285 - time (sec): 137.83 - samples/sec: 434.58 - lr: 0.000008 - momentum: 0.000000
2023-07-08 00:34:10,669 epoch 10 - iter 60/150 - loss 0.00523960 - time (sec): 184.18 - samples/sec: 437.00 - lr: 0.000007 - momentum: 0.000000
2023-07-08 00:34:56,859 epoch 10 - iter 75/150 - loss 0.00548857 - time (sec): 230.37 - samples/sec: 436.54 - lr: 0.000006 - momentum: 0.000000
2023-07-08 00:35:40,955 epoch 10 - iter 90/150 - loss 0.00526611 - time (sec): 274.47 - samples/sec: 443.24 - lr: 0.000005 - momentum: 0.000000
2023-07-08 00:36:26,603 epoch 10 - iter 105/150 - loss 0.00535468 - time (sec): 320.12 - samples/sec: 444.78 - lr: 0.000004 - momentum: 0.000000
2023-07-08 00:37:11,394 epoch 10 - iter 120/150 - loss 0.00505431 - time (sec): 364.91 - samples/sec: 447.03 - lr: 0.000003 - momentum: 0.000000
2023-07-08 00:37:57,261 epoch 10 - iter 135/150 - loss 0.00538528 - time (sec): 410.78 - samples/sec: 449.28 - lr: 0.000002 - momentum: 0.000000
2023-07-08 00:38:41,777 epoch 10 - iter 150/150 - loss 0.00534634 - time (sec): 455.29 - samples/sec: 449.31 - lr: 0.000001 - momentum: 0.000000
2023-07-08 00:38:41,778 ----------------------------------------------------------------------------------------------------
2023-07-08 00:38:41,778 EPOCH 10 done: loss 0.0053 - lr: 0.000001
2023-07-08 00:39:30,118 DEV : loss 0.20147503912448883 - f1-score (micro avg)  0.7183
2023-07-08 00:40:17,053 TEST : loss 0.09689409285783768 - f1-score (micro avg)  0.9355
2023-07-08 00:40:31,721 ----------------------------------------------------------------------------------------------------
2023-07-08 00:40:31,725 Testing using last state of model ...
2023-07-08 00:41:19,797 
Results:
- F-score (micro) 0.9355
- F-score (macro) 0.9212
- Accuracy 0.9046

By class:
              precision    recall  f1-score   support

         ORG     0.9038    0.9500    0.9263      1661
         LOC     0.9501    0.9359    0.9429      1668
         PER     0.9833    0.9833    0.9833      1617
        MISC     0.8145    0.8504    0.8321       702

   micro avg     0.9280    0.9430    0.9355      5648
   macro avg     0.9129    0.9299    0.9212      5648
weighted avg     0.9291    0.9430    0.9358      5648

2023-07-08 00:41:19,797 ----------------------------------------------------------------------------------------------------
