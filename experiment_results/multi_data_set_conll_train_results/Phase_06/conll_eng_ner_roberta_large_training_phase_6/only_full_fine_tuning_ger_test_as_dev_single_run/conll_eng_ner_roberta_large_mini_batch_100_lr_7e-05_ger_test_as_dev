2023-07-07 19:59:58,583 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,585 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-07 19:59:58,585 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,585 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-07 19:59:58,585 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,585 Train:  14987 sentences
2023-07-07 19:59:58,585         (train_with_dev=False, train_with_test=False)
2023-07-07 19:59:58,585 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,585 Training Params:
2023-07-07 19:59:58,585  - learning_rate: "7e-05" 
2023-07-07 19:59:58,585  - mini_batch_size: "100"
2023-07-07 19:59:58,585  - max_epochs: "10"
2023-07-07 19:59:58,585  - shuffle: "True"
2023-07-07 19:59:58,585 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,586 Plugins:
2023-07-07 19:59:58,586  - LinearScheduler | warmup_fraction: '0.1'
2023-07-07 19:59:58,586 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,586 Final evaluation on model after last epoch (final-model.pt)
2023-07-07 19:59:58,586  - metric: "('micro avg', 'f1-score')"
2023-07-07 19:59:58,586 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,586 Computation:
2023-07-07 19:59:58,586  - compute on device: cuda:1
2023-07-07 19:59:58,586  - embedding storage: none
2023-07-07 19:59:58,586 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,586 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_7e-05_ger_test_as_dev"
2023-07-07 19:59:58,586 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,586 Removed gradient clipping
2023-07-07 19:59:58,586 ----------------------------------------------------------------------------------------------------
2023-07-07 19:59:58,586 ----------------------------------------------------------------------------------------------------
2023-07-07 20:00:46,639 epoch 1 - iter 15/150 - loss 3.05657952 - time (sec): 48.05 - samples/sec: 427.79 - lr: 0.000007 - momentum: 0.000000
2023-07-07 20:01:35,868 epoch 1 - iter 30/150 - loss 2.18816576 - time (sec): 97.28 - samples/sec: 426.32 - lr: 0.000014 - momentum: 0.000000
2023-07-07 20:02:24,974 epoch 1 - iter 45/150 - loss 1.68993040 - time (sec): 146.39 - samples/sec: 422.18 - lr: 0.000021 - momentum: 0.000000
2023-07-07 20:03:10,240 epoch 1 - iter 60/150 - loss 1.40865264 - time (sec): 191.65 - samples/sec: 426.22 - lr: 0.000028 - momentum: 0.000000
2023-07-07 20:03:56,227 epoch 1 - iter 75/150 - loss 1.22411078 - time (sec): 237.64 - samples/sec: 428.00 - lr: 0.000035 - momentum: 0.000000
2023-07-07 20:04:42,131 epoch 1 - iter 90/150 - loss 1.06860656 - time (sec): 283.54 - samples/sec: 432.38 - lr: 0.000042 - momentum: 0.000000
2023-07-07 20:05:28,396 epoch 1 - iter 105/150 - loss 0.94118855 - time (sec): 329.81 - samples/sec: 436.18 - lr: 0.000049 - momentum: 0.000000
2023-07-07 20:06:14,181 epoch 1 - iter 120/150 - loss 0.84221916 - time (sec): 375.59 - samples/sec: 437.10 - lr: 0.000056 - momentum: 0.000000
2023-07-07 20:07:00,339 epoch 1 - iter 135/150 - loss 0.76188852 - time (sec): 421.75 - samples/sec: 437.90 - lr: 0.000063 - momentum: 0.000000
2023-07-07 20:07:46,642 epoch 1 - iter 150/150 - loss 0.69721489 - time (sec): 468.05 - samples/sec: 437.06 - lr: 0.000070 - momentum: 0.000000
2023-07-07 20:07:46,642 ----------------------------------------------------------------------------------------------------
2023-07-07 20:07:46,642 EPOCH 1 done: loss 0.6972 - lr: 0.000070
2023-07-07 20:08:29,925 DEV : loss 0.17005713284015656 - f1-score (micro avg)  0.6887
2023-07-07 20:09:12,585 TEST : loss 0.10763511806726456 - f1-score (micro avg)  0.8938
2023-07-07 20:09:12,639 ----------------------------------------------------------------------------------------------------
2023-07-07 20:09:57,734 epoch 2 - iter 15/150 - loss 0.11877529 - time (sec): 45.09 - samples/sec: 458.12 - lr: 0.000069 - momentum: 0.000000
2023-07-07 20:10:47,862 epoch 2 - iter 30/150 - loss 0.13538001 - time (sec): 95.22 - samples/sec: 428.84 - lr: 0.000069 - momentum: 0.000000
2023-07-07 20:11:36,122 epoch 2 - iter 45/150 - loss 0.15416097 - time (sec): 143.48 - samples/sec: 426.39 - lr: 0.000068 - momentum: 0.000000
2023-07-07 20:12:24,107 epoch 2 - iter 60/150 - loss 0.17121431 - time (sec): 191.47 - samples/sec: 430.08 - lr: 0.000067 - momentum: 0.000000
2023-07-07 20:13:12,030 epoch 2 - iter 75/150 - loss 0.16651912 - time (sec): 239.39 - samples/sec: 429.53 - lr: 0.000066 - momentum: 0.000000
2023-07-07 20:14:01,364 epoch 2 - iter 90/150 - loss 0.16653074 - time (sec): 288.72 - samples/sec: 426.54 - lr: 0.000065 - momentum: 0.000000
2023-07-07 20:14:49,756 epoch 2 - iter 105/150 - loss 0.18030336 - time (sec): 337.11 - samples/sec: 427.09 - lr: 0.000065 - momentum: 0.000000
2023-07-07 20:15:36,921 epoch 2 - iter 120/150 - loss 0.17702065 - time (sec): 384.28 - samples/sec: 427.68 - lr: 0.000064 - momentum: 0.000000
2023-07-07 20:16:22,673 epoch 2 - iter 135/150 - loss 0.16938835 - time (sec): 430.03 - samples/sec: 428.92 - lr: 0.000063 - momentum: 0.000000
2023-07-07 20:17:08,574 epoch 2 - iter 150/150 - loss 0.15997473 - time (sec): 475.93 - samples/sec: 429.82 - lr: 0.000062 - momentum: 0.000000
2023-07-07 20:17:08,575 ----------------------------------------------------------------------------------------------------
2023-07-07 20:17:08,575 EPOCH 2 done: loss 0.1600 - lr: 0.000062
2023-07-07 20:17:51,634 DEV : loss 0.19813375174999237 - f1-score (micro avg)  0.6849
2023-07-07 20:18:34,486 TEST : loss 0.10311637818813324 - f1-score (micro avg)  0.9085
2023-07-07 20:18:34,532 ----------------------------------------------------------------------------------------------------
2023-07-07 20:19:19,720 epoch 3 - iter 15/150 - loss 0.07775307 - time (sec): 45.19 - samples/sec: 453.49 - lr: 0.000062 - momentum: 0.000000
2023-07-07 20:20:04,263 epoch 3 - iter 30/150 - loss 0.09658938 - time (sec): 89.73 - samples/sec: 455.81 - lr: 0.000061 - momentum: 0.000000
2023-07-07 20:20:49,269 epoch 3 - iter 45/150 - loss 0.09747773 - time (sec): 134.74 - samples/sec: 454.90 - lr: 0.000060 - momentum: 0.000000
2023-07-07 20:21:35,531 epoch 3 - iter 60/150 - loss 0.09553055 - time (sec): 181.00 - samples/sec: 452.75 - lr: 0.000059 - momentum: 0.000000
2023-07-07 20:22:22,053 epoch 3 - iter 75/150 - loss 0.09293711 - time (sec): 227.52 - samples/sec: 450.96 - lr: 0.000058 - momentum: 0.000000
2023-07-07 20:23:07,709 epoch 3 - iter 90/150 - loss 0.09005888 - time (sec): 273.18 - samples/sec: 449.16 - lr: 0.000058 - momentum: 0.000000
2023-07-07 20:23:55,471 epoch 3 - iter 105/150 - loss 0.08758303 - time (sec): 320.94 - samples/sec: 447.44 - lr: 0.000057 - momentum: 0.000000
2023-07-07 20:24:43,198 epoch 3 - iter 120/150 - loss 0.08571973 - time (sec): 368.67 - samples/sec: 445.55 - lr: 0.000056 - momentum: 0.000000
2023-07-07 20:25:30,772 epoch 3 - iter 135/150 - loss 0.08438785 - time (sec): 416.24 - samples/sec: 441.55 - lr: 0.000055 - momentum: 0.000000
2023-07-07 20:26:17,849 epoch 3 - iter 150/150 - loss 0.08311903 - time (sec): 463.32 - samples/sec: 441.53 - lr: 0.000055 - momentum: 0.000000
2023-07-07 20:26:17,849 ----------------------------------------------------------------------------------------------------
2023-07-07 20:26:17,849 EPOCH 3 done: loss 0.0831 - lr: 0.000055
2023-07-07 20:27:05,831 DEV : loss 0.17948777973651886 - f1-score (micro avg)  0.688
2023-07-07 20:27:52,406 TEST : loss 0.09441827982664108 - f1-score (micro avg)  0.9133
2023-07-07 20:27:52,460 ----------------------------------------------------------------------------------------------------
2023-07-07 20:28:41,119 epoch 4 - iter 15/150 - loss 0.05797404 - time (sec): 48.66 - samples/sec: 419.14 - lr: 0.000054 - momentum: 0.000000
2023-07-07 20:29:26,508 epoch 4 - iter 30/150 - loss 0.05351917 - time (sec): 94.05 - samples/sec: 438.90 - lr: 0.000053 - momentum: 0.000000
2023-07-07 20:30:12,217 epoch 4 - iter 45/150 - loss 0.05022862 - time (sec): 139.76 - samples/sec: 444.63 - lr: 0.000052 - momentum: 0.000000
2023-07-07 20:30:57,262 epoch 4 - iter 60/150 - loss 0.04853633 - time (sec): 184.80 - samples/sec: 446.07 - lr: 0.000051 - momentum: 0.000000
2023-07-07 20:31:41,415 epoch 4 - iter 75/150 - loss 0.04863260 - time (sec): 228.95 - samples/sec: 442.71 - lr: 0.000051 - momentum: 0.000000
2023-07-07 20:32:26,611 epoch 4 - iter 90/150 - loss 0.04868511 - time (sec): 274.15 - samples/sec: 445.57 - lr: 0.000050 - momentum: 0.000000
2023-07-07 20:33:11,029 epoch 4 - iter 105/150 - loss 0.04842947 - time (sec): 318.57 - samples/sec: 449.46 - lr: 0.000049 - momentum: 0.000000
2023-07-07 20:33:56,345 epoch 4 - iter 120/150 - loss 0.04742766 - time (sec): 363.88 - samples/sec: 450.71 - lr: 0.000048 - momentum: 0.000000
2023-07-07 20:34:43,470 epoch 4 - iter 135/150 - loss 0.04652302 - time (sec): 411.01 - samples/sec: 448.39 - lr: 0.000048 - momentum: 0.000000
2023-07-07 20:35:27,979 epoch 4 - iter 150/150 - loss 0.04578566 - time (sec): 455.52 - samples/sec: 449.09 - lr: 0.000047 - momentum: 0.000000
2023-07-07 20:35:27,980 ----------------------------------------------------------------------------------------------------
2023-07-07 20:35:27,980 EPOCH 4 done: loss 0.0458 - lr: 0.000047
2023-07-07 20:36:16,080 DEV : loss 0.16848726570606232 - f1-score (micro avg)  0.7143
2023-07-07 20:37:03,392 TEST : loss 0.0825871080160141 - f1-score (micro avg)  0.9295
2023-07-07 20:37:03,450 ----------------------------------------------------------------------------------------------------
2023-07-07 20:37:52,382 epoch 5 - iter 15/150 - loss 0.03236283 - time (sec): 48.93 - samples/sec: 405.42 - lr: 0.000046 - momentum: 0.000000
2023-07-07 20:38:41,233 epoch 5 - iter 30/150 - loss 0.03231505 - time (sec): 97.78 - samples/sec: 412.16 - lr: 0.000045 - momentum: 0.000000
2023-07-07 20:39:29,700 epoch 5 - iter 45/150 - loss 0.03371343 - time (sec): 146.25 - samples/sec: 410.80 - lr: 0.000045 - momentum: 0.000000
2023-07-07 20:40:19,544 epoch 5 - iter 60/150 - loss 0.03312244 - time (sec): 196.09 - samples/sec: 412.34 - lr: 0.000044 - momentum: 0.000000
2023-07-07 20:41:09,094 epoch 5 - iter 75/150 - loss 0.03355464 - time (sec): 245.64 - samples/sec: 417.26 - lr: 0.000043 - momentum: 0.000000
2023-07-07 20:41:55,319 epoch 5 - iter 90/150 - loss 0.03283298 - time (sec): 291.87 - samples/sec: 423.12 - lr: 0.000042 - momentum: 0.000000
2023-07-07 20:42:41,896 epoch 5 - iter 105/150 - loss 0.03312055 - time (sec): 338.44 - samples/sec: 423.74 - lr: 0.000041 - momentum: 0.000000
2023-07-07 20:43:28,154 epoch 5 - iter 120/150 - loss 0.03344922 - time (sec): 384.70 - samples/sec: 426.63 - lr: 0.000041 - momentum: 0.000000
2023-07-07 20:44:13,937 epoch 5 - iter 135/150 - loss 0.03385514 - time (sec): 430.49 - samples/sec: 428.67 - lr: 0.000040 - momentum: 0.000000
2023-07-07 20:44:58,802 epoch 5 - iter 150/150 - loss 0.03425753 - time (sec): 475.35 - samples/sec: 430.35 - lr: 0.000039 - momentum: 0.000000
2023-07-07 20:44:58,803 ----------------------------------------------------------------------------------------------------
2023-07-07 20:44:58,803 EPOCH 5 done: loss 0.0343 - lr: 0.000039
2023-07-07 20:45:47,122 DEV : loss 0.15000976622104645 - f1-score (micro avg)  0.7442
2023-07-07 20:46:30,052 TEST : loss 0.09090963751077652 - f1-score (micro avg)  0.928
2023-07-07 20:46:30,126 ----------------------------------------------------------------------------------------------------
2023-07-07 20:47:16,272 epoch 6 - iter 15/150 - loss 0.02894854 - time (sec): 46.14 - samples/sec: 453.59 - lr: 0.000038 - momentum: 0.000000
2023-07-07 20:48:02,445 epoch 6 - iter 30/150 - loss 0.02934619 - time (sec): 92.32 - samples/sec: 448.67 - lr: 0.000038 - momentum: 0.000000
2023-07-07 20:48:47,614 epoch 6 - iter 45/150 - loss 0.02967829 - time (sec): 137.48 - samples/sec: 446.10 - lr: 0.000037 - momentum: 0.000000
2023-07-07 20:49:35,646 epoch 6 - iter 60/150 - loss 0.02907974 - time (sec): 185.52 - samples/sec: 439.75 - lr: 0.000036 - momentum: 0.000000
2023-07-07 20:50:24,119 epoch 6 - iter 75/150 - loss 0.02918345 - time (sec): 233.99 - samples/sec: 438.86 - lr: 0.000035 - momentum: 0.000000
2023-07-07 20:51:12,585 epoch 6 - iter 90/150 - loss 0.02955954 - time (sec): 282.46 - samples/sec: 436.78 - lr: 0.000034 - momentum: 0.000000
2023-07-07 20:52:00,342 epoch 6 - iter 105/150 - loss 0.02974807 - time (sec): 330.21 - samples/sec: 435.28 - lr: 0.000034 - momentum: 0.000000
2023-07-07 20:52:47,834 epoch 6 - iter 120/150 - loss 0.03073113 - time (sec): 377.71 - samples/sec: 434.31 - lr: 0.000033 - momentum: 0.000000
2023-07-07 20:53:34,875 epoch 6 - iter 135/150 - loss 0.03040067 - time (sec): 424.75 - samples/sec: 433.82 - lr: 0.000032 - momentum: 0.000000
2023-07-07 20:54:21,494 epoch 6 - iter 150/150 - loss 0.03056984 - time (sec): 471.37 - samples/sec: 433.99 - lr: 0.000031 - momentum: 0.000000
2023-07-07 20:54:21,495 ----------------------------------------------------------------------------------------------------
2023-07-07 20:54:21,495 EPOCH 6 done: loss 0.0306 - lr: 0.000031
2023-07-07 20:55:05,427 DEV : loss 0.16253530979156494 - f1-score (micro avg)  0.7306
2023-07-07 20:55:48,673 TEST : loss 0.09504274278879166 - f1-score (micro avg)  0.922
2023-07-07 20:55:48,727 ----------------------------------------------------------------------------------------------------
2023-07-07 20:56:31,386 epoch 7 - iter 15/150 - loss 0.02865192 - time (sec): 42.66 - samples/sec: 474.01 - lr: 0.000031 - momentum: 0.000000
2023-07-07 20:57:15,752 epoch 7 - iter 30/150 - loss 0.02716168 - time (sec): 87.02 - samples/sec: 469.42 - lr: 0.000030 - momentum: 0.000000
2023-07-07 20:58:01,792 epoch 7 - iter 45/150 - loss 0.02586346 - time (sec): 133.06 - samples/sec: 462.28 - lr: 0.000029 - momentum: 0.000000
2023-07-07 20:58:45,818 epoch 7 - iter 60/150 - loss 0.02640817 - time (sec): 177.09 - samples/sec: 463.29 - lr: 0.000028 - momentum: 0.000000
2023-07-07 20:59:31,702 epoch 7 - iter 75/150 - loss 0.02908792 - time (sec): 222.97 - samples/sec: 461.19 - lr: 0.000028 - momentum: 0.000000
2023-07-07 21:00:17,078 epoch 7 - iter 90/150 - loss 0.02889659 - time (sec): 268.35 - samples/sec: 458.00 - lr: 0.000027 - momentum: 0.000000
2023-07-07 21:01:03,099 epoch 7 - iter 105/150 - loss 0.02910227 - time (sec): 314.37 - samples/sec: 456.76 - lr: 0.000026 - momentum: 0.000000
2023-07-07 21:01:49,469 epoch 7 - iter 120/150 - loss 0.02828553 - time (sec): 360.74 - samples/sec: 454.26 - lr: 0.000025 - momentum: 0.000000
2023-07-07 21:02:38,353 epoch 7 - iter 135/150 - loss 0.02773420 - time (sec): 409.62 - samples/sec: 450.10 - lr: 0.000024 - momentum: 0.000000
2023-07-07 21:03:25,993 epoch 7 - iter 150/150 - loss 0.02724253 - time (sec): 457.26 - samples/sec: 447.37 - lr: 0.000024 - momentum: 0.000000
2023-07-07 21:03:25,994 ----------------------------------------------------------------------------------------------------
2023-07-07 21:03:25,994 EPOCH 7 done: loss 0.0272 - lr: 0.000024
2023-07-07 21:04:14,154 DEV : loss 0.18484023213386536 - f1-score (micro avg)  0.7192
2023-07-07 21:05:01,930 TEST : loss 0.09263837337493896 - f1-score (micro avg)  0.9301
2023-07-07 21:05:02,119 ----------------------------------------------------------------------------------------------------
2023-07-07 21:05:50,520 epoch 8 - iter 15/150 - loss 0.02306572 - time (sec): 48.40 - samples/sec: 431.00 - lr: 0.000023 - momentum: 0.000000
2023-07-07 21:06:39,128 epoch 8 - iter 30/150 - loss 0.02188186 - time (sec): 97.00 - samples/sec: 425.89 - lr: 0.000022 - momentum: 0.000000
2023-07-07 21:07:25,900 epoch 8 - iter 45/150 - loss 0.02078990 - time (sec): 143.78 - samples/sec: 431.34 - lr: 0.000021 - momentum: 0.000000
2023-07-07 21:08:11,272 epoch 8 - iter 60/150 - loss 0.02042697 - time (sec): 189.15 - samples/sec: 436.28 - lr: 0.000021 - momentum: 0.000000
2023-07-07 21:08:56,938 epoch 8 - iter 75/150 - loss 0.02003906 - time (sec): 234.81 - samples/sec: 436.95 - lr: 0.000020 - momentum: 0.000000
2023-07-07 21:09:42,399 epoch 8 - iter 90/150 - loss 0.01940043 - time (sec): 280.28 - samples/sec: 438.49 - lr: 0.000019 - momentum: 0.000000
2023-07-07 21:10:28,182 epoch 8 - iter 105/150 - loss 0.01942483 - time (sec): 326.06 - samples/sec: 440.13 - lr: 0.000018 - momentum: 0.000000
2023-07-07 21:11:13,020 epoch 8 - iter 120/150 - loss 0.01957821 - time (sec): 370.90 - samples/sec: 440.74 - lr: 0.000017 - momentum: 0.000000
2023-07-07 21:11:59,231 epoch 8 - iter 135/150 - loss 0.01881859 - time (sec): 417.11 - samples/sec: 440.34 - lr: 0.000017 - momentum: 0.000000
2023-07-07 21:12:46,193 epoch 8 - iter 150/150 - loss 0.01891567 - time (sec): 464.07 - samples/sec: 440.81 - lr: 0.000016 - momentum: 0.000000
2023-07-07 21:12:46,194 ----------------------------------------------------------------------------------------------------
2023-07-07 21:12:46,194 EPOCH 8 done: loss 0.0189 - lr: 0.000016
2023-07-07 21:13:29,730 DEV : loss 0.1890747845172882 - f1-score (micro avg)  0.7288
2023-07-07 21:14:14,931 TEST : loss 0.09561608731746674 - f1-score (micro avg)  0.9312
2023-07-07 21:14:14,992 ----------------------------------------------------------------------------------------------------
2023-07-07 21:15:03,346 epoch 9 - iter 15/150 - loss 0.01384274 - time (sec): 48.35 - samples/sec: 419.39 - lr: 0.000015 - momentum: 0.000000
2023-07-07 21:15:52,590 epoch 9 - iter 30/150 - loss 0.01418723 - time (sec): 97.60 - samples/sec: 411.91 - lr: 0.000014 - momentum: 0.000000
2023-07-07 21:16:41,540 epoch 9 - iter 45/150 - loss 0.01537918 - time (sec): 146.55 - samples/sec: 418.81 - lr: 0.000014 - momentum: 0.000000
2023-07-07 21:17:29,892 epoch 9 - iter 60/150 - loss 0.01592784 - time (sec): 194.90 - samples/sec: 422.64 - lr: 0.000013 - momentum: 0.000000
2023-07-07 21:18:17,692 epoch 9 - iter 75/150 - loss 0.01762906 - time (sec): 242.70 - samples/sec: 420.81 - lr: 0.000012 - momentum: 0.000000
2023-07-07 21:19:05,836 epoch 9 - iter 90/150 - loss 0.01681639 - time (sec): 290.84 - samples/sec: 421.71 - lr: 0.000011 - momentum: 0.000000
2023-07-07 21:19:53,923 epoch 9 - iter 105/150 - loss 0.01664054 - time (sec): 338.93 - samples/sec: 422.75 - lr: 0.000011 - momentum: 0.000000
2023-07-07 21:20:40,247 epoch 9 - iter 120/150 - loss 0.01609184 - time (sec): 385.25 - samples/sec: 426.78 - lr: 0.000010 - momentum: 0.000000
2023-07-07 21:21:25,945 epoch 9 - iter 135/150 - loss 0.01640943 - time (sec): 430.95 - samples/sec: 426.57 - lr: 0.000009 - momentum: 0.000000
2023-07-07 21:22:11,643 epoch 9 - iter 150/150 - loss 0.01599706 - time (sec): 476.65 - samples/sec: 429.18 - lr: 0.000008 - momentum: 0.000000
2023-07-07 21:22:11,644 ----------------------------------------------------------------------------------------------------
2023-07-07 21:22:11,644 EPOCH 9 done: loss 0.0160 - lr: 0.000008
2023-07-07 21:22:55,411 DEV : loss 0.16172456741333008 - f1-score (micro avg)  0.7547
2023-07-07 21:23:38,042 TEST : loss 0.0923508033156395 - f1-score (micro avg)  0.9344
2023-07-07 21:23:38,104 ----------------------------------------------------------------------------------------------------
2023-07-07 21:24:25,436 epoch 10 - iter 15/150 - loss 0.01097891 - time (sec): 47.33 - samples/sec: 435.35 - lr: 0.000007 - momentum: 0.000000
2023-07-07 21:25:11,798 epoch 10 - iter 30/150 - loss 0.01228299 - time (sec): 93.69 - samples/sec: 432.53 - lr: 0.000007 - momentum: 0.000000
2023-07-07 21:25:57,687 epoch 10 - iter 45/150 - loss 0.01170991 - time (sec): 139.58 - samples/sec: 437.81 - lr: 0.000006 - momentum: 0.000000
2023-07-07 21:26:42,350 epoch 10 - iter 60/150 - loss 0.01179853 - time (sec): 184.24 - samples/sec: 440.40 - lr: 0.000005 - momentum: 0.000000
2023-07-07 21:27:28,824 epoch 10 - iter 75/150 - loss 0.01197817 - time (sec): 230.72 - samples/sec: 438.09 - lr: 0.000004 - momentum: 0.000000
2023-07-07 21:28:18,170 epoch 10 - iter 90/150 - loss 0.01228851 - time (sec): 280.06 - samples/sec: 432.90 - lr: 0.000004 - momentum: 0.000000
2023-07-07 21:29:05,983 epoch 10 - iter 105/150 - loss 0.01246114 - time (sec): 327.88 - samples/sec: 434.84 - lr: 0.000003 - momentum: 0.000000
2023-07-07 21:29:55,082 epoch 10 - iter 120/150 - loss 0.01198372 - time (sec): 376.98 - samples/sec: 431.67 - lr: 0.000002 - momentum: 0.000000
2023-07-07 21:30:43,129 epoch 10 - iter 135/150 - loss 0.01199593 - time (sec): 425.02 - samples/sec: 431.89 - lr: 0.000001 - momentum: 0.000000
2023-07-07 21:31:30,586 epoch 10 - iter 150/150 - loss 0.01232041 - time (sec): 472.48 - samples/sec: 432.96 - lr: 0.000000 - momentum: 0.000000
2023-07-07 21:31:30,587 ----------------------------------------------------------------------------------------------------
2023-07-07 21:31:30,587 EPOCH 10 done: loss 0.0123 - lr: 0.000000
2023-07-07 21:32:18,880 DEV : loss 0.17796605825424194 - f1-score (micro avg)  0.7466
2023-07-07 21:33:02,337 TEST : loss 0.09658418595790863 - f1-score (micro avg)  0.9339
2023-07-07 21:33:18,127 ----------------------------------------------------------------------------------------------------
2023-07-07 21:33:18,132 Testing using last state of model ...
2023-07-07 21:34:01,109 
Results:
- F-score (micro) 0.9339
- F-score (macro) 0.9186
- Accuracy 0.9011

By class:
              precision    recall  f1-score   support

         ORG     0.9107    0.9392    0.9247      1661
         LOC     0.9441    0.9412    0.9427      1668
         PER     0.9876    0.9814    0.9845      1617
        MISC     0.7979    0.8490    0.8226       702

   micro avg     0.9272    0.9407    0.9339      5648
   macro avg     0.9100    0.9277    0.9186      5648
weighted avg     0.9285    0.9407    0.9344      5648

2023-07-07 21:34:01,110 ----------------------------------------------------------------------------------------------------
