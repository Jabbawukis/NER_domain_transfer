2023-07-12 14:06:22,299 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,300 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-12 14:06:22,300 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,300 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-12 14:06:22,300 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,300 Train:  14987 sentences
2023-07-12 14:06:22,300         (train_with_dev=False, train_with_test=False)
2023-07-12 14:06:22,300 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,300 Training Params:
2023-07-12 14:06:22,300  - learning_rate: "5e-05" 
2023-07-12 14:06:22,300  - mini_batch_size: "400"
2023-07-12 14:06:22,300  - max_epochs: "10"
2023-07-12 14:06:22,300  - shuffle: "True"
2023-07-12 14:06:22,300 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,300 Plugins:
2023-07-12 14:06:22,301  - LinearScheduler | warmup_fraction: '0.1'
2023-07-12 14:06:22,301 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,301 Final evaluation on model after last epoch (final-model.pt)
2023-07-12 14:06:22,301  - metric: "('micro avg', 'f1-score')"
2023-07-12 14:06:22,301 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,301 Computation:
2023-07-12 14:06:22,301  - compute on device: cuda:3
2023-07-12 14:06:22,301  - embedding storage: none
2023-07-12 14:06:22,301 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,301 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_400_lr_5e-05_run_1_ger_test_as_dev"
2023-07-12 14:06:22,301 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,301 Removed gradient clipping
2023-07-12 14:06:22,301 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:22,301 ----------------------------------------------------------------------------------------------------
2023-07-12 14:06:57,592 epoch 1 - iter 3/38 - loss 3.02426408 - time (sec): 35.29 - samples/sec: 451.55 - lr: 0.000003 - momentum: 0.000000
2023-07-12 14:07:31,433 epoch 1 - iter 6/38 - loss 2.96014500 - time (sec): 69.13 - samples/sec: 474.11 - lr: 0.000007 - momentum: 0.000000
2023-07-12 14:08:05,788 epoch 1 - iter 9/38 - loss 2.83549565 - time (sec): 103.49 - samples/sec: 475.32 - lr: 0.000011 - momentum: 0.000000
2023-07-12 14:08:40,656 epoch 1 - iter 12/38 - loss 2.60507877 - time (sec): 138.35 - samples/sec: 472.89 - lr: 0.000014 - momentum: 0.000000
2023-07-12 14:09:17,403 epoch 1 - iter 15/38 - loss 2.30319263 - time (sec): 175.10 - samples/sec: 463.11 - lr: 0.000018 - momentum: 0.000000
2023-07-12 14:09:54,830 epoch 1 - iter 18/38 - loss 2.08756499 - time (sec): 212.53 - samples/sec: 461.12 - lr: 0.000022 - momentum: 0.000000
2023-07-12 14:10:31,337 epoch 1 - iter 21/38 - loss 1.90082154 - time (sec): 249.04 - samples/sec: 462.27 - lr: 0.000026 - momentum: 0.000000
2023-07-12 14:11:06,589 epoch 1 - iter 24/38 - loss 1.76206396 - time (sec): 284.29 - samples/sec: 461.28 - lr: 0.000030 - momentum: 0.000000
2023-07-12 14:11:40,381 epoch 1 - iter 27/38 - loss 1.63921056 - time (sec): 318.08 - samples/sec: 463.46 - lr: 0.000034 - momentum: 0.000000
2023-07-12 14:12:24,998 epoch 1 - iter 30/38 - loss 1.53324933 - time (sec): 362.70 - samples/sec: 452.66 - lr: 0.000038 - momentum: 0.000000
2023-07-12 14:13:21,344 epoch 1 - iter 33/38 - loss 1.44741555 - time (sec): 419.04 - samples/sec: 429.15 - lr: 0.000042 - momentum: 0.000000
2023-07-12 14:14:17,413 epoch 1 - iter 36/38 - loss 1.36725576 - time (sec): 475.11 - samples/sec: 413.53 - lr: 0.000046 - momentum: 0.000000
2023-07-12 14:14:35,682 ----------------------------------------------------------------------------------------------------
2023-07-12 14:14:35,682 EPOCH 1 done: loss 1.3325 - lr: 0.000046
2023-07-12 14:15:20,423 DEV : loss 0.2657344937324524 - f1-score (micro avg)  0.4895
2023-07-12 14:16:01,996 TEST : loss 0.3794268071651459 - f1-score (micro avg)  0.5064
2023-07-12 14:16:02,045 ----------------------------------------------------------------------------------------------------
2023-07-12 14:16:37,999 epoch 2 - iter 3/38 - loss 0.43730903 - time (sec): 35.95 - samples/sec: 445.09 - lr: 0.000050 - momentum: 0.000000
2023-07-12 14:17:14,152 epoch 2 - iter 6/38 - loss 0.39980817 - time (sec): 72.11 - samples/sec: 446.42 - lr: 0.000049 - momentum: 0.000000
2023-07-12 14:17:50,458 epoch 2 - iter 9/38 - loss 0.37914670 - time (sec): 108.41 - samples/sec: 448.42 - lr: 0.000049 - momentum: 0.000000
2023-07-12 14:18:26,811 epoch 2 - iter 12/38 - loss 0.36754770 - time (sec): 144.76 - samples/sec: 450.70 - lr: 0.000048 - momentum: 0.000000
2023-07-12 14:19:02,518 epoch 2 - iter 15/38 - loss 0.34834338 - time (sec): 180.47 - samples/sec: 451.66 - lr: 0.000048 - momentum: 0.000000
2023-07-12 14:19:36,326 epoch 2 - iter 18/38 - loss 0.33417142 - time (sec): 214.28 - samples/sec: 454.22 - lr: 0.000048 - momentum: 0.000000
2023-07-12 14:20:12,139 epoch 2 - iter 21/38 - loss 0.31702454 - time (sec): 250.09 - samples/sec: 455.67 - lr: 0.000047 - momentum: 0.000000
2023-07-12 14:20:49,133 epoch 2 - iter 24/38 - loss 0.30392330 - time (sec): 287.09 - samples/sec: 455.99 - lr: 0.000047 - momentum: 0.000000
2023-07-12 14:21:26,066 epoch 2 - iter 27/38 - loss 0.28995053 - time (sec): 324.02 - samples/sec: 453.77 - lr: 0.000046 - momentum: 0.000000
2023-07-12 14:22:02,542 epoch 2 - iter 30/38 - loss 0.27735421 - time (sec): 360.49 - samples/sec: 453.57 - lr: 0.000046 - momentum: 0.000000
2023-07-12 14:22:38,447 epoch 2 - iter 33/38 - loss 0.26542828 - time (sec): 396.40 - samples/sec: 454.29 - lr: 0.000045 - momentum: 0.000000
2023-07-12 14:23:14,636 epoch 2 - iter 36/38 - loss 0.25706380 - time (sec): 432.59 - samples/sec: 454.05 - lr: 0.000045 - momentum: 0.000000
2023-07-12 14:23:31,706 ----------------------------------------------------------------------------------------------------
2023-07-12 14:23:31,706 EPOCH 2 done: loss 0.2525 - lr: 0.000045
2023-07-12 14:24:18,257 DEV : loss 0.17875325679779053 - f1-score (micro avg)  0.705
2023-07-12 14:25:24,288 TEST : loss 0.10173545032739639 - f1-score (micro avg)  0.8969
2023-07-12 14:25:24,336 ----------------------------------------------------------------------------------------------------
2023-07-12 14:26:22,664 epoch 3 - iter 3/38 - loss 0.12518522 - time (sec): 58.33 - samples/sec: 283.44 - lr: 0.000044 - momentum: 0.000000
2023-07-12 14:27:01,740 epoch 3 - iter 6/38 - loss 0.12471494 - time (sec): 97.40 - samples/sec: 335.66 - lr: 0.000044 - momentum: 0.000000
2023-07-12 14:27:39,014 epoch 3 - iter 9/38 - loss 0.11520428 - time (sec): 134.68 - samples/sec: 362.11 - lr: 0.000043 - momentum: 0.000000
2023-07-12 14:28:14,414 epoch 3 - iter 12/38 - loss 0.11174618 - time (sec): 170.08 - samples/sec: 382.10 - lr: 0.000043 - momentum: 0.000000
2023-07-12 14:28:51,633 epoch 3 - iter 15/38 - loss 0.11061668 - time (sec): 207.30 - samples/sec: 392.87 - lr: 0.000042 - momentum: 0.000000
2023-07-12 14:29:26,889 epoch 3 - iter 18/38 - loss 0.10561019 - time (sec): 242.55 - samples/sec: 404.38 - lr: 0.000042 - momentum: 0.000000
2023-07-12 14:30:03,606 epoch 3 - iter 21/38 - loss 0.10350044 - time (sec): 279.27 - samples/sec: 411.06 - lr: 0.000042 - momentum: 0.000000
2023-07-12 14:30:40,242 epoch 3 - iter 24/38 - loss 0.10116605 - time (sec): 315.90 - samples/sec: 412.81 - lr: 0.000041 - momentum: 0.000000
2023-07-12 14:31:16,259 epoch 3 - iter 27/38 - loss 0.09904195 - time (sec): 351.92 - samples/sec: 414.28 - lr: 0.000041 - momentum: 0.000000
2023-07-12 14:31:49,858 epoch 3 - iter 30/38 - loss 0.09671189 - time (sec): 385.52 - samples/sec: 422.48 - lr: 0.000040 - momentum: 0.000000
2023-07-12 14:32:24,943 epoch 3 - iter 33/38 - loss 0.09474251 - time (sec): 420.61 - samples/sec: 427.85 - lr: 0.000040 - momentum: 0.000000
2023-07-12 14:32:59,955 epoch 3 - iter 36/38 - loss 0.09183643 - time (sec): 455.62 - samples/sec: 431.03 - lr: 0.000039 - momentum: 0.000000
2023-07-12 14:33:16,834 ----------------------------------------------------------------------------------------------------
2023-07-12 14:33:16,835 EPOCH 3 done: loss 0.0909 - lr: 0.000039
2023-07-12 14:33:58,951 DEV : loss 0.16380609571933746 - f1-score (micro avg)  0.7269
2023-07-12 14:34:40,325 TEST : loss 0.08501909673213959 - f1-score (micro avg)  0.9192
2023-07-12 14:34:40,387 ----------------------------------------------------------------------------------------------------
2023-07-12 14:35:17,000 epoch 4 - iter 3/38 - loss 0.05656325 - time (sec): 36.61 - samples/sec: 457.42 - lr: 0.000039 - momentum: 0.000000
2023-07-12 14:35:51,817 epoch 4 - iter 6/38 - loss 0.05930527 - time (sec): 71.43 - samples/sec: 454.75 - lr: 0.000038 - momentum: 0.000000
2023-07-12 14:36:27,692 epoch 4 - iter 9/38 - loss 0.05994941 - time (sec): 107.30 - samples/sec: 458.89 - lr: 0.000038 - momentum: 0.000000
2023-07-12 14:37:26,349 epoch 4 - iter 12/38 - loss 0.06006553 - time (sec): 165.96 - samples/sec: 394.29 - lr: 0.000037 - momentum: 0.000000
2023-07-12 14:38:24,966 epoch 4 - iter 15/38 - loss 0.06283776 - time (sec): 224.58 - samples/sec: 366.85 - lr: 0.000037 - momentum: 0.000000
2023-07-12 14:39:06,357 epoch 4 - iter 18/38 - loss 0.06688793 - time (sec): 265.97 - samples/sec: 371.25 - lr: 0.000037 - momentum: 0.000000
2023-07-12 14:39:43,064 epoch 4 - iter 21/38 - loss 0.06886756 - time (sec): 302.68 - samples/sec: 380.95 - lr: 0.000036 - momentum: 0.000000
2023-07-12 14:40:18,750 epoch 4 - iter 24/38 - loss 0.07023793 - time (sec): 338.36 - samples/sec: 387.37 - lr: 0.000036 - momentum: 0.000000
2023-07-12 14:40:54,785 epoch 4 - iter 27/38 - loss 0.07053681 - time (sec): 374.40 - samples/sec: 394.04 - lr: 0.000035 - momentum: 0.000000
2023-07-12 14:41:31,315 epoch 4 - iter 30/38 - loss 0.07020178 - time (sec): 410.93 - samples/sec: 398.32 - lr: 0.000035 - momentum: 0.000000
2023-07-12 14:42:07,905 epoch 4 - iter 33/38 - loss 0.06998641 - time (sec): 447.52 - samples/sec: 401.49 - lr: 0.000034 - momentum: 0.000000
2023-07-12 14:42:43,800 epoch 4 - iter 36/38 - loss 0.07030167 - time (sec): 483.41 - samples/sec: 405.88 - lr: 0.000034 - momentum: 0.000000
2023-07-12 14:43:02,218 ----------------------------------------------------------------------------------------------------
2023-07-12 14:43:02,218 EPOCH 4 done: loss 0.0701 - lr: 0.000034
2023-07-12 14:43:46,185 DEV : loss 0.16079244017601013 - f1-score (micro avg)  0.7531
2023-07-12 14:44:29,380 TEST : loss 0.09512264281511307 - f1-score (micro avg)  0.9143
2023-07-12 14:44:29,450 ----------------------------------------------------------------------------------------------------
2023-07-12 14:45:05,351 epoch 5 - iter 3/38 - loss 0.07685380 - time (sec): 35.90 - samples/sec: 455.09 - lr: 0.000033 - momentum: 0.000000
2023-07-12 14:45:41,638 epoch 5 - iter 6/38 - loss 0.06847467 - time (sec): 72.19 - samples/sec: 452.25 - lr: 0.000033 - momentum: 0.000000
2023-07-12 14:46:18,076 epoch 5 - iter 9/38 - loss 0.06410233 - time (sec): 108.62 - samples/sec: 450.36 - lr: 0.000032 - momentum: 0.000000
2023-07-12 14:46:54,057 epoch 5 - iter 12/38 - loss 0.06109728 - time (sec): 144.60 - samples/sec: 451.15 - lr: 0.000032 - momentum: 0.000000
2023-07-12 14:47:29,459 epoch 5 - iter 15/38 - loss 0.06017822 - time (sec): 180.01 - samples/sec: 453.13 - lr: 0.000032 - momentum: 0.000000
2023-07-12 14:48:03,055 epoch 5 - iter 18/38 - loss 0.05828447 - time (sec): 213.60 - samples/sec: 458.22 - lr: 0.000031 - momentum: 0.000000
2023-07-12 14:48:42,700 epoch 5 - iter 21/38 - loss 0.05726365 - time (sec): 253.25 - samples/sec: 451.00 - lr: 0.000031 - momentum: 0.000000
2023-07-12 14:49:42,305 epoch 5 - iter 24/38 - loss 0.05592254 - time (sec): 312.85 - samples/sec: 418.39 - lr: 0.000030 - momentum: 0.000000
2023-07-12 14:50:41,590 epoch 5 - iter 27/38 - loss 0.05548190 - time (sec): 372.14 - samples/sec: 396.75 - lr: 0.000030 - momentum: 0.000000
2023-07-12 14:51:19,416 epoch 5 - iter 30/38 - loss 0.05463032 - time (sec): 409.96 - samples/sec: 399.75 - lr: 0.000029 - momentum: 0.000000
2023-07-12 14:51:56,087 epoch 5 - iter 33/38 - loss 0.05396762 - time (sec): 446.63 - samples/sec: 402.60 - lr: 0.000029 - momentum: 0.000000
2023-07-12 14:52:32,921 epoch 5 - iter 36/38 - loss 0.05221678 - time (sec): 483.47 - samples/sec: 406.13 - lr: 0.000028 - momentum: 0.000000
2023-07-12 14:52:50,737 ----------------------------------------------------------------------------------------------------
2023-07-12 14:52:50,738 EPOCH 5 done: loss 0.0515 - lr: 0.000028
2023-07-12 14:53:34,502 DEV : loss 0.1713288575410843 - f1-score (micro avg)  0.7337
2023-07-12 14:54:15,086 TEST : loss 0.09947916865348816 - f1-score (micro avg)  0.9205
2023-07-12 14:54:15,137 ----------------------------------------------------------------------------------------------------
2023-07-12 14:54:51,446 epoch 6 - iter 3/38 - loss 0.04996582 - time (sec): 36.31 - samples/sec: 445.63 - lr: 0.000028 - momentum: 0.000000
2023-07-12 14:55:27,002 epoch 6 - iter 6/38 - loss 0.04341934 - time (sec): 71.86 - samples/sec: 453.05 - lr: 0.000027 - momentum: 0.000000
2023-07-12 14:56:00,978 epoch 6 - iter 9/38 - loss 0.04438293 - time (sec): 105.84 - samples/sec: 461.02 - lr: 0.000027 - momentum: 0.000000
2023-07-12 14:56:34,943 epoch 6 - iter 12/38 - loss 0.04311062 - time (sec): 139.80 - samples/sec: 467.68 - lr: 0.000026 - momentum: 0.000000
2023-07-12 14:57:11,214 epoch 6 - iter 15/38 - loss 0.04200843 - time (sec): 176.08 - samples/sec: 467.44 - lr: 0.000026 - momentum: 0.000000
2023-07-12 14:57:46,581 epoch 6 - iter 18/38 - loss 0.04198195 - time (sec): 211.44 - samples/sec: 464.44 - lr: 0.000026 - momentum: 0.000000
2023-07-12 14:58:23,140 epoch 6 - iter 21/38 - loss 0.04098618 - time (sec): 248.00 - samples/sec: 462.46 - lr: 0.000025 - momentum: 0.000000
2023-07-12 14:58:58,953 epoch 6 - iter 24/38 - loss 0.04035622 - time (sec): 283.81 - samples/sec: 460.77 - lr: 0.000025 - momentum: 0.000000
2023-07-12 14:59:34,975 epoch 6 - iter 27/38 - loss 0.03989245 - time (sec): 319.84 - samples/sec: 459.61 - lr: 0.000024 - momentum: 0.000000
2023-07-12 15:00:10,420 epoch 6 - iter 30/38 - loss 0.03929310 - time (sec): 355.28 - samples/sec: 460.46 - lr: 0.000024 - momentum: 0.000000
2023-07-12 15:00:51,759 epoch 6 - iter 33/38 - loss 0.03908796 - time (sec): 396.62 - samples/sec: 454.24 - lr: 0.000023 - momentum: 0.000000
2023-07-12 15:01:49,377 epoch 6 - iter 36/38 - loss 0.03902153 - time (sec): 454.24 - samples/sec: 433.73 - lr: 0.000023 - momentum: 0.000000
2023-07-12 15:02:18,221 ----------------------------------------------------------------------------------------------------
2023-07-12 15:02:18,221 EPOCH 6 done: loss 0.0390 - lr: 0.000023
2023-07-12 15:03:11,529 DEV : loss 0.16075177490711212 - f1-score (micro avg)  0.7444
2023-07-12 15:03:54,052 TEST : loss 0.08978430926799774 - f1-score (micro avg)  0.9266
2023-07-12 15:03:54,102 ----------------------------------------------------------------------------------------------------
2023-07-12 15:04:30,052 epoch 7 - iter 3/38 - loss 0.02860439 - time (sec): 35.95 - samples/sec: 466.17 - lr: 0.000022 - momentum: 0.000000
2023-07-12 15:05:05,809 epoch 7 - iter 6/38 - loss 0.03039040 - time (sec): 71.71 - samples/sec: 456.42 - lr: 0.000022 - momentum: 0.000000
2023-07-12 15:05:42,072 epoch 7 - iter 9/38 - loss 0.03149842 - time (sec): 107.97 - samples/sec: 449.20 - lr: 0.000021 - momentum: 0.000000
2023-07-12 15:06:18,673 epoch 7 - iter 12/38 - loss 0.03130736 - time (sec): 144.57 - samples/sec: 451.94 - lr: 0.000021 - momentum: 0.000000
2023-07-12 15:06:55,220 epoch 7 - iter 15/38 - loss 0.03113799 - time (sec): 181.12 - samples/sec: 456.33 - lr: 0.000021 - momentum: 0.000000
2023-07-12 15:07:31,805 epoch 7 - iter 18/38 - loss 0.03246139 - time (sec): 217.70 - samples/sec: 456.14 - lr: 0.000020 - momentum: 0.000000
2023-07-12 15:08:06,782 epoch 7 - iter 21/38 - loss 0.03175606 - time (sec): 252.68 - samples/sec: 456.16 - lr: 0.000020 - momentum: 0.000000
2023-07-12 15:08:40,739 epoch 7 - iter 24/38 - loss 0.03179368 - time (sec): 286.64 - samples/sec: 456.43 - lr: 0.000019 - momentum: 0.000000
2023-07-12 15:09:17,114 epoch 7 - iter 27/38 - loss 0.03198561 - time (sec): 323.01 - samples/sec: 455.74 - lr: 0.000019 - momentum: 0.000000
2023-07-12 15:09:51,382 epoch 7 - iter 30/38 - loss 0.03217903 - time (sec): 357.28 - samples/sec: 457.91 - lr: 0.000018 - momentum: 0.000000
2023-07-12 15:10:27,520 epoch 7 - iter 33/38 - loss 0.03236463 - time (sec): 393.42 - samples/sec: 457.35 - lr: 0.000018 - momentum: 0.000000
2023-07-12 15:11:03,696 epoch 7 - iter 36/38 - loss 0.03285230 - time (sec): 429.59 - samples/sec: 457.05 - lr: 0.000017 - momentum: 0.000000
2023-07-12 15:11:21,731 ----------------------------------------------------------------------------------------------------
2023-07-12 15:11:21,731 EPOCH 7 done: loss 0.0325 - lr: 0.000017
2023-07-12 15:12:04,661 DEV : loss 0.17301391065120697 - f1-score (micro avg)  0.7379
2023-07-12 15:12:50,291 TEST : loss 0.08711104840040207 - f1-score (micro avg)  0.9315
2023-07-12 15:12:50,347 ----------------------------------------------------------------------------------------------------
2023-07-12 15:13:47,530 epoch 8 - iter 3/38 - loss 0.03446551 - time (sec): 57.18 - samples/sec: 291.06 - lr: 0.000017 - momentum: 0.000000
2023-07-12 15:14:45,701 epoch 8 - iter 6/38 - loss 0.03009250 - time (sec): 115.35 - samples/sec: 281.69 - lr: 0.000016 - momentum: 0.000000
2023-07-12 15:15:28,721 epoch 8 - iter 9/38 - loss 0.02971277 - time (sec): 158.37 - samples/sec: 307.74 - lr: 0.000016 - momentum: 0.000000
2023-07-12 15:16:05,877 epoch 8 - iter 12/38 - loss 0.02921686 - time (sec): 195.53 - samples/sec: 335.91 - lr: 0.000015 - momentum: 0.000000
2023-07-12 15:16:42,450 epoch 8 - iter 15/38 - loss 0.02907431 - time (sec): 232.10 - samples/sec: 349.02 - lr: 0.000015 - momentum: 0.000000
2023-07-12 15:17:18,454 epoch 8 - iter 18/38 - loss 0.02795791 - time (sec): 268.11 - samples/sec: 363.49 - lr: 0.000015 - momentum: 0.000000
2023-07-12 15:17:54,981 epoch 8 - iter 21/38 - loss 0.02660637 - time (sec): 304.63 - samples/sec: 373.66 - lr: 0.000014 - momentum: 0.000000
2023-07-12 15:18:31,693 epoch 8 - iter 24/38 - loss 0.02676211 - time (sec): 341.34 - samples/sec: 382.42 - lr: 0.000014 - momentum: 0.000000
2023-07-12 15:19:07,593 epoch 8 - iter 27/38 - loss 0.02645520 - time (sec): 377.24 - samples/sec: 391.31 - lr: 0.000013 - momentum: 0.000000
2023-07-12 15:19:42,840 epoch 8 - iter 30/38 - loss 0.02634420 - time (sec): 412.49 - samples/sec: 396.92 - lr: 0.000013 - momentum: 0.000000
2023-07-12 15:20:18,656 epoch 8 - iter 33/38 - loss 0.02649027 - time (sec): 448.31 - samples/sec: 400.82 - lr: 0.000012 - momentum: 0.000000
2023-07-12 15:20:53,486 epoch 8 - iter 36/38 - loss 0.02646289 - time (sec): 483.14 - samples/sec: 406.49 - lr: 0.000012 - momentum: 0.000000
2023-07-12 15:21:11,807 ----------------------------------------------------------------------------------------------------
2023-07-12 15:21:11,808 EPOCH 8 done: loss 0.0265 - lr: 0.000012
2023-07-12 15:21:54,195 DEV : loss 0.17883199453353882 - f1-score (micro avg)  0.7335
2023-07-12 15:22:36,569 TEST : loss 0.0902089923620224 - f1-score (micro avg)  0.9309
2023-07-12 15:22:36,618 ----------------------------------------------------------------------------------------------------
2023-07-12 15:23:12,810 epoch 9 - iter 3/38 - loss 0.02902408 - time (sec): 36.19 - samples/sec: 449.29 - lr: 0.000011 - momentum: 0.000000
2023-07-12 15:23:49,440 epoch 9 - iter 6/38 - loss 0.02563792 - time (sec): 72.82 - samples/sec: 454.66 - lr: 0.000011 - momentum: 0.000000
2023-07-12 15:24:24,343 epoch 9 - iter 9/38 - loss 0.02489742 - time (sec): 107.72 - samples/sec: 458.95 - lr: 0.000010 - momentum: 0.000000
2023-07-12 15:25:06,779 epoch 9 - iter 12/38 - loss 0.02451598 - time (sec): 150.16 - samples/sec: 436.48 - lr: 0.000010 - momentum: 0.000000
2023-07-12 15:26:02,988 epoch 9 - iter 15/38 - loss 0.02379502 - time (sec): 206.37 - samples/sec: 401.54 - lr: 0.000010 - momentum: 0.000000
2023-07-12 15:27:00,364 epoch 9 - iter 18/38 - loss 0.02384006 - time (sec): 263.74 - samples/sec: 375.22 - lr: 0.000009 - momentum: 0.000000
2023-07-12 15:27:37,223 epoch 9 - iter 21/38 - loss 0.02438301 - time (sec): 300.60 - samples/sec: 383.62 - lr: 0.000009 - momentum: 0.000000
2023-07-12 15:28:13,637 epoch 9 - iter 24/38 - loss 0.02427184 - time (sec): 337.02 - samples/sec: 390.29 - lr: 0.000008 - momentum: 0.000000
2023-07-12 15:28:49,734 epoch 9 - iter 27/38 - loss 0.02391071 - time (sec): 373.11 - samples/sec: 395.27 - lr: 0.000008 - momentum: 0.000000
2023-07-12 15:29:26,284 epoch 9 - iter 30/38 - loss 0.02385154 - time (sec): 409.66 - samples/sec: 401.23 - lr: 0.000007 - momentum: 0.000000
2023-07-12 15:30:02,693 epoch 9 - iter 33/38 - loss 0.02398509 - time (sec): 446.07 - samples/sec: 404.55 - lr: 0.000007 - momentum: 0.000000
2023-07-12 15:30:38,863 epoch 9 - iter 36/38 - loss 0.02371578 - time (sec): 482.24 - samples/sec: 407.86 - lr: 0.000007 - momentum: 0.000000
2023-07-12 15:30:56,425 ----------------------------------------------------------------------------------------------------
2023-07-12 15:30:56,426 EPOCH 9 done: loss 0.0238 - lr: 0.000007
2023-07-12 15:31:38,412 DEV : loss 0.17468035221099854 - f1-score (micro avg)  0.7359
2023-07-12 15:32:21,658 TEST : loss 0.09106170386075974 - f1-score (micro avg)  0.931
2023-07-12 15:32:21,723 ----------------------------------------------------------------------------------------------------
2023-07-12 15:32:56,649 epoch 10 - iter 3/38 - loss 0.01949076 - time (sec): 34.92 - samples/sec: 466.76 - lr: 0.000006 - momentum: 0.000000
2023-07-12 15:33:33,641 epoch 10 - iter 6/38 - loss 0.01960961 - time (sec): 71.92 - samples/sec: 454.43 - lr: 0.000005 - momentum: 0.000000
2023-07-12 15:34:10,100 epoch 10 - iter 9/38 - loss 0.02123497 - time (sec): 108.38 - samples/sec: 453.40 - lr: 0.000005 - momentum: 0.000000
2023-07-12 15:34:46,548 epoch 10 - iter 12/38 - loss 0.02098186 - time (sec): 144.82 - samples/sec: 448.26 - lr: 0.000004 - momentum: 0.000000
2023-07-12 15:35:23,009 epoch 10 - iter 15/38 - loss 0.02182193 - time (sec): 181.28 - samples/sec: 448.85 - lr: 0.000004 - momentum: 0.000000
2023-07-12 15:35:58,516 epoch 10 - iter 18/38 - loss 0.02205619 - time (sec): 216.79 - samples/sec: 453.28 - lr: 0.000004 - momentum: 0.000000
2023-07-12 15:36:33,556 epoch 10 - iter 21/38 - loss 0.02198671 - time (sec): 251.83 - samples/sec: 454.57 - lr: 0.000003 - momentum: 0.000000
2023-07-12 15:37:22,407 epoch 10 - iter 24/38 - loss 0.02175933 - time (sec): 300.68 - samples/sec: 435.07 - lr: 0.000003 - momentum: 0.000000
2023-07-12 15:38:15,494 epoch 10 - iter 27/38 - loss 0.02230133 - time (sec): 353.77 - samples/sec: 418.39 - lr: 0.000002 - momentum: 0.000000
2023-07-12 15:39:05,552 epoch 10 - iter 30/38 - loss 0.02226346 - time (sec): 403.83 - samples/sec: 406.28 - lr: 0.000002 - momentum: 0.000000
2023-07-12 15:39:40,696 epoch 10 - iter 33/38 - loss 0.02173117 - time (sec): 438.97 - samples/sec: 413.01 - lr: 0.000001 - momentum: 0.000000
2023-07-12 15:40:14,404 epoch 10 - iter 36/38 - loss 0.02189743 - time (sec): 472.68 - samples/sec: 416.80 - lr: 0.000001 - momentum: 0.000000
2023-07-12 15:40:31,204 ----------------------------------------------------------------------------------------------------
2023-07-12 15:40:31,204 EPOCH 10 done: loss 0.0222 - lr: 0.000001
2023-07-12 15:41:14,817 DEV : loss 0.17220883071422577 - f1-score (micro avg)  0.7407
2023-07-12 15:41:55,509 TEST : loss 0.09118907153606415 - f1-score (micro avg)  0.9313
2023-07-12 15:42:06,243 ----------------------------------------------------------------------------------------------------
2023-07-12 15:42:06,248 Testing using last state of model ...
2023-07-12 15:42:46,752 
Results:
- F-score (micro) 0.9313
- F-score (macro) 0.9161
- Accuracy 0.8966

By class:
              precision    recall  f1-score   support

         ORG     0.9180    0.9229    0.9204      1661
         LOC     0.9461    0.9371    0.9416      1668
         PER     0.9881    0.9784    0.9832      1617
        MISC     0.7839    0.8575    0.8190       702

   micro avg     0.9278    0.9348    0.9313      5648
   macro avg     0.9090    0.9240    0.9161      5648
weighted avg     0.9297    0.9348    0.9321      5648

2023-07-12 15:42:46,752 ----------------------------------------------------------------------------------------------------
