2023-07-12 17:19:24,554 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Train:  14987 sentences
2023-07-12 17:19:24,556         (train_with_dev=False, train_with_test=False)
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Training Params:
2023-07-12 17:19:24,556  - learning_rate: "5e-05" 
2023-07-12 17:19:24,556  - mini_batch_size: "400"
2023-07-12 17:19:24,556  - max_epochs: "10"
2023-07-12 17:19:24,556  - shuffle: "True"
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Plugins:
2023-07-12 17:19:24,556  - LinearScheduler | warmup_fraction: '0.1'
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Final evaluation on model after last epoch (final-model.pt)
2023-07-12 17:19:24,556  - metric: "('micro avg', 'f1-score')"
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Computation:
2023-07-12 17:19:24,556  - compute on device: cuda:3
2023-07-12 17:19:24,556  - embedding storage: none
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_400_lr_5e-05_run_3_ger_test_as_dev"
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 Removed gradient clipping
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:19:24,556 ----------------------------------------------------------------------------------------------------
2023-07-12 17:20:01,843 epoch 1 - iter 3/38 - loss 3.66269899 - time (sec): 37.29 - samples/sec: 436.06 - lr: 0.000003 - momentum: 0.000000
2023-07-12 17:20:37,751 epoch 1 - iter 6/38 - loss 3.54276771 - time (sec): 73.19 - samples/sec: 447.50 - lr: 0.000007 - momentum: 0.000000
2023-07-12 17:21:13,202 epoch 1 - iter 9/38 - loss 3.44597227 - time (sec): 108.64 - samples/sec: 449.14 - lr: 0.000011 - momentum: 0.000000
2023-07-12 17:21:50,849 epoch 1 - iter 12/38 - loss 3.26934971 - time (sec): 146.29 - samples/sec: 448.13 - lr: 0.000014 - momentum: 0.000000
2023-07-12 17:22:26,399 epoch 1 - iter 15/38 - loss 2.92827968 - time (sec): 181.84 - samples/sec: 450.72 - lr: 0.000018 - momentum: 0.000000
2023-07-12 17:23:02,045 epoch 1 - iter 18/38 - loss 2.63801062 - time (sec): 217.49 - samples/sec: 451.52 - lr: 0.000022 - momentum: 0.000000
2023-07-12 17:23:36,951 epoch 1 - iter 21/38 - loss 2.39070749 - time (sec): 252.39 - samples/sec: 454.37 - lr: 0.000026 - momentum: 0.000000
2023-07-12 17:24:12,631 epoch 1 - iter 24/38 - loss 2.18409828 - time (sec): 288.07 - samples/sec: 454.29 - lr: 0.000030 - momentum: 0.000000
2023-07-12 17:24:47,113 epoch 1 - iter 27/38 - loss 2.01092063 - time (sec): 322.56 - samples/sec: 457.72 - lr: 0.000034 - momentum: 0.000000
2023-07-12 17:25:21,768 epoch 1 - iter 30/38 - loss 1.86574116 - time (sec): 357.21 - samples/sec: 460.84 - lr: 0.000038 - momentum: 0.000000
2023-07-12 17:25:57,582 epoch 1 - iter 33/38 - loss 1.75159079 - time (sec): 393.02 - samples/sec: 458.86 - lr: 0.000042 - momentum: 0.000000
2023-07-12 17:26:33,100 epoch 1 - iter 36/38 - loss 1.65351583 - time (sec): 428.54 - samples/sec: 458.36 - lr: 0.000046 - momentum: 0.000000
2023-07-12 17:26:50,682 ----------------------------------------------------------------------------------------------------
2023-07-12 17:26:50,682 EPOCH 1 done: loss 1.6072 - lr: 0.000046
2023-07-12 17:27:32,496 DEV : loss 0.26392924785614014 - f1-score (micro avg)  0.4109
2023-07-12 17:28:13,023 TEST : loss 0.37520185112953186 - f1-score (micro avg)  0.5506
2023-07-12 17:28:13,073 ----------------------------------------------------------------------------------------------------
2023-07-12 17:28:48,116 epoch 2 - iter 3/38 - loss 0.42992262 - time (sec): 35.04 - samples/sec: 440.90 - lr: 0.000050 - momentum: 0.000000
2023-07-12 17:29:22,332 epoch 2 - iter 6/38 - loss 0.40647783 - time (sec): 69.26 - samples/sec: 456.41 - lr: 0.000049 - momentum: 0.000000
2023-07-12 17:30:10,291 epoch 2 - iter 9/38 - loss 0.37934260 - time (sec): 117.22 - samples/sec: 406.19 - lr: 0.000049 - momentum: 0.000000
2023-07-12 17:31:06,545 epoch 2 - iter 12/38 - loss 0.35855317 - time (sec): 173.47 - samples/sec: 368.86 - lr: 0.000048 - momentum: 0.000000
2023-07-12 17:31:59,629 epoch 2 - iter 15/38 - loss 0.33555588 - time (sec): 226.55 - samples/sec: 357.04 - lr: 0.000048 - momentum: 0.000000
2023-07-12 17:32:36,822 epoch 2 - iter 18/38 - loss 0.31502843 - time (sec): 263.75 - samples/sec: 368.06 - lr: 0.000048 - momentum: 0.000000
2023-07-12 17:33:13,565 epoch 2 - iter 21/38 - loss 0.30115668 - time (sec): 300.49 - samples/sec: 376.87 - lr: 0.000047 - momentum: 0.000000
2023-07-12 17:33:50,102 epoch 2 - iter 24/38 - loss 0.28449485 - time (sec): 337.03 - samples/sec: 387.42 - lr: 0.000047 - momentum: 0.000000
2023-07-12 17:34:26,407 epoch 2 - iter 27/38 - loss 0.27207618 - time (sec): 373.33 - samples/sec: 393.20 - lr: 0.000046 - momentum: 0.000000
2023-07-12 17:35:02,366 epoch 2 - iter 30/38 - loss 0.25993647 - time (sec): 409.29 - samples/sec: 398.58 - lr: 0.000046 - momentum: 0.000000
2023-07-12 17:35:39,001 epoch 2 - iter 33/38 - loss 0.24922775 - time (sec): 445.93 - samples/sec: 403.30 - lr: 0.000045 - momentum: 0.000000
2023-07-12 17:36:14,924 epoch 2 - iter 36/38 - loss 0.23850234 - time (sec): 481.85 - samples/sec: 408.29 - lr: 0.000045 - momentum: 0.000000
2023-07-12 17:36:32,656 ----------------------------------------------------------------------------------------------------
2023-07-12 17:36:32,657 EPOCH 2 done: loss 0.2344 - lr: 0.000045
2023-07-12 17:37:18,711 DEV : loss 0.21368230879306793 - f1-score (micro avg)  0.6789
2023-07-12 17:38:02,376 TEST : loss 0.10748809576034546 - f1-score (micro avg)  0.8958
2023-07-12 17:38:02,425 ----------------------------------------------------------------------------------------------------
2023-07-12 17:38:38,972 epoch 3 - iter 3/38 - loss 0.10272715 - time (sec): 36.55 - samples/sec: 457.10 - lr: 0.000044 - momentum: 0.000000
2023-07-12 17:39:14,865 epoch 3 - iter 6/38 - loss 0.09347542 - time (sec): 72.44 - samples/sec: 464.00 - lr: 0.000044 - momentum: 0.000000
2023-07-12 17:39:51,439 epoch 3 - iter 9/38 - loss 0.09515704 - time (sec): 109.01 - samples/sec: 458.88 - lr: 0.000043 - momentum: 0.000000
2023-07-12 17:40:28,383 epoch 3 - iter 12/38 - loss 0.09310669 - time (sec): 145.96 - samples/sec: 454.24 - lr: 0.000043 - momentum: 0.000000
2023-07-12 17:41:04,297 epoch 3 - iter 15/38 - loss 0.09210567 - time (sec): 181.87 - samples/sec: 451.83 - lr: 0.000042 - momentum: 0.000000
2023-07-12 17:41:39,217 epoch 3 - iter 18/38 - loss 0.09175945 - time (sec): 216.79 - samples/sec: 451.94 - lr: 0.000042 - momentum: 0.000000
2023-07-12 17:42:28,453 epoch 3 - iter 21/38 - loss 0.09078717 - time (sec): 266.03 - samples/sec: 429.51 - lr: 0.000042 - momentum: 0.000000
2023-07-12 17:43:26,748 epoch 3 - iter 24/38 - loss 0.08837863 - time (sec): 324.32 - samples/sec: 402.29 - lr: 0.000041 - momentum: 0.000000
2023-07-12 17:44:19,016 epoch 3 - iter 27/38 - loss 0.08631670 - time (sec): 376.59 - samples/sec: 390.63 - lr: 0.000041 - momentum: 0.000000
2023-07-12 17:44:56,226 epoch 3 - iter 30/38 - loss 0.08433261 - time (sec): 413.80 - samples/sec: 393.93 - lr: 0.000040 - momentum: 0.000000
2023-07-12 17:45:33,090 epoch 3 - iter 33/38 - loss 0.08259029 - time (sec): 450.66 - samples/sec: 397.66 - lr: 0.000040 - momentum: 0.000000
2023-07-12 17:46:09,520 epoch 3 - iter 36/38 - loss 0.08124139 - time (sec): 487.09 - samples/sec: 403.01 - lr: 0.000039 - momentum: 0.000000
2023-07-12 17:46:27,486 ----------------------------------------------------------------------------------------------------
2023-07-12 17:46:27,487 EPOCH 3 done: loss 0.0806 - lr: 0.000039
2023-07-12 17:47:09,906 DEV : loss 0.18376876413822174 - f1-score (micro avg)  0.7277
2023-07-12 17:47:50,307 TEST : loss 0.09931762516498566 - f1-score (micro avg)  0.9193
2023-07-12 17:47:50,356 ----------------------------------------------------------------------------------------------------
2023-07-12 17:48:27,539 epoch 4 - iter 3/38 - loss 0.06123447 - time (sec): 37.18 - samples/sec: 430.40 - lr: 0.000039 - momentum: 0.000000
2023-07-12 17:49:03,316 epoch 4 - iter 6/38 - loss 0.05692640 - time (sec): 72.96 - samples/sec: 438.66 - lr: 0.000038 - momentum: 0.000000
2023-07-12 17:49:37,276 epoch 4 - iter 9/38 - loss 0.05687835 - time (sec): 106.92 - samples/sec: 449.07 - lr: 0.000038 - momentum: 0.000000
2023-07-12 17:50:12,079 epoch 4 - iter 12/38 - loss 0.05559036 - time (sec): 141.72 - samples/sec: 452.34 - lr: 0.000037 - momentum: 0.000000
2023-07-12 17:50:49,440 epoch 4 - iter 15/38 - loss 0.05443591 - time (sec): 179.08 - samples/sec: 450.09 - lr: 0.000037 - momentum: 0.000000
2023-07-12 17:51:25,621 epoch 4 - iter 18/38 - loss 0.05505273 - time (sec): 215.26 - samples/sec: 451.84 - lr: 0.000037 - momentum: 0.000000
2023-07-12 17:52:01,971 epoch 4 - iter 21/38 - loss 0.05479871 - time (sec): 251.61 - samples/sec: 452.23 - lr: 0.000036 - momentum: 0.000000
2023-07-12 17:52:38,135 epoch 4 - iter 24/38 - loss 0.05431668 - time (sec): 287.78 - samples/sec: 452.59 - lr: 0.000036 - momentum: 0.000000
2023-07-12 17:53:13,183 epoch 4 - iter 27/38 - loss 0.05356808 - time (sec): 322.83 - samples/sec: 454.21 - lr: 0.000035 - momentum: 0.000000
2023-07-12 17:53:48,180 epoch 4 - iter 30/38 - loss 0.05324911 - time (sec): 357.82 - samples/sec: 454.32 - lr: 0.000035 - momentum: 0.000000
2023-07-12 17:54:30,411 epoch 4 - iter 33/38 - loss 0.05257513 - time (sec): 400.05 - samples/sec: 448.03 - lr: 0.000034 - momentum: 0.000000
2023-07-12 17:55:29,279 epoch 4 - iter 36/38 - loss 0.05250054 - time (sec): 458.92 - samples/sec: 428.42 - lr: 0.000034 - momentum: 0.000000
2023-07-12 17:55:58,326 ----------------------------------------------------------------------------------------------------
2023-07-12 17:55:58,327 EPOCH 4 done: loss 0.0520 - lr: 0.000034
2023-07-12 17:56:51,260 DEV : loss 0.15001024305820465 - f1-score (micro avg)  0.7416
2023-07-12 17:57:32,467 TEST : loss 0.08188888430595398 - f1-score (micro avg)  0.9285
2023-07-12 17:57:32,517 ----------------------------------------------------------------------------------------------------
2023-07-12 17:58:09,520 epoch 5 - iter 3/38 - loss 0.04062009 - time (sec): 37.00 - samples/sec: 444.71 - lr: 0.000033 - momentum: 0.000000
2023-07-12 17:58:44,970 epoch 5 - iter 6/38 - loss 0.04043165 - time (sec): 72.45 - samples/sec: 451.05 - lr: 0.000033 - momentum: 0.000000
2023-07-12 17:59:21,369 epoch 5 - iter 9/38 - loss 0.04121705 - time (sec): 108.85 - samples/sec: 445.57 - lr: 0.000032 - momentum: 0.000000
2023-07-12 17:59:57,552 epoch 5 - iter 12/38 - loss 0.04155088 - time (sec): 145.03 - samples/sec: 447.85 - lr: 0.000032 - momentum: 0.000000
2023-07-12 18:00:34,267 epoch 5 - iter 15/38 - loss 0.04145007 - time (sec): 181.75 - samples/sec: 450.56 - lr: 0.000032 - momentum: 0.000000
2023-07-12 18:01:10,540 epoch 5 - iter 18/38 - loss 0.04131668 - time (sec): 218.02 - samples/sec: 450.14 - lr: 0.000031 - momentum: 0.000000
2023-07-12 18:01:44,880 epoch 5 - iter 21/38 - loss 0.04109918 - time (sec): 252.36 - samples/sec: 452.38 - lr: 0.000031 - momentum: 0.000000
2023-07-12 18:02:19,318 epoch 5 - iter 24/38 - loss 0.04184741 - time (sec): 286.80 - samples/sec: 453.07 - lr: 0.000030 - momentum: 0.000000
2023-07-12 18:02:56,126 epoch 5 - iter 27/38 - loss 0.04141462 - time (sec): 323.61 - samples/sec: 454.79 - lr: 0.000030 - momentum: 0.000000
2023-07-12 18:03:32,440 epoch 5 - iter 30/38 - loss 0.04128571 - time (sec): 359.92 - samples/sec: 454.45 - lr: 0.000029 - momentum: 0.000000
2023-07-12 18:04:07,989 epoch 5 - iter 33/38 - loss 0.04042029 - time (sec): 395.47 - samples/sec: 454.87 - lr: 0.000029 - momentum: 0.000000
2023-07-12 18:04:44,029 epoch 5 - iter 36/38 - loss 0.04025989 - time (sec): 431.51 - samples/sec: 454.51 - lr: 0.000028 - momentum: 0.000000
2023-07-12 18:05:01,424 ----------------------------------------------------------------------------------------------------
2023-07-12 18:05:01,425 EPOCH 5 done: loss 0.0401 - lr: 0.000028
2023-07-12 18:05:46,130 DEV : loss 0.16908472776412964 - f1-score (micro avg)  0.7406
2023-07-12 18:06:29,910 TEST : loss 0.08732108771800995 - f1-score (micro avg)  0.9279
2023-07-12 18:06:29,967 ----------------------------------------------------------------------------------------------------
2023-07-12 18:07:24,951 epoch 6 - iter 3/38 - loss 0.03234623 - time (sec): 54.98 - samples/sec: 313.79 - lr: 0.000028 - momentum: 0.000000
2023-07-12 18:08:24,960 epoch 6 - iter 6/38 - loss 0.03051283 - time (sec): 114.99 - samples/sec: 292.14 - lr: 0.000027 - momentum: 0.000000
2023-07-12 18:09:10,643 epoch 6 - iter 9/38 - loss 0.03145273 - time (sec): 160.67 - samples/sec: 305.38 - lr: 0.000027 - momentum: 0.000000
2023-07-12 18:09:47,254 epoch 6 - iter 12/38 - loss 0.03191276 - time (sec): 197.29 - samples/sec: 333.00 - lr: 0.000026 - momentum: 0.000000
2023-07-12 18:10:22,929 epoch 6 - iter 15/38 - loss 0.03085549 - time (sec): 232.96 - samples/sec: 352.30 - lr: 0.000026 - momentum: 0.000000
2023-07-12 18:11:00,582 epoch 6 - iter 18/38 - loss 0.03022615 - time (sec): 270.61 - samples/sec: 365.06 - lr: 0.000026 - momentum: 0.000000
2023-07-12 18:11:37,824 epoch 6 - iter 21/38 - loss 0.03006872 - time (sec): 307.85 - samples/sec: 374.81 - lr: 0.000025 - momentum: 0.000000
2023-07-12 18:12:14,419 epoch 6 - iter 24/38 - loss 0.03037525 - time (sec): 344.45 - samples/sec: 382.24 - lr: 0.000025 - momentum: 0.000000
2023-07-12 18:12:50,747 epoch 6 - iter 27/38 - loss 0.03028635 - time (sec): 380.78 - samples/sec: 387.55 - lr: 0.000024 - momentum: 0.000000
2023-07-12 18:13:26,626 epoch 6 - iter 30/38 - loss 0.03086996 - time (sec): 416.66 - samples/sec: 394.94 - lr: 0.000024 - momentum: 0.000000
2023-07-12 18:14:02,019 epoch 6 - iter 33/38 - loss 0.03103405 - time (sec): 452.05 - samples/sec: 399.66 - lr: 0.000023 - momentum: 0.000000
2023-07-12 18:14:36,898 epoch 6 - iter 36/38 - loss 0.03142499 - time (sec): 486.93 - samples/sec: 404.51 - lr: 0.000023 - momentum: 0.000000
2023-07-12 18:14:55,057 ----------------------------------------------------------------------------------------------------
2023-07-12 18:14:55,058 EPOCH 6 done: loss 0.0314 - lr: 0.000023
2023-07-12 18:15:38,925 DEV : loss 0.17200767993927002 - f1-score (micro avg)  0.7468
2023-07-12 18:16:19,509 TEST : loss 0.093368761241436 - f1-score (micro avg)  0.93
2023-07-12 18:16:19,567 ----------------------------------------------------------------------------------------------------
2023-07-12 18:16:56,068 epoch 7 - iter 3/38 - loss 0.02941933 - time (sec): 36.50 - samples/sec: 447.27 - lr: 0.000022 - momentum: 0.000000
2023-07-12 18:17:33,467 epoch 7 - iter 6/38 - loss 0.03143879 - time (sec): 73.90 - samples/sec: 435.74 - lr: 0.000022 - momentum: 0.000000
2023-07-12 18:18:09,674 epoch 7 - iter 9/38 - loss 0.03155577 - time (sec): 110.11 - samples/sec: 436.29 - lr: 0.000021 - momentum: 0.000000
2023-07-12 18:18:47,449 epoch 7 - iter 12/38 - loss 0.03055264 - time (sec): 147.88 - samples/sec: 435.36 - lr: 0.000021 - momentum: 0.000000
2023-07-12 18:19:46,610 epoch 7 - iter 15/38 - loss 0.03044487 - time (sec): 207.04 - samples/sec: 389.33 - lr: 0.000021 - momentum: 0.000000
2023-07-12 18:20:45,532 epoch 7 - iter 18/38 - loss 0.03043177 - time (sec): 265.96 - samples/sec: 366.21 - lr: 0.000020 - momentum: 0.000000
2023-07-12 18:21:24,186 epoch 7 - iter 21/38 - loss 0.02971000 - time (sec): 304.62 - samples/sec: 374.89 - lr: 0.000020 - momentum: 0.000000
2023-07-12 18:22:00,944 epoch 7 - iter 24/38 - loss 0.03041110 - time (sec): 341.38 - samples/sec: 381.60 - lr: 0.000019 - momentum: 0.000000
2023-07-12 18:22:37,872 epoch 7 - iter 27/38 - loss 0.03025952 - time (sec): 378.30 - samples/sec: 388.60 - lr: 0.000019 - momentum: 0.000000
2023-07-12 18:23:14,253 epoch 7 - iter 30/38 - loss 0.02939137 - time (sec): 414.68 - samples/sec: 394.42 - lr: 0.000018 - momentum: 0.000000
2023-07-12 18:23:50,587 epoch 7 - iter 33/38 - loss 0.02965763 - time (sec): 451.02 - samples/sec: 398.84 - lr: 0.000018 - momentum: 0.000000
2023-07-12 18:24:27,206 epoch 7 - iter 36/38 - loss 0.02907414 - time (sec): 487.64 - samples/sec: 403.35 - lr: 0.000017 - momentum: 0.000000
2023-07-12 18:24:45,257 ----------------------------------------------------------------------------------------------------
2023-07-12 18:24:45,257 EPOCH 7 done: loss 0.0290 - lr: 0.000017
2023-07-12 18:25:27,173 DEV : loss 0.16855421662330627 - f1-score (micro avg)  0.7419
2023-07-12 18:26:11,183 TEST : loss 0.09299544990062714 - f1-score (micro avg)  0.9315
2023-07-12 18:26:11,233 ----------------------------------------------------------------------------------------------------
2023-07-12 18:26:47,139 epoch 8 - iter 3/38 - loss 0.02742743 - time (sec): 35.90 - samples/sec: 445.49 - lr: 0.000017 - momentum: 0.000000
2023-07-12 18:27:23,614 epoch 8 - iter 6/38 - loss 0.02795488 - time (sec): 72.38 - samples/sec: 443.06 - lr: 0.000016 - momentum: 0.000000
2023-07-12 18:28:01,051 epoch 8 - iter 9/38 - loss 0.02797180 - time (sec): 109.82 - samples/sec: 441.85 - lr: 0.000016 - momentum: 0.000000
2023-07-12 18:28:37,110 epoch 8 - iter 12/38 - loss 0.02697034 - time (sec): 145.87 - samples/sec: 443.56 - lr: 0.000015 - momentum: 0.000000
2023-07-12 18:29:13,230 epoch 8 - iter 15/38 - loss 0.02575616 - time (sec): 181.99 - samples/sec: 442.47 - lr: 0.000015 - momentum: 0.000000
2023-07-12 18:29:48,632 epoch 8 - iter 18/38 - loss 0.02616465 - time (sec): 217.40 - samples/sec: 444.55 - lr: 0.000015 - momentum: 0.000000
2023-07-12 18:30:23,034 epoch 8 - iter 21/38 - loss 0.02548922 - time (sec): 251.80 - samples/sec: 447.85 - lr: 0.000014 - momentum: 0.000000
2023-07-12 18:31:08,006 epoch 8 - iter 24/38 - loss 0.02499627 - time (sec): 296.77 - samples/sec: 436.18 - lr: 0.000014 - momentum: 0.000000
2023-07-12 18:32:06,214 epoch 8 - iter 27/38 - loss 0.02475065 - time (sec): 354.98 - samples/sec: 412.23 - lr: 0.000013 - momentum: 0.000000
2023-07-12 18:32:59,497 epoch 8 - iter 30/38 - loss 0.02477257 - time (sec): 408.26 - samples/sec: 400.44 - lr: 0.000013 - momentum: 0.000000
2023-07-12 18:33:35,908 epoch 8 - iter 33/38 - loss 0.02474392 - time (sec): 444.67 - samples/sec: 405.88 - lr: 0.000012 - momentum: 0.000000
2023-07-12 18:34:12,821 epoch 8 - iter 36/38 - loss 0.02468050 - time (sec): 481.59 - samples/sec: 408.65 - lr: 0.000012 - momentum: 0.000000
2023-07-12 18:34:30,523 ----------------------------------------------------------------------------------------------------
2023-07-12 18:34:30,524 EPOCH 8 done: loss 0.0247 - lr: 0.000012
2023-07-12 18:35:12,769 DEV : loss 0.1686817854642868 - f1-score (micro avg)  0.755
2023-07-12 18:35:55,134 TEST : loss 0.09462101757526398 - f1-score (micro avg)  0.9317
2023-07-12 18:35:55,185 ----------------------------------------------------------------------------------------------------
2023-07-12 18:36:31,059 epoch 9 - iter 3/38 - loss 0.03051910 - time (sec): 35.87 - samples/sec: 462.96 - lr: 0.000011 - momentum: 0.000000
2023-07-12 18:37:07,089 epoch 9 - iter 6/38 - loss 0.02346143 - time (sec): 71.90 - samples/sec: 453.71 - lr: 0.000011 - momentum: 0.000000
2023-07-12 18:37:42,881 epoch 9 - iter 9/38 - loss 0.02372661 - time (sec): 107.70 - samples/sec: 453.70 - lr: 0.000010 - momentum: 0.000000
2023-07-12 18:38:17,043 epoch 9 - iter 12/38 - loss 0.02346657 - time (sec): 141.86 - samples/sec: 465.75 - lr: 0.000010 - momentum: 0.000000
2023-07-12 18:38:52,014 epoch 9 - iter 15/38 - loss 0.02490952 - time (sec): 176.83 - samples/sec: 465.91 - lr: 0.000010 - momentum: 0.000000
2023-07-12 18:39:27,981 epoch 9 - iter 18/38 - loss 0.02379020 - time (sec): 212.79 - samples/sec: 465.06 - lr: 0.000009 - momentum: 0.000000
2023-07-12 18:40:04,669 epoch 9 - iter 21/38 - loss 0.02332494 - time (sec): 249.48 - samples/sec: 460.22 - lr: 0.000009 - momentum: 0.000000
2023-07-12 18:40:40,595 epoch 9 - iter 24/38 - loss 0.02342041 - time (sec): 285.41 - samples/sec: 458.83 - lr: 0.000008 - momentum: 0.000000
2023-07-12 18:41:17,000 epoch 9 - iter 27/38 - loss 0.02320930 - time (sec): 321.81 - samples/sec: 458.29 - lr: 0.000008 - momentum: 0.000000
2023-07-12 18:41:52,825 epoch 9 - iter 30/38 - loss 0.02342486 - time (sec): 357.64 - samples/sec: 459.18 - lr: 0.000007 - momentum: 0.000000
2023-07-12 18:42:27,647 epoch 9 - iter 33/38 - loss 0.02312314 - time (sec): 392.46 - samples/sec: 459.56 - lr: 0.000007 - momentum: 0.000000
2023-07-12 18:43:14,766 epoch 9 - iter 36/38 - loss 0.02322497 - time (sec): 439.58 - samples/sec: 447.40 - lr: 0.000007 - momentum: 0.000000
2023-07-12 18:43:43,297 ----------------------------------------------------------------------------------------------------
2023-07-12 18:43:43,298 EPOCH 9 done: loss 0.0230 - lr: 0.000007
2023-07-12 18:44:52,283 DEV : loss 0.16865769028663635 - f1-score (micro avg)  0.7508
2023-07-12 18:45:37,487 TEST : loss 0.09322412312030792 - f1-score (micro avg)  0.9326
2023-07-12 18:45:37,545 ----------------------------------------------------------------------------------------------------
2023-07-12 18:46:13,219 epoch 10 - iter 3/38 - loss 0.01746734 - time (sec): 35.67 - samples/sec: 458.48 - lr: 0.000006 - momentum: 0.000000
2023-07-12 18:46:49,619 epoch 10 - iter 6/38 - loss 0.02032743 - time (sec): 72.07 - samples/sec: 462.56 - lr: 0.000005 - momentum: 0.000000
2023-07-12 18:47:25,453 epoch 10 - iter 9/38 - loss 0.02000732 - time (sec): 107.91 - samples/sec: 466.26 - lr: 0.000005 - momentum: 0.000000
2023-07-12 18:48:03,357 epoch 10 - iter 12/38 - loss 0.01981163 - time (sec): 145.81 - samples/sec: 459.75 - lr: 0.000004 - momentum: 0.000000
2023-07-12 18:48:40,161 epoch 10 - iter 15/38 - loss 0.02056735 - time (sec): 182.61 - samples/sec: 459.17 - lr: 0.000004 - momentum: 0.000000
2023-07-12 18:49:16,900 epoch 10 - iter 18/38 - loss 0.02013231 - time (sec): 219.35 - samples/sec: 454.80 - lr: 0.000004 - momentum: 0.000000
2023-07-12 18:49:53,029 epoch 10 - iter 21/38 - loss 0.02029062 - time (sec): 255.48 - samples/sec: 455.03 - lr: 0.000003 - momentum: 0.000000
2023-07-12 18:50:28,422 epoch 10 - iter 24/38 - loss 0.02082879 - time (sec): 290.88 - samples/sec: 454.33 - lr: 0.000003 - momentum: 0.000000
2023-07-12 18:51:02,883 epoch 10 - iter 27/38 - loss 0.02114970 - time (sec): 325.34 - samples/sec: 456.87 - lr: 0.000002 - momentum: 0.000000
2023-07-12 18:51:38,113 epoch 10 - iter 30/38 - loss 0.02104322 - time (sec): 360.57 - samples/sec: 456.24 - lr: 0.000002 - momentum: 0.000000
2023-07-12 18:52:14,824 epoch 10 - iter 33/38 - loss 0.02098808 - time (sec): 397.28 - samples/sec: 454.82 - lr: 0.000001 - momentum: 0.000000
2023-07-12 18:52:50,129 epoch 10 - iter 36/38 - loss 0.02077556 - time (sec): 432.58 - samples/sec: 454.67 - lr: 0.000001 - momentum: 0.000000
2023-07-12 18:53:07,555 ----------------------------------------------------------------------------------------------------
2023-07-12 18:53:07,556 EPOCH 10 done: loss 0.0208 - lr: 0.000001
2023-07-12 18:53:49,222 DEV : loss 0.1697559952735901 - f1-score (micro avg)  0.7528
2023-07-12 18:54:31,295 TEST : loss 0.09346242249011993 - f1-score (micro avg)  0.9329
2023-07-12 18:54:43,971 ----------------------------------------------------------------------------------------------------
2023-07-12 18:54:43,974 Testing using last state of model ...
2023-07-12 18:55:46,788 
Results:
- F-score (micro) 0.9329
- F-score (macro) 0.9178
- Accuracy 0.9004

By class:
              precision    recall  f1-score   support

         ORG     0.9070    0.9392    0.9228      1661
         LOC     0.9512    0.9353    0.9432      1668
         PER     0.9851    0.9790    0.9820      1617
        MISC     0.8016    0.8462    0.8233       702

   micro avg     0.9280    0.9379    0.9329      5648
   macro avg     0.9112    0.9249    0.9178      5648
weighted avg     0.9293    0.9379    0.9334      5648

2023-07-12 18:55:46,788 ----------------------------------------------------------------------------------------------------
