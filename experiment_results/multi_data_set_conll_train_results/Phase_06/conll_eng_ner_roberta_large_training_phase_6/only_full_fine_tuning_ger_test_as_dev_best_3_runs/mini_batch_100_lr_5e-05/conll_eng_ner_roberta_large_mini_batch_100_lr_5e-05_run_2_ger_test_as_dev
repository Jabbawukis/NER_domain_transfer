2023-07-12 20:34:09,470 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,471 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-12 20:34:09,471 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,471 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 Train:  14987 sentences
2023-07-12 20:34:09,472         (train_with_dev=False, train_with_test=False)
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 Training Params:
2023-07-12 20:34:09,472  - learning_rate: "5e-05" 
2023-07-12 20:34:09,472  - mini_batch_size: "100"
2023-07-12 20:34:09,472  - max_epochs: "10"
2023-07-12 20:34:09,472  - shuffle: "True"
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 Plugins:
2023-07-12 20:34:09,472  - LinearScheduler | warmup_fraction: '0.1'
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 Final evaluation on model after last epoch (final-model.pt)
2023-07-12 20:34:09,472  - metric: "('micro avg', 'f1-score')"
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 Computation:
2023-07-12 20:34:09,472  - compute on device: cuda:3
2023-07-12 20:34:09,472  - embedding storage: none
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_5e-05_run_2_ger_test_as_dev"
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 Removed gradient clipping
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:34:09,472 ----------------------------------------------------------------------------------------------------
2023-07-12 20:35:21,520 epoch 1 - iter 15/150 - loss 3.56154509 - time (sec): 72.05 - samples/sec: 278.21 - lr: 0.000005 - momentum: 0.000000
2023-07-12 20:36:24,062 epoch 1 - iter 30/150 - loss 2.86831299 - time (sec): 134.59 - samples/sec: 299.98 - lr: 0.000010 - momentum: 0.000000
2023-07-12 20:37:10,621 epoch 1 - iter 45/150 - loss 2.22805089 - time (sec): 181.15 - samples/sec: 332.41 - lr: 0.000015 - momentum: 0.000000
2023-07-12 20:37:56,866 epoch 1 - iter 60/150 - loss 1.82261011 - time (sec): 227.39 - samples/sec: 355.69 - lr: 0.000020 - momentum: 0.000000
2023-07-12 20:38:42,304 epoch 1 - iter 75/150 - loss 1.55313154 - time (sec): 272.83 - samples/sec: 370.45 - lr: 0.000025 - momentum: 0.000000
2023-07-12 20:39:28,272 epoch 1 - iter 90/150 - loss 1.33803080 - time (sec): 318.80 - samples/sec: 384.68 - lr: 0.000030 - momentum: 0.000000
2023-07-12 20:40:13,398 epoch 1 - iter 105/150 - loss 1.18940250 - time (sec): 363.92 - samples/sec: 392.22 - lr: 0.000035 - momentum: 0.000000
2023-07-12 20:40:58,624 epoch 1 - iter 120/150 - loss 1.06501772 - time (sec): 409.15 - samples/sec: 399.66 - lr: 0.000040 - momentum: 0.000000
2023-07-12 20:41:42,303 epoch 1 - iter 135/150 - loss 0.96266577 - time (sec): 452.83 - samples/sec: 407.67 - lr: 0.000045 - momentum: 0.000000
2023-07-12 20:42:26,808 epoch 1 - iter 150/150 - loss 0.88204118 - time (sec): 497.33 - samples/sec: 411.33 - lr: 0.000050 - momentum: 0.000000
2023-07-12 20:42:26,809 ----------------------------------------------------------------------------------------------------
2023-07-12 20:42:26,809 EPOCH 1 done: loss 0.8820 - lr: 0.000050
2023-07-12 20:43:10,655 DEV : loss 0.18194133043289185 - f1-score (micro avg)  0.6925
2023-07-12 20:43:51,515 TEST : loss 0.09933698177337646 - f1-score (micro avg)  0.8928
2023-07-12 20:43:51,578 ----------------------------------------------------------------------------------------------------
2023-07-12 20:44:38,185 epoch 2 - iter 15/150 - loss 0.10968998 - time (sec): 46.61 - samples/sec: 439.29 - lr: 0.000049 - momentum: 0.000000
2023-07-12 20:45:22,925 epoch 2 - iter 30/150 - loss 0.10898555 - time (sec): 91.34 - samples/sec: 448.32 - lr: 0.000049 - momentum: 0.000000
2023-07-12 20:46:22,729 epoch 2 - iter 45/150 - loss 0.10004253 - time (sec): 151.15 - samples/sec: 405.84 - lr: 0.000048 - momentum: 0.000000
2023-07-12 20:47:36,931 epoch 2 - iter 60/150 - loss 0.09390666 - time (sec): 225.35 - samples/sec: 359.15 - lr: 0.000048 - momentum: 0.000000
2023-07-12 20:48:32,383 epoch 2 - iter 75/150 - loss 0.09018888 - time (sec): 280.80 - samples/sec: 365.89 - lr: 0.000047 - momentum: 0.000000
2023-07-12 20:49:18,935 epoch 2 - iter 90/150 - loss 0.08649890 - time (sec): 327.36 - samples/sec: 375.67 - lr: 0.000047 - momentum: 0.000000
2023-07-12 20:50:06,455 epoch 2 - iter 105/150 - loss 0.08424242 - time (sec): 374.88 - samples/sec: 383.26 - lr: 0.000046 - momentum: 0.000000
2023-07-12 20:50:52,598 epoch 2 - iter 120/150 - loss 0.08209888 - time (sec): 421.02 - samples/sec: 388.33 - lr: 0.000046 - momentum: 0.000000
2023-07-12 20:51:39,258 epoch 2 - iter 135/150 - loss 0.07989570 - time (sec): 467.68 - samples/sec: 394.04 - lr: 0.000045 - momentum: 0.000000
2023-07-12 20:52:25,521 epoch 2 - iter 150/150 - loss 0.07828882 - time (sec): 513.94 - samples/sec: 398.04 - lr: 0.000045 - momentum: 0.000000
2023-07-12 20:52:25,521 ----------------------------------------------------------------------------------------------------
2023-07-12 20:52:25,521 EPOCH 2 done: loss 0.0783 - lr: 0.000045
2023-07-12 20:53:10,563 DEV : loss 0.15817862749099731 - f1-score (micro avg)  0.7447
2023-07-12 20:53:53,838 TEST : loss 0.08485297858715057 - f1-score (micro avg)  0.9155
2023-07-12 20:53:53,894 ----------------------------------------------------------------------------------------------------
2023-07-12 20:54:39,902 epoch 3 - iter 15/150 - loss 0.05528430 - time (sec): 46.01 - samples/sec: 440.73 - lr: 0.000044 - momentum: 0.000000
2023-07-12 20:55:25,871 epoch 3 - iter 30/150 - loss 0.05091252 - time (sec): 91.97 - samples/sec: 440.61 - lr: 0.000043 - momentum: 0.000000
2023-07-12 20:56:12,555 epoch 3 - iter 45/150 - loss 0.04845053 - time (sec): 138.66 - samples/sec: 440.48 - lr: 0.000043 - momentum: 0.000000
2023-07-12 20:56:58,977 epoch 3 - iter 60/150 - loss 0.04805008 - time (sec): 185.08 - samples/sec: 442.89 - lr: 0.000042 - momentum: 0.000000
2023-07-12 20:57:42,874 epoch 3 - iter 75/150 - loss 0.04736752 - time (sec): 228.98 - samples/sec: 445.78 - lr: 0.000042 - momentum: 0.000000
2023-07-12 20:58:52,678 epoch 3 - iter 90/150 - loss 0.04666556 - time (sec): 298.78 - samples/sec: 409.98 - lr: 0.000041 - momentum: 0.000000
2023-07-12 21:00:05,467 epoch 3 - iter 105/150 - loss 0.04724516 - time (sec): 371.57 - samples/sec: 382.83 - lr: 0.000041 - momentum: 0.000000
2023-07-12 21:00:52,689 epoch 3 - iter 120/150 - loss 0.04710178 - time (sec): 418.79 - samples/sec: 389.05 - lr: 0.000040 - momentum: 0.000000
2023-07-12 21:01:39,235 epoch 3 - iter 135/150 - loss 0.04797246 - time (sec): 465.34 - samples/sec: 394.50 - lr: 0.000040 - momentum: 0.000000
2023-07-12 21:02:25,151 epoch 3 - iter 150/150 - loss 0.04753053 - time (sec): 511.25 - samples/sec: 400.13 - lr: 0.000039 - momentum: 0.000000
2023-07-12 21:02:25,151 ----------------------------------------------------------------------------------------------------
2023-07-12 21:02:25,151 EPOCH 3 done: loss 0.0475 - lr: 0.000039
2023-07-12 21:03:07,494 DEV : loss 0.14594395458698273 - f1-score (micro avg)  0.7557
2023-07-12 21:03:49,700 TEST : loss 0.08655384927988052 - f1-score (micro avg)  0.9241
2023-07-12 21:03:49,750 ----------------------------------------------------------------------------------------------------
2023-07-12 21:04:35,377 epoch 4 - iter 15/150 - loss 0.03446146 - time (sec): 45.63 - samples/sec: 434.60 - lr: 0.000038 - momentum: 0.000000
2023-07-12 21:05:20,985 epoch 4 - iter 30/150 - loss 0.03236388 - time (sec): 91.23 - samples/sec: 449.97 - lr: 0.000038 - momentum: 0.000000
2023-07-12 21:06:04,779 epoch 4 - iter 45/150 - loss 0.03295506 - time (sec): 135.03 - samples/sec: 448.50 - lr: 0.000037 - momentum: 0.000000
2023-07-12 21:06:51,059 epoch 4 - iter 60/150 - loss 0.03479577 - time (sec): 181.31 - samples/sec: 447.77 - lr: 0.000037 - momentum: 0.000000
2023-07-12 21:07:37,455 epoch 4 - iter 75/150 - loss 0.03434530 - time (sec): 227.70 - samples/sec: 447.41 - lr: 0.000036 - momentum: 0.000000
2023-07-12 21:08:23,695 epoch 4 - iter 90/150 - loss 0.03400946 - time (sec): 273.94 - samples/sec: 447.84 - lr: 0.000036 - momentum: 0.000000
2023-07-12 21:09:09,372 epoch 4 - iter 105/150 - loss 0.03452076 - time (sec): 319.62 - samples/sec: 449.41 - lr: 0.000035 - momentum: 0.000000
2023-07-12 21:09:53,968 epoch 4 - iter 120/150 - loss 0.03449836 - time (sec): 364.22 - samples/sec: 448.81 - lr: 0.000035 - momentum: 0.000000
2023-07-12 21:10:56,930 epoch 4 - iter 135/150 - loss 0.03350783 - time (sec): 427.18 - samples/sec: 432.05 - lr: 0.000034 - momentum: 0.000000
2023-07-12 21:12:10,974 epoch 4 - iter 150/150 - loss 0.03319583 - time (sec): 501.22 - samples/sec: 408.14 - lr: 0.000033 - momentum: 0.000000
2023-07-12 21:12:10,975 ----------------------------------------------------------------------------------------------------
2023-07-12 21:12:10,975 EPOCH 4 done: loss 0.0332 - lr: 0.000033
2023-07-12 21:12:58,618 DEV : loss 0.17373745143413544 - f1-score (micro avg)  0.7393
2023-07-12 21:13:41,220 TEST : loss 0.08214078843593597 - f1-score (micro avg)  0.9317
2023-07-12 21:13:41,276 ----------------------------------------------------------------------------------------------------
2023-07-12 21:14:27,100 epoch 5 - iter 15/150 - loss 0.02451173 - time (sec): 45.82 - samples/sec: 440.93 - lr: 0.000033 - momentum: 0.000000
2023-07-12 21:15:13,119 epoch 5 - iter 30/150 - loss 0.02912186 - time (sec): 91.84 - samples/sec: 433.23 - lr: 0.000032 - momentum: 0.000000
2023-07-12 21:15:59,788 epoch 5 - iter 45/150 - loss 0.02822898 - time (sec): 138.51 - samples/sec: 432.45 - lr: 0.000032 - momentum: 0.000000
2023-07-12 21:16:45,897 epoch 5 - iter 60/150 - loss 0.02707267 - time (sec): 184.62 - samples/sec: 434.71 - lr: 0.000031 - momentum: 0.000000
2023-07-12 21:17:31,977 epoch 5 - iter 75/150 - loss 0.02733793 - time (sec): 230.70 - samples/sec: 437.29 - lr: 0.000031 - momentum: 0.000000
2023-07-12 21:18:16,841 epoch 5 - iter 90/150 - loss 0.02675373 - time (sec): 275.56 - samples/sec: 442.74 - lr: 0.000030 - momentum: 0.000000
2023-07-12 21:19:01,405 epoch 5 - iter 105/150 - loss 0.02592297 - time (sec): 320.13 - samples/sec: 447.97 - lr: 0.000030 - momentum: 0.000000
2023-07-12 21:19:47,507 epoch 5 - iter 120/150 - loss 0.02580481 - time (sec): 366.23 - samples/sec: 447.21 - lr: 0.000029 - momentum: 0.000000
2023-07-12 21:20:33,540 epoch 5 - iter 135/150 - loss 0.02637569 - time (sec): 412.26 - samples/sec: 445.51 - lr: 0.000028 - momentum: 0.000000
2023-07-12 21:21:19,887 epoch 5 - iter 150/150 - loss 0.02598604 - time (sec): 458.61 - samples/sec: 446.06 - lr: 0.000028 - momentum: 0.000000
2023-07-12 21:21:19,887 ----------------------------------------------------------------------------------------------------
2023-07-12 21:21:19,887 EPOCH 5 done: loss 0.0260 - lr: 0.000028
2023-07-12 21:22:02,934 DEV : loss 0.19740593433380127 - f1-score (micro avg)  0.7105
2023-07-12 21:22:48,027 TEST : loss 0.09375876933336258 - f1-score (micro avg)  0.9307
2023-07-12 21:22:48,084 ----------------------------------------------------------------------------------------------------
2023-07-12 21:24:01,380 epoch 6 - iter 15/150 - loss 0.01994321 - time (sec): 73.29 - samples/sec: 280.95 - lr: 0.000027 - momentum: 0.000000
2023-07-12 21:25:12,172 epoch 6 - iter 30/150 - loss 0.01849506 - time (sec): 144.09 - samples/sec: 281.73 - lr: 0.000027 - momentum: 0.000000
2023-07-12 21:26:00,327 epoch 6 - iter 45/150 - loss 0.01953672 - time (sec): 192.24 - samples/sec: 319.17 - lr: 0.000026 - momentum: 0.000000
2023-07-12 21:26:47,742 epoch 6 - iter 60/150 - loss 0.01995799 - time (sec): 239.66 - samples/sec: 341.04 - lr: 0.000026 - momentum: 0.000000
2023-07-12 21:27:34,424 epoch 6 - iter 75/150 - loss 0.02034588 - time (sec): 286.34 - samples/sec: 357.76 - lr: 0.000025 - momentum: 0.000000
2023-07-12 21:28:20,509 epoch 6 - iter 90/150 - loss 0.02018396 - time (sec): 332.42 - samples/sec: 371.03 - lr: 0.000025 - momentum: 0.000000
2023-07-12 21:29:07,515 epoch 6 - iter 105/150 - loss 0.02006867 - time (sec): 379.43 - samples/sec: 377.83 - lr: 0.000024 - momentum: 0.000000
2023-07-12 21:29:53,847 epoch 6 - iter 120/150 - loss 0.01992116 - time (sec): 425.76 - samples/sec: 384.46 - lr: 0.000024 - momentum: 0.000000
2023-07-12 21:30:37,691 epoch 6 - iter 135/150 - loss 0.01990890 - time (sec): 469.61 - samples/sec: 392.09 - lr: 0.000023 - momentum: 0.000000
2023-07-12 21:31:22,631 epoch 6 - iter 150/150 - loss 0.02048905 - time (sec): 514.55 - samples/sec: 397.57 - lr: 0.000022 - momentum: 0.000000
2023-07-12 21:31:22,632 ----------------------------------------------------------------------------------------------------
2023-07-12 21:31:22,632 EPOCH 6 done: loss 0.0205 - lr: 0.000022
2023-07-12 21:32:05,132 DEV : loss 0.18033258616924286 - f1-score (micro avg)  0.73
2023-07-12 21:32:46,065 TEST : loss 0.10510878264904022 - f1-score (micro avg)  0.9149
2023-07-12 21:32:46,116 ----------------------------------------------------------------------------------------------------
2023-07-12 21:33:31,937 epoch 7 - iter 15/150 - loss 0.05125662 - time (sec): 45.82 - samples/sec: 449.55 - lr: 0.000022 - momentum: 0.000000
2023-07-12 21:34:18,091 epoch 7 - iter 30/150 - loss 0.04529202 - time (sec): 91.97 - samples/sec: 451.52 - lr: 0.000021 - momentum: 0.000000
2023-07-12 21:35:02,879 epoch 7 - iter 45/150 - loss 0.04184001 - time (sec): 136.76 - samples/sec: 456.18 - lr: 0.000021 - momentum: 0.000000
2023-07-12 21:36:14,457 epoch 7 - iter 60/150 - loss 0.03999909 - time (sec): 208.34 - samples/sec: 396.05 - lr: 0.000020 - momentum: 0.000000
2023-07-12 21:37:24,864 epoch 7 - iter 75/150 - loss 0.03854529 - time (sec): 278.75 - samples/sec: 369.70 - lr: 0.000020 - momentum: 0.000000
2023-07-12 21:38:11,560 epoch 7 - iter 90/150 - loss 0.03735273 - time (sec): 325.44 - samples/sec: 379.91 - lr: 0.000019 - momentum: 0.000000
2023-07-12 21:38:56,906 epoch 7 - iter 105/150 - loss 0.03578762 - time (sec): 370.79 - samples/sec: 388.02 - lr: 0.000019 - momentum: 0.000000
2023-07-12 21:39:43,317 epoch 7 - iter 120/150 - loss 0.03437351 - time (sec): 417.20 - samples/sec: 394.02 - lr: 0.000018 - momentum: 0.000000
2023-07-12 21:40:29,940 epoch 7 - iter 135/150 - loss 0.03306846 - time (sec): 463.82 - samples/sec: 397.17 - lr: 0.000017 - momentum: 0.000000
2023-07-12 21:41:15,730 epoch 7 - iter 150/150 - loss 0.03220615 - time (sec): 509.61 - samples/sec: 401.42 - lr: 0.000017 - momentum: 0.000000
2023-07-12 21:41:15,731 ----------------------------------------------------------------------------------------------------
2023-07-12 21:41:15,731 EPOCH 7 done: loss 0.0322 - lr: 0.000017
2023-07-12 21:41:59,366 DEV : loss 0.16269458830356598 - f1-score (micro avg)  0.7495
2023-07-12 21:42:42,151 TEST : loss 0.09723882377147675 - f1-score (micro avg)  0.9278
2023-07-12 21:42:42,202 ----------------------------------------------------------------------------------------------------
2023-07-12 21:43:26,413 epoch 8 - iter 15/150 - loss 0.02361514 - time (sec): 44.21 - samples/sec: 454.63 - lr: 0.000016 - momentum: 0.000000
2023-07-12 21:44:13,003 epoch 8 - iter 30/150 - loss 0.01996133 - time (sec): 90.80 - samples/sec: 445.95 - lr: 0.000016 - momentum: 0.000000
2023-07-12 21:44:59,498 epoch 8 - iter 45/150 - loss 0.01821647 - time (sec): 137.29 - samples/sec: 445.57 - lr: 0.000015 - momentum: 0.000000
2023-07-12 21:45:45,825 epoch 8 - iter 60/150 - loss 0.01771292 - time (sec): 183.62 - samples/sec: 448.30 - lr: 0.000015 - momentum: 0.000000
2023-07-12 21:46:31,309 epoch 8 - iter 75/150 - loss 0.01856094 - time (sec): 229.11 - samples/sec: 449.98 - lr: 0.000014 - momentum: 0.000000
2023-07-12 21:47:15,644 epoch 8 - iter 90/150 - loss 0.01839748 - time (sec): 273.44 - samples/sec: 448.21 - lr: 0.000014 - momentum: 0.000000
2023-07-12 21:48:27,608 epoch 8 - iter 105/150 - loss 0.01853978 - time (sec): 345.41 - samples/sec: 413.31 - lr: 0.000013 - momentum: 0.000000
2023-07-12 21:49:38,493 epoch 8 - iter 120/150 - loss 0.01806917 - time (sec): 416.29 - samples/sec: 391.89 - lr: 0.000012 - momentum: 0.000000
2023-07-12 21:50:25,469 epoch 8 - iter 135/150 - loss 0.01852390 - time (sec): 463.27 - samples/sec: 397.42 - lr: 0.000012 - momentum: 0.000000
2023-07-12 21:51:11,891 epoch 8 - iter 150/150 - loss 0.01898906 - time (sec): 509.69 - samples/sec: 401.36 - lr: 0.000011 - momentum: 0.000000
2023-07-12 21:51:11,892 ----------------------------------------------------------------------------------------------------
2023-07-12 21:51:11,892 EPOCH 8 done: loss 0.0190 - lr: 0.000011
2023-07-12 21:51:55,607 DEV : loss 0.1625192016363144 - f1-score (micro avg)  0.7474
2023-07-12 21:52:36,426 TEST : loss 0.09810398519039154 - f1-score (micro avg)  0.9312
2023-07-12 21:52:36,477 ----------------------------------------------------------------------------------------------------
2023-07-12 21:53:21,955 epoch 9 - iter 15/150 - loss 0.01658773 - time (sec): 45.48 - samples/sec: 441.04 - lr: 0.000011 - momentum: 0.000000
2023-07-12 21:54:08,509 epoch 9 - iter 30/150 - loss 0.01449160 - time (sec): 92.03 - samples/sec: 447.30 - lr: 0.000010 - momentum: 0.000000
2023-07-12 21:54:52,808 epoch 9 - iter 45/150 - loss 0.01389572 - time (sec): 136.33 - samples/sec: 451.34 - lr: 0.000010 - momentum: 0.000000
2023-07-12 21:55:36,925 epoch 9 - iter 60/150 - loss 0.01365256 - time (sec): 180.45 - samples/sec: 455.54 - lr: 0.000009 - momentum: 0.000000
2023-07-12 21:56:23,261 epoch 9 - iter 75/150 - loss 0.01429834 - time (sec): 226.78 - samples/sec: 453.79 - lr: 0.000009 - momentum: 0.000000
2023-07-12 21:57:09,228 epoch 9 - iter 90/150 - loss 0.01377981 - time (sec): 272.75 - samples/sec: 452.21 - lr: 0.000008 - momentum: 0.000000
2023-07-12 21:57:55,316 epoch 9 - iter 105/150 - loss 0.01393430 - time (sec): 318.84 - samples/sec: 449.93 - lr: 0.000008 - momentum: 0.000000
2023-07-12 21:58:40,950 epoch 9 - iter 120/150 - loss 0.01402649 - time (sec): 364.47 - samples/sec: 449.79 - lr: 0.000007 - momentum: 0.000000
2023-07-12 21:59:28,665 epoch 9 - iter 135/150 - loss 0.01422089 - time (sec): 412.19 - samples/sec: 447.46 - lr: 0.000006 - momentum: 0.000000
2023-07-12 22:00:42,001 epoch 9 - iter 150/150 - loss 0.01433491 - time (sec): 485.52 - samples/sec: 421.33 - lr: 0.000006 - momentum: 0.000000
2023-07-12 22:00:42,001 ----------------------------------------------------------------------------------------------------
2023-07-12 22:00:42,001 EPOCH 9 done: loss 0.0143 - lr: 0.000006
2023-07-12 22:01:44,409 DEV : loss 0.14854852855205536 - f1-score (micro avg)  0.7626
2023-07-12 22:02:27,607 TEST : loss 0.09575190395116806 - f1-score (micro avg)  0.9337
2023-07-12 22:02:27,658 ----------------------------------------------------------------------------------------------------
2023-07-12 22:03:13,588 epoch 10 - iter 15/150 - loss 0.01568118 - time (sec): 45.93 - samples/sec: 443.41 - lr: 0.000005 - momentum: 0.000000
2023-07-12 22:03:59,713 epoch 10 - iter 30/150 - loss 0.01441849 - time (sec): 92.05 - samples/sec: 443.75 - lr: 0.000005 - momentum: 0.000000
2023-07-12 22:04:46,436 epoch 10 - iter 45/150 - loss 0.01414343 - time (sec): 138.78 - samples/sec: 443.43 - lr: 0.000004 - momentum: 0.000000
2023-07-12 22:05:32,463 epoch 10 - iter 60/150 - loss 0.01337785 - time (sec): 184.80 - samples/sec: 441.81 - lr: 0.000004 - momentum: 0.000000
2023-07-12 22:06:18,663 epoch 10 - iter 75/150 - loss 0.01318407 - time (sec): 231.00 - samples/sec: 440.09 - lr: 0.000003 - momentum: 0.000000
2023-07-12 22:07:02,412 epoch 10 - iter 90/150 - loss 0.01313308 - time (sec): 274.75 - samples/sec: 444.10 - lr: 0.000003 - momentum: 0.000000
2023-07-12 22:07:46,324 epoch 10 - iter 105/150 - loss 0.01307311 - time (sec): 318.66 - samples/sec: 448.37 - lr: 0.000002 - momentum: 0.000000
2023-07-12 22:08:32,682 epoch 10 - iter 120/150 - loss 0.01283534 - time (sec): 365.02 - samples/sec: 447.70 - lr: 0.000001 - momentum: 0.000000
2023-07-12 22:09:18,677 epoch 10 - iter 135/150 - loss 0.01249653 - time (sec): 411.02 - samples/sec: 447.41 - lr: 0.000001 - momentum: 0.000000
2023-07-12 22:10:05,469 epoch 10 - iter 150/150 - loss 0.01242810 - time (sec): 457.81 - samples/sec: 446.84 - lr: 0.000000 - momentum: 0.000000
2023-07-12 22:10:05,470 ----------------------------------------------------------------------------------------------------
2023-07-12 22:10:05,470 EPOCH 10 done: loss 0.0124 - lr: 0.000000
2023-07-12 22:10:48,008 DEV : loss 0.15656980872154236 - f1-score (micro avg)  0.7587
2023-07-12 22:11:33,972 TEST : loss 0.09605014324188232 - f1-score (micro avg)  0.9348
2023-07-12 22:11:48,207 ----------------------------------------------------------------------------------------------------
2023-07-12 22:11:48,213 Testing using last state of model ...
2023-07-12 22:12:57,041 
Results:
- F-score (micro) 0.9348
- F-score (macro) 0.9193
- Accuracy 0.9015

By class:
              precision    recall  f1-score   support

         ORG     0.9165    0.9380    0.9271      1661
         LOC     0.9494    0.9448    0.9471      1668
         PER     0.9857    0.9777    0.9817      1617
        MISC     0.7880    0.8575    0.8213       702

   micro avg     0.9282    0.9414    0.9348      5648
   macro avg     0.9099    0.9295    0.9193      5648
weighted avg     0.9300    0.9414    0.9355      5648

2023-07-12 22:12:57,041 ----------------------------------------------------------------------------------------------------
