2023-07-12 06:03:00,541 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Corpus: 14987 train + 3160 dev + 3684 test sentences
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Train:  14987 sentences
2023-07-12 06:03:00,542         (train_with_dev=False, train_with_test=False)
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Training Params:
2023-07-12 06:03:00,542  - learning_rate: "8e-05" 
2023-07-12 06:03:00,542  - mini_batch_size: "100"
2023-07-12 06:03:00,542  - max_epochs: "10"
2023-07-12 06:03:00,542  - shuffle: "True"
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Plugins:
2023-07-12 06:03:00,542  - LinearScheduler | warmup_fraction: '0.1'
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Final evaluation on model after last epoch (final-model.pt)
2023-07-12 06:03:00,542  - metric: "('micro avg', 'f1-score')"
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Computation:
2023-07-12 06:03:00,542  - compute on device: cuda:3
2023-07-12 06:03:00,542  - embedding storage: none
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Model training base path: "resources/taggers/conll_eng_ner_roberta_large_mini_batch_100_lr_8e-05_run_2_ger_test_as_dev"
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 Removed gradient clipping
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:00,542 ----------------------------------------------------------------------------------------------------
2023-07-12 06:03:44,757 epoch 1 - iter 15/150 - loss 2.80459156 - time (sec): 44.21 - samples/sec: 450.86 - lr: 0.000007 - momentum: 0.000000
2023-07-12 06:04:28,793 epoch 1 - iter 30/150 - loss 2.05989043 - time (sec): 88.25 - samples/sec: 456.72 - lr: 0.000015 - momentum: 0.000000
2023-07-12 06:05:13,272 epoch 1 - iter 45/150 - loss 1.60268371 - time (sec): 132.73 - samples/sec: 460.85 - lr: 0.000023 - momentum: 0.000000
2023-07-12 06:05:57,250 epoch 1 - iter 60/150 - loss 1.33986713 - time (sec): 176.71 - samples/sec: 462.17 - lr: 0.000031 - momentum: 0.000000
2023-07-12 06:06:42,521 epoch 1 - iter 75/150 - loss 1.13882385 - time (sec): 221.98 - samples/sec: 462.89 - lr: 0.000039 - momentum: 0.000000
2023-07-12 06:07:27,099 epoch 1 - iter 90/150 - loss 0.99176034 - time (sec): 266.55 - samples/sec: 462.67 - lr: 0.000047 - momentum: 0.000000
2023-07-12 06:08:11,311 epoch 1 - iter 105/150 - loss 0.87929538 - time (sec): 310.77 - samples/sec: 462.03 - lr: 0.000055 - momentum: 0.000000
2023-07-12 06:08:56,647 epoch 1 - iter 120/150 - loss 0.78830306 - time (sec): 356.10 - samples/sec: 459.51 - lr: 0.000063 - momentum: 0.000000
2023-07-12 06:09:42,149 epoch 1 - iter 135/150 - loss 0.71155974 - time (sec): 401.60 - samples/sec: 459.23 - lr: 0.000071 - momentum: 0.000000
2023-07-12 06:10:27,246 epoch 1 - iter 150/150 - loss 0.65235013 - time (sec): 446.70 - samples/sec: 457.95 - lr: 0.000079 - momentum: 0.000000
2023-07-12 06:10:27,247 ----------------------------------------------------------------------------------------------------
2023-07-12 06:10:27,247 EPOCH 1 done: loss 0.6524 - lr: 0.000079
2023-07-12 06:11:09,774 DEV : loss 0.18713469803333282 - f1-score (micro avg)  0.7259
2023-07-12 06:11:49,490 TEST : loss 0.09674272686243057 - f1-score (micro avg)  0.9052
2023-07-12 06:11:49,537 ----------------------------------------------------------------------------------------------------
2023-07-12 06:12:33,711 epoch 2 - iter 15/150 - loss 0.08479241 - time (sec): 44.17 - samples/sec: 444.22 - lr: 0.000079 - momentum: 0.000000
2023-07-12 06:13:18,157 epoch 2 - iter 30/150 - loss 0.09189225 - time (sec): 88.62 - samples/sec: 457.45 - lr: 0.000078 - momentum: 0.000000
2023-07-12 06:14:03,022 epoch 2 - iter 45/150 - loss 0.09350837 - time (sec): 133.48 - samples/sec: 462.61 - lr: 0.000077 - momentum: 0.000000
2023-07-12 06:14:48,108 epoch 2 - iter 60/150 - loss 0.08901406 - time (sec): 178.57 - samples/sec: 459.53 - lr: 0.000077 - momentum: 0.000000
2023-07-12 06:15:32,958 epoch 2 - iter 75/150 - loss 0.08656375 - time (sec): 223.42 - samples/sec: 456.39 - lr: 0.000076 - momentum: 0.000000
2023-07-12 06:16:18,660 epoch 2 - iter 90/150 - loss 0.08256440 - time (sec): 269.12 - samples/sec: 456.33 - lr: 0.000075 - momentum: 0.000000
2023-07-12 06:17:03,550 epoch 2 - iter 105/150 - loss 0.08050243 - time (sec): 314.01 - samples/sec: 455.63 - lr: 0.000074 - momentum: 0.000000
2023-07-12 06:17:49,110 epoch 2 - iter 120/150 - loss 0.07712791 - time (sec): 359.57 - samples/sec: 456.28 - lr: 0.000073 - momentum: 0.000000
2023-07-12 06:18:33,965 epoch 2 - iter 135/150 - loss 0.07504107 - time (sec): 404.43 - samples/sec: 456.44 - lr: 0.000072 - momentum: 0.000000
2023-07-12 06:19:18,135 epoch 2 - iter 150/150 - loss 0.07334819 - time (sec): 448.60 - samples/sec: 456.02 - lr: 0.000071 - momentum: 0.000000
2023-07-12 06:19:18,135 ----------------------------------------------------------------------------------------------------
2023-07-12 06:19:18,135 EPOCH 2 done: loss 0.0733 - lr: 0.000071
2023-07-12 06:20:00,726 DEV : loss 0.1691417247056961 - f1-score (micro avg)  0.7212
2023-07-12 06:20:40,770 TEST : loss 0.10660930722951889 - f1-score (micro avg)  0.9066
2023-07-12 06:20:40,816 ----------------------------------------------------------------------------------------------------
2023-07-12 06:21:25,348 epoch 3 - iter 15/150 - loss 0.06489969 - time (sec): 44.53 - samples/sec: 465.16 - lr: 0.000070 - momentum: 0.000000
2023-07-12 06:22:09,520 epoch 3 - iter 30/150 - loss 0.06245582 - time (sec): 88.70 - samples/sec: 464.33 - lr: 0.000069 - momentum: 0.000000
2023-07-12 06:22:53,778 epoch 3 - iter 45/150 - loss 0.05772543 - time (sec): 132.96 - samples/sec: 463.03 - lr: 0.000069 - momentum: 0.000000
2023-07-12 06:23:38,646 epoch 3 - iter 60/150 - loss 0.05975552 - time (sec): 177.83 - samples/sec: 463.46 - lr: 0.000068 - momentum: 0.000000
2023-07-12 06:24:23,835 epoch 3 - iter 75/150 - loss 0.05811903 - time (sec): 223.02 - samples/sec: 459.13 - lr: 0.000067 - momentum: 0.000000
2023-07-12 06:25:06,429 epoch 3 - iter 90/150 - loss 0.06063826 - time (sec): 265.61 - samples/sec: 463.74 - lr: 0.000066 - momentum: 0.000000
2023-07-12 06:25:49,632 epoch 3 - iter 105/150 - loss 0.06129236 - time (sec): 308.81 - samples/sec: 464.00 - lr: 0.000065 - momentum: 0.000000
2023-07-12 06:26:34,109 epoch 3 - iter 120/150 - loss 0.05915888 - time (sec): 353.29 - samples/sec: 465.06 - lr: 0.000064 - momentum: 0.000000
2023-07-12 06:27:18,798 epoch 3 - iter 135/150 - loss 0.05857706 - time (sec): 397.98 - samples/sec: 462.29 - lr: 0.000063 - momentum: 0.000000
2023-07-12 06:28:03,398 epoch 3 - iter 150/150 - loss 0.05723804 - time (sec): 442.58 - samples/sec: 462.21 - lr: 0.000062 - momentum: 0.000000
2023-07-12 06:28:03,398 ----------------------------------------------------------------------------------------------------
2023-07-12 06:28:03,399 EPOCH 3 done: loss 0.0572 - lr: 0.000062
2023-07-12 06:28:44,803 DEV : loss 0.17861564457416534 - f1-score (micro avg)  0.7061
2023-07-12 06:29:25,737 TEST : loss 0.10103881359100342 - f1-score (micro avg)  0.9087
2023-07-12 06:29:25,784 ----------------------------------------------------------------------------------------------------
2023-07-12 06:30:10,577 epoch 4 - iter 15/150 - loss 0.03764255 - time (sec): 44.79 - samples/sec: 474.80 - lr: 0.000062 - momentum: 0.000000
2023-07-12 06:30:55,163 epoch 4 - iter 30/150 - loss 0.03559628 - time (sec): 89.38 - samples/sec: 469.54 - lr: 0.000061 - momentum: 0.000000
2023-07-12 06:31:40,293 epoch 4 - iter 45/150 - loss 0.03748571 - time (sec): 134.51 - samples/sec: 462.19 - lr: 0.000060 - momentum: 0.000000
2023-07-12 06:32:25,306 epoch 4 - iter 60/150 - loss 0.03837007 - time (sec): 179.52 - samples/sec: 457.32 - lr: 0.000059 - momentum: 0.000000
2023-07-12 06:33:10,049 epoch 4 - iter 75/150 - loss 0.04188052 - time (sec): 224.26 - samples/sec: 457.94 - lr: 0.000058 - momentum: 0.000000
2023-07-12 06:33:55,009 epoch 4 - iter 90/150 - loss 0.04408778 - time (sec): 269.22 - samples/sec: 456.83 - lr: 0.000057 - momentum: 0.000000
2023-07-12 06:34:39,747 epoch 4 - iter 105/150 - loss 0.04436573 - time (sec): 313.96 - samples/sec: 458.14 - lr: 0.000056 - momentum: 0.000000
2023-07-12 06:35:25,406 epoch 4 - iter 120/150 - loss 0.04507623 - time (sec): 359.62 - samples/sec: 457.17 - lr: 0.000055 - momentum: 0.000000
2023-07-12 06:36:11,184 epoch 4 - iter 135/150 - loss 0.04451477 - time (sec): 405.40 - samples/sec: 455.89 - lr: 0.000054 - momentum: 0.000000
2023-07-12 06:36:55,484 epoch 4 - iter 150/150 - loss 0.04343817 - time (sec): 449.70 - samples/sec: 454.90 - lr: 0.000054 - momentum: 0.000000
2023-07-12 06:36:55,484 ----------------------------------------------------------------------------------------------------
2023-07-12 06:36:55,484 EPOCH 4 done: loss 0.0434 - lr: 0.000054
2023-07-12 06:37:36,887 DEV : loss 0.14495334029197693 - f1-score (micro avg)  0.7501
2023-07-12 06:38:17,849 TEST : loss 0.09702593088150024 - f1-score (micro avg)  0.9233
2023-07-12 06:38:17,895 ----------------------------------------------------------------------------------------------------
2023-07-12 06:39:02,771 epoch 5 - iter 15/150 - loss 0.03128130 - time (sec): 44.87 - samples/sec: 466.27 - lr: 0.000053 - momentum: 0.000000
2023-07-12 06:39:46,821 epoch 5 - iter 30/150 - loss 0.02916432 - time (sec): 88.92 - samples/sec: 454.26 - lr: 0.000052 - momentum: 0.000000
2023-07-12 06:40:31,890 epoch 5 - iter 45/150 - loss 0.02882290 - time (sec): 133.99 - samples/sec: 455.70 - lr: 0.000051 - momentum: 0.000000
2023-07-12 06:41:16,794 epoch 5 - iter 60/150 - loss 0.02860443 - time (sec): 178.90 - samples/sec: 455.54 - lr: 0.000050 - momentum: 0.000000
2023-07-12 06:42:01,738 epoch 5 - iter 75/150 - loss 0.03014133 - time (sec): 223.84 - samples/sec: 452.93 - lr: 0.000049 - momentum: 0.000000
2023-07-12 06:42:48,272 epoch 5 - iter 90/150 - loss 0.03078331 - time (sec): 270.37 - samples/sec: 451.45 - lr: 0.000048 - momentum: 0.000000
2023-07-12 06:43:33,269 epoch 5 - iter 105/150 - loss 0.02987674 - time (sec): 315.37 - samples/sec: 453.90 - lr: 0.000047 - momentum: 0.000000
2023-07-12 06:44:18,236 epoch 5 - iter 120/150 - loss 0.03216217 - time (sec): 360.34 - samples/sec: 453.07 - lr: 0.000046 - momentum: 0.000000
2023-07-12 06:45:03,713 epoch 5 - iter 135/150 - loss 0.03188161 - time (sec): 405.82 - samples/sec: 453.52 - lr: 0.000046 - momentum: 0.000000
2023-07-12 06:45:48,156 epoch 5 - iter 150/150 - loss 0.03085720 - time (sec): 450.26 - samples/sec: 454.33 - lr: 0.000045 - momentum: 0.000000
2023-07-12 06:45:48,156 ----------------------------------------------------------------------------------------------------
2023-07-12 06:45:48,156 EPOCH 5 done: loss 0.0309 - lr: 0.000045
2023-07-12 06:46:29,521 DEV : loss 0.1756155788898468 - f1-score (micro avg)  0.7162
2023-07-12 06:47:10,612 TEST : loss 0.09507379680871964 - f1-score (micro avg)  0.9273
2023-07-12 06:47:10,660 ----------------------------------------------------------------------------------------------------
2023-07-12 06:47:55,152 epoch 6 - iter 15/150 - loss 0.02168754 - time (sec): 44.49 - samples/sec: 461.68 - lr: 0.000044 - momentum: 0.000000
2023-07-12 06:48:39,465 epoch 6 - iter 30/150 - loss 0.02086617 - time (sec): 88.80 - samples/sec: 453.95 - lr: 0.000043 - momentum: 0.000000
2023-07-12 06:49:23,921 epoch 6 - iter 45/150 - loss 0.02170552 - time (sec): 133.26 - samples/sec: 460.85 - lr: 0.000042 - momentum: 0.000000
2023-07-12 06:50:08,192 epoch 6 - iter 60/150 - loss 0.02158816 - time (sec): 177.53 - samples/sec: 460.67 - lr: 0.000041 - momentum: 0.000000
2023-07-12 06:50:53,599 epoch 6 - iter 75/150 - loss 0.02103231 - time (sec): 222.94 - samples/sec: 458.87 - lr: 0.000040 - momentum: 0.000000
2023-07-12 06:51:38,472 epoch 6 - iter 90/150 - loss 0.02122907 - time (sec): 267.81 - samples/sec: 459.39 - lr: 0.000039 - momentum: 0.000000
2023-07-12 06:52:23,895 epoch 6 - iter 105/150 - loss 0.02133869 - time (sec): 313.23 - samples/sec: 459.24 - lr: 0.000039 - momentum: 0.000000
2023-07-12 06:53:08,033 epoch 6 - iter 120/150 - loss 0.02114203 - time (sec): 357.37 - samples/sec: 461.68 - lr: 0.000038 - momentum: 0.000000
2023-07-12 06:53:52,277 epoch 6 - iter 135/150 - loss 0.02146377 - time (sec): 401.62 - samples/sec: 459.65 - lr: 0.000037 - momentum: 0.000000
2023-07-12 06:54:36,864 epoch 6 - iter 150/150 - loss 0.02124371 - time (sec): 446.20 - samples/sec: 458.46 - lr: 0.000036 - momentum: 0.000000
2023-07-12 06:54:36,865 ----------------------------------------------------------------------------------------------------
2023-07-12 06:54:36,865 EPOCH 6 done: loss 0.0212 - lr: 0.000036
2023-07-12 06:55:18,123 DEV : loss 0.17647498846054077 - f1-score (micro avg)  0.7268
2023-07-12 06:55:58,079 TEST : loss 0.09910326451063156 - f1-score (micro avg)  0.9256
2023-07-12 06:55:58,147 ----------------------------------------------------------------------------------------------------
2023-07-12 06:56:44,885 epoch 7 - iter 15/150 - loss 0.01701758 - time (sec): 46.74 - samples/sec: 459.58 - lr: 0.000035 - momentum: 0.000000
2023-07-12 06:57:29,715 epoch 7 - iter 30/150 - loss 0.01478108 - time (sec): 91.57 - samples/sec: 461.99 - lr: 0.000034 - momentum: 0.000000
2023-07-12 06:58:15,214 epoch 7 - iter 45/150 - loss 0.01585495 - time (sec): 137.07 - samples/sec: 460.20 - lr: 0.000033 - momentum: 0.000000
2023-07-12 06:58:59,827 epoch 7 - iter 60/150 - loss 0.01542871 - time (sec): 181.68 - samples/sec: 460.98 - lr: 0.000032 - momentum: 0.000000
2023-07-12 06:59:44,214 epoch 7 - iter 75/150 - loss 0.01842043 - time (sec): 226.06 - samples/sec: 461.62 - lr: 0.000031 - momentum: 0.000000
2023-07-12 07:00:29,241 epoch 7 - iter 90/150 - loss 0.02167234 - time (sec): 271.09 - samples/sec: 457.18 - lr: 0.000031 - momentum: 0.000000
2023-07-12 07:01:13,857 epoch 7 - iter 105/150 - loss 0.02207034 - time (sec): 315.71 - samples/sec: 456.67 - lr: 0.000030 - momentum: 0.000000
2023-07-12 07:01:59,694 epoch 7 - iter 120/150 - loss 0.02169926 - time (sec): 361.55 - samples/sec: 454.00 - lr: 0.000029 - momentum: 0.000000
2023-07-12 07:02:44,100 epoch 7 - iter 135/150 - loss 0.02113525 - time (sec): 405.95 - samples/sec: 455.67 - lr: 0.000028 - momentum: 0.000000
2023-07-12 07:03:28,670 epoch 7 - iter 150/150 - loss 0.02052013 - time (sec): 450.52 - samples/sec: 454.07 - lr: 0.000027 - momentum: 0.000000
2023-07-12 07:03:28,670 ----------------------------------------------------------------------------------------------------
2023-07-12 07:03:28,670 EPOCH 7 done: loss 0.0205 - lr: 0.000027
2023-07-12 07:04:09,969 DEV : loss 0.17953787744045258 - f1-score (micro avg)  0.7366
2023-07-12 07:04:49,658 TEST : loss 0.1019153967499733 - f1-score (micro avg)  0.9294
2023-07-12 07:04:49,705 ----------------------------------------------------------------------------------------------------
2023-07-12 07:05:34,233 epoch 8 - iter 15/150 - loss 0.01226354 - time (sec): 44.53 - samples/sec: 449.89 - lr: 0.000026 - momentum: 0.000000
2023-07-12 07:06:19,412 epoch 8 - iter 30/150 - loss 0.01169660 - time (sec): 89.71 - samples/sec: 446.75 - lr: 0.000025 - momentum: 0.000000
2023-07-12 07:07:04,585 epoch 8 - iter 45/150 - loss 0.01165841 - time (sec): 134.88 - samples/sec: 451.55 - lr: 0.000024 - momentum: 0.000000
2023-07-12 07:07:49,366 epoch 8 - iter 60/150 - loss 0.01242551 - time (sec): 179.66 - samples/sec: 452.25 - lr: 0.000024 - momentum: 0.000000
2023-07-12 07:08:34,566 epoch 8 - iter 75/150 - loss 0.01153668 - time (sec): 224.86 - samples/sec: 451.14 - lr: 0.000023 - momentum: 0.000000
2023-07-12 07:09:19,166 epoch 8 - iter 90/150 - loss 0.01204113 - time (sec): 269.46 - samples/sec: 451.65 - lr: 0.000022 - momentum: 0.000000
2023-07-12 07:10:03,824 epoch 8 - iter 105/150 - loss 0.01250750 - time (sec): 314.12 - samples/sec: 454.02 - lr: 0.000021 - momentum: 0.000000
2023-07-12 07:10:48,670 epoch 8 - iter 120/150 - loss 0.01236445 - time (sec): 358.96 - samples/sec: 453.96 - lr: 0.000020 - momentum: 0.000000
2023-07-12 07:11:33,731 epoch 8 - iter 135/150 - loss 0.01213634 - time (sec): 404.02 - samples/sec: 455.53 - lr: 0.000019 - momentum: 0.000000
2023-07-12 07:12:18,103 epoch 8 - iter 150/150 - loss 0.01205862 - time (sec): 448.40 - samples/sec: 456.22 - lr: 0.000018 - momentum: 0.000000
2023-07-12 07:12:18,103 ----------------------------------------------------------------------------------------------------
2023-07-12 07:12:18,103 EPOCH 8 done: loss 0.0121 - lr: 0.000018
2023-07-12 07:13:00,708 DEV : loss 0.18367886543273926 - f1-score (micro avg)  0.745
2023-07-12 07:13:40,560 TEST : loss 0.10396763682365417 - f1-score (micro avg)  0.933
2023-07-12 07:13:40,607 ----------------------------------------------------------------------------------------------------
2023-07-12 07:14:24,974 epoch 9 - iter 15/150 - loss 0.00712905 - time (sec): 44.36 - samples/sec: 463.05 - lr: 0.000017 - momentum: 0.000000
2023-07-12 07:15:09,563 epoch 9 - iter 30/150 - loss 0.00662370 - time (sec): 88.95 - samples/sec: 461.33 - lr: 0.000016 - momentum: 0.000000
2023-07-12 07:15:54,624 epoch 9 - iter 45/150 - loss 0.00696285 - time (sec): 134.02 - samples/sec: 458.01 - lr: 0.000016 - momentum: 0.000000
2023-07-12 07:16:39,521 epoch 9 - iter 60/150 - loss 0.00790459 - time (sec): 178.91 - samples/sec: 452.04 - lr: 0.000015 - momentum: 0.000000
2023-07-12 07:17:24,343 epoch 9 - iter 75/150 - loss 0.00815460 - time (sec): 223.73 - samples/sec: 453.49 - lr: 0.000014 - momentum: 0.000000
2023-07-12 07:18:09,593 epoch 9 - iter 90/150 - loss 0.00837401 - time (sec): 268.98 - samples/sec: 453.16 - lr: 0.000013 - momentum: 0.000000
2023-07-12 07:18:54,866 epoch 9 - iter 105/150 - loss 0.00821819 - time (sec): 314.26 - samples/sec: 452.20 - lr: 0.000012 - momentum: 0.000000
2023-07-12 07:19:39,365 epoch 9 - iter 120/150 - loss 0.00885705 - time (sec): 358.76 - samples/sec: 453.74 - lr: 0.000011 - momentum: 0.000000
2023-07-12 07:20:23,920 epoch 9 - iter 135/150 - loss 0.00840813 - time (sec): 403.31 - samples/sec: 455.93 - lr: 0.000010 - momentum: 0.000000
2023-07-12 07:21:08,836 epoch 9 - iter 150/150 - loss 0.00848130 - time (sec): 448.23 - samples/sec: 456.39 - lr: 0.000009 - momentum: 0.000000
2023-07-12 07:21:08,836 ----------------------------------------------------------------------------------------------------
2023-07-12 07:21:08,836 EPOCH 9 done: loss 0.0085 - lr: 0.000009
2023-07-12 07:21:51,804 DEV : loss 0.17832918465137482 - f1-score (micro avg)  0.7482
2023-07-12 07:22:31,711 TEST : loss 0.10214872658252716 - f1-score (micro avg)  0.934
2023-07-12 07:22:31,765 ----------------------------------------------------------------------------------------------------
2023-07-12 07:23:16,929 epoch 10 - iter 15/150 - loss 0.00742754 - time (sec): 45.16 - samples/sec: 454.01 - lr: 0.000008 - momentum: 0.000000
2023-07-12 07:24:01,219 epoch 10 - iter 30/150 - loss 0.00623807 - time (sec): 89.45 - samples/sec: 456.95 - lr: 0.000008 - momentum: 0.000000
2023-07-12 07:24:46,832 epoch 10 - iter 45/150 - loss 0.00611204 - time (sec): 135.06 - samples/sec: 454.37 - lr: 0.000007 - momentum: 0.000000
2023-07-12 07:25:31,693 epoch 10 - iter 60/150 - loss 0.00657050 - time (sec): 179.93 - samples/sec: 452.98 - lr: 0.000006 - momentum: 0.000000
2023-07-12 07:26:17,699 epoch 10 - iter 75/150 - loss 0.00619555 - time (sec): 225.93 - samples/sec: 451.20 - lr: 0.000005 - momentum: 0.000000
2023-07-12 07:27:01,693 epoch 10 - iter 90/150 - loss 0.00650203 - time (sec): 269.93 - samples/sec: 453.15 - lr: 0.000004 - momentum: 0.000000
2023-07-12 07:27:46,698 epoch 10 - iter 105/150 - loss 0.00646253 - time (sec): 314.93 - samples/sec: 455.14 - lr: 0.000003 - momentum: 0.000000
2023-07-12 07:28:31,756 epoch 10 - iter 120/150 - loss 0.00671079 - time (sec): 359.99 - samples/sec: 454.80 - lr: 0.000002 - momentum: 0.000000
2023-07-12 07:29:16,569 epoch 10 - iter 135/150 - loss 0.00665271 - time (sec): 404.80 - samples/sec: 455.29 - lr: 0.000001 - momentum: 0.000000
2023-07-12 07:30:02,048 epoch 10 - iter 150/150 - loss 0.00673694 - time (sec): 450.28 - samples/sec: 454.31 - lr: 0.000001 - momentum: 0.000000
2023-07-12 07:30:02,049 ----------------------------------------------------------------------------------------------------
2023-07-12 07:30:02,049 EPOCH 10 done: loss 0.0067 - lr: 0.000001
2023-07-12 07:30:44,829 DEV : loss 0.17780092358589172 - f1-score (micro avg)  0.7516
2023-07-12 07:31:24,630 TEST : loss 0.10085146129131317 - f1-score (micro avg)  0.936
2023-07-12 07:31:37,474 ----------------------------------------------------------------------------------------------------
2023-07-12 07:31:37,479 Testing using last state of model ...
2023-07-12 07:32:16,922 
Results:
- F-score (micro) 0.936
- F-score (macro) 0.9225
- Accuracy 0.9066

By class:
              precision    recall  f1-score   support

         ORG     0.9152    0.9416    0.9282      1661
         LOC     0.9485    0.9388    0.9437      1668
         PER     0.9790    0.9808    0.9799      1617
        MISC     0.8173    0.8604    0.8383       702

   micro avg     0.9302    0.9419    0.9360      5648
   macro avg     0.9150    0.9304    0.9225      5648
weighted avg     0.9311    0.9419    0.9364      5648

2023-07-12 07:32:16,922 ----------------------------------------------------------------------------------------------------
