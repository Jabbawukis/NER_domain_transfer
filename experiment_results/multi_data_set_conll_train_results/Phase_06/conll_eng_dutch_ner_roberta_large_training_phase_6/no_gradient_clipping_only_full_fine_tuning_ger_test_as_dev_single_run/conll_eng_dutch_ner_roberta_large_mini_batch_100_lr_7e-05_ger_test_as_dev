2023-07-21 10:37:16,232 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,234 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-21 10:37:16,234 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,234 MultiCorpus: 31080 train + 3160 dev + 8998 test sentences
 - CONLL_03_DUTCH Corpus: 16093 train + 2969 dev + 5314 test sentences - /vol/fob-vol4/mi17/christod/.flair/datasets/conll_03_dutch
 - CONLL_03 Corpus: 14987 train + 3466 dev + 3684 test sentences - /vol/fob-vol4/mi17/christod/.flair/datasets/conll_03
2023-07-21 10:37:16,234 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,234 Train:  31080 sentences
2023-07-21 10:37:16,234         (train_with_dev=False, train_with_test=False)
2023-07-21 10:37:16,234 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,234 Training Params:
2023-07-21 10:37:16,234  - learning_rate: "7e-05" 
2023-07-21 10:37:16,235  - mini_batch_size: "100"
2023-07-21 10:37:16,235  - max_epochs: "10"
2023-07-21 10:37:16,235  - shuffle: "True"
2023-07-21 10:37:16,235 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,235 Plugins:
2023-07-21 10:37:16,235  - LinearScheduler | warmup_fraction: '0.1'
2023-07-21 10:37:16,235 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,235 Final evaluation on model after last epoch (final-model.pt)
2023-07-21 10:37:16,235  - metric: "('micro avg', 'f1-score')"
2023-07-21 10:37:16,235 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,235 Computation:
2023-07-21 10:37:16,235  - compute on device: cuda:2
2023-07-21 10:37:16,235  - embedding storage: none
2023-07-21 10:37:16,235 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,235 Model training base path: "resources/taggers/conll_eng_dutch_ner_roberta_large_mini_batch_100_lr_7e-05_ger_test_as_dev"
2023-07-21 10:37:16,235 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,235 Removed gradient clipping
2023-07-21 10:37:16,235 ----------------------------------------------------------------------------------------------------
2023-07-21 10:37:16,235 ----------------------------------------------------------------------------------------------------
2023-07-21 10:39:26,506 epoch 1 - iter 31/311 - loss 2.93238246 - time (sec): 130.27 - samples/sec: 309.77 - lr: 0.000007 - momentum: 0.000000
2023-07-21 10:41:35,607 epoch 1 - iter 62/311 - loss 1.79562135 - time (sec): 259.37 - samples/sec: 315.54 - lr: 0.000014 - momentum: 0.000000
2023-07-21 10:43:40,989 epoch 1 - iter 93/311 - loss 1.34354802 - time (sec): 384.75 - samples/sec: 316.67 - lr: 0.000021 - momentum: 0.000000
2023-07-21 10:45:49,581 epoch 1 - iter 124/311 - loss 1.07378270 - time (sec): 513.34 - samples/sec: 317.29 - lr: 0.000028 - momentum: 0.000000
2023-07-21 10:47:57,735 epoch 1 - iter 155/311 - loss 0.89181686 - time (sec): 641.50 - samples/sec: 319.01 - lr: 0.000035 - momentum: 0.000000
2023-07-21 10:50:04,942 epoch 1 - iter 186/311 - loss 0.76785132 - time (sec): 768.71 - samples/sec: 318.14 - lr: 0.000042 - momentum: 0.000000
2023-07-21 10:52:09,886 epoch 1 - iter 217/311 - loss 0.67168552 - time (sec): 893.65 - samples/sec: 319.04 - lr: 0.000049 - momentum: 0.000000
2023-07-21 10:54:21,753 epoch 1 - iter 248/311 - loss 0.60052433 - time (sec): 1025.52 - samples/sec: 317.36 - lr: 0.000056 - momentum: 0.000000
2023-07-21 10:56:33,474 epoch 1 - iter 279/311 - loss 0.54432687 - time (sec): 1157.24 - samples/sec: 316.29 - lr: 0.000063 - momentum: 0.000000
2023-07-21 10:58:47,430 epoch 1 - iter 310/311 - loss 0.49882356 - time (sec): 1291.19 - samples/sec: 314.74 - lr: 0.000070 - momentum: 0.000000
2023-07-21 10:58:50,122 ----------------------------------------------------------------------------------------------------
2023-07-21 10:58:50,122 EPOCH 1 done: loss 0.4977 - lr: 0.000070
2023-07-21 10:59:54,254 DEV : loss 0.161345437169075 - f1-score (micro avg)  0.7117
2023-07-21 11:02:20,329 TEST : loss 0.07210779935121536 - f1-score (micro avg)  0.8946
2023-07-21 11:02:20,497 ----------------------------------------------------------------------------------------------------
2023-07-21 11:04:30,232 epoch 2 - iter 31/311 - loss 0.07481343 - time (sec): 129.73 - samples/sec: 322.28 - lr: 0.000069 - momentum: 0.000000
2023-07-21 11:06:31,180 epoch 2 - iter 62/311 - loss 0.07504247 - time (sec): 250.68 - samples/sec: 328.58 - lr: 0.000068 - momentum: 0.000000
2023-07-21 11:08:40,266 epoch 2 - iter 93/311 - loss 0.07343856 - time (sec): 379.77 - samples/sec: 325.69 - lr: 0.000068 - momentum: 0.000000
2023-07-21 11:10:47,873 epoch 2 - iter 124/311 - loss 0.07085720 - time (sec): 507.37 - samples/sec: 323.45 - lr: 0.000067 - momentum: 0.000000
2023-07-21 11:12:54,128 epoch 2 - iter 155/311 - loss 0.06980435 - time (sec): 633.63 - samples/sec: 322.83 - lr: 0.000066 - momentum: 0.000000
2023-07-21 11:15:04,415 epoch 2 - iter 186/311 - loss 0.06761276 - time (sec): 763.92 - samples/sec: 319.61 - lr: 0.000065 - momentum: 0.000000
2023-07-21 11:17:14,416 epoch 2 - iter 217/311 - loss 0.06522780 - time (sec): 893.92 - samples/sec: 318.64 - lr: 0.000065 - momentum: 0.000000
2023-07-21 11:19:26,053 epoch 2 - iter 248/311 - loss 0.06273862 - time (sec): 1025.55 - samples/sec: 318.73 - lr: 0.000064 - momentum: 0.000000
2023-07-21 11:21:39,122 epoch 2 - iter 279/311 - loss 0.06106673 - time (sec): 1158.62 - samples/sec: 316.88 - lr: 0.000063 - momentum: 0.000000
2023-07-21 11:23:48,829 epoch 2 - iter 310/311 - loss 0.05956468 - time (sec): 1288.33 - samples/sec: 315.56 - lr: 0.000062 - momentum: 0.000000
2023-07-21 11:23:52,057 ----------------------------------------------------------------------------------------------------
2023-07-21 11:23:52,058 EPOCH 2 done: loss 0.0595 - lr: 0.000062
2023-07-21 11:24:52,487 DEV : loss 0.16827185451984406 - f1-score (micro avg)  0.7041
2023-07-21 11:27:25,302 TEST : loss 0.04856809228658676 - f1-score (micro avg)  0.9243
2023-07-21 11:27:25,470 ----------------------------------------------------------------------------------------------------
2023-07-21 11:29:35,139 epoch 3 - iter 31/311 - loss 0.02986174 - time (sec): 129.67 - samples/sec: 313.46 - lr: 0.000061 - momentum: 0.000000
2023-07-21 11:31:42,589 epoch 3 - iter 62/311 - loss 0.03201206 - time (sec): 257.12 - samples/sec: 318.01 - lr: 0.000061 - momentum: 0.000000
2023-07-21 11:33:48,202 epoch 3 - iter 93/311 - loss 0.03316140 - time (sec): 382.73 - samples/sec: 318.03 - lr: 0.000060 - momentum: 0.000000
2023-07-21 11:35:57,660 epoch 3 - iter 124/311 - loss 0.03252476 - time (sec): 512.19 - samples/sec: 316.70 - lr: 0.000059 - momentum: 0.000000
2023-07-21 11:38:05,475 epoch 3 - iter 155/311 - loss 0.03251996 - time (sec): 640.00 - samples/sec: 316.53 - lr: 0.000058 - momentum: 0.000000
2023-07-21 11:40:11,413 epoch 3 - iter 186/311 - loss 0.03243710 - time (sec): 765.94 - samples/sec: 316.98 - lr: 0.000058 - momentum: 0.000000
2023-07-21 11:42:23,787 epoch 3 - iter 217/311 - loss 0.03181540 - time (sec): 898.32 - samples/sec: 315.73 - lr: 0.000057 - momentum: 0.000000
2023-07-21 11:44:32,776 epoch 3 - iter 248/311 - loss 0.03171458 - time (sec): 1027.30 - samples/sec: 315.77 - lr: 0.000056 - momentum: 0.000000
2023-07-21 11:46:43,410 epoch 3 - iter 279/311 - loss 0.03200664 - time (sec): 1157.94 - samples/sec: 315.37 - lr: 0.000055 - momentum: 0.000000
2023-07-21 11:48:57,722 epoch 3 - iter 310/311 - loss 0.03156704 - time (sec): 1292.25 - samples/sec: 314.45 - lr: 0.000055 - momentum: 0.000000
2023-07-21 11:49:01,024 ----------------------------------------------------------------------------------------------------
2023-07-21 11:49:01,025 EPOCH 3 done: loss 0.0317 - lr: 0.000055
2023-07-21 11:50:01,333 DEV : loss 0.1822664588689804 - f1-score (micro avg)  0.7142
2023-07-21 11:52:34,884 TEST : loss 0.05835077539086342 - f1-score (micro avg)  0.9248
2023-07-21 11:52:35,037 ----------------------------------------------------------------------------------------------------
2023-07-21 11:54:47,322 epoch 4 - iter 31/311 - loss 0.02100987 - time (sec): 132.28 - samples/sec: 309.62 - lr: 0.000054 - momentum: 0.000000
2023-07-21 11:56:56,451 epoch 4 - iter 62/311 - loss 0.02075583 - time (sec): 261.41 - samples/sec: 312.43 - lr: 0.000053 - momentum: 0.000000
2023-07-21 11:59:03,552 epoch 4 - iter 93/311 - loss 0.02100156 - time (sec): 388.51 - samples/sec: 313.51 - lr: 0.000052 - momentum: 0.000000
2023-07-21 12:01:12,593 epoch 4 - iter 124/311 - loss 0.02156652 - time (sec): 517.55 - samples/sec: 313.97 - lr: 0.000051 - momentum: 0.000000
2023-07-21 12:03:18,611 epoch 4 - iter 155/311 - loss 0.02202745 - time (sec): 643.57 - samples/sec: 316.33 - lr: 0.000051 - momentum: 0.000000
2023-07-21 12:05:25,891 epoch 4 - iter 186/311 - loss 0.02168832 - time (sec): 770.85 - samples/sec: 317.79 - lr: 0.000050 - momentum: 0.000000
2023-07-21 12:07:33,286 epoch 4 - iter 217/311 - loss 0.02262573 - time (sec): 898.25 - samples/sec: 317.42 - lr: 0.000049 - momentum: 0.000000
2023-07-21 12:09:45,356 epoch 4 - iter 248/311 - loss 0.02246251 - time (sec): 1030.32 - samples/sec: 315.84 - lr: 0.000048 - momentum: 0.000000
2023-07-21 12:11:56,790 epoch 4 - iter 279/311 - loss 0.02265126 - time (sec): 1161.75 - samples/sec: 315.54 - lr: 0.000048 - momentum: 0.000000
2023-07-21 12:14:10,917 epoch 4 - iter 310/311 - loss 0.02280872 - time (sec): 1295.88 - samples/sec: 313.65 - lr: 0.000047 - momentum: 0.000000
2023-07-21 12:14:14,456 ----------------------------------------------------------------------------------------------------
2023-07-21 12:14:14,456 EPOCH 4 done: loss 0.0229 - lr: 0.000047
2023-07-21 12:15:13,488 DEV : loss 0.1944562792778015 - f1-score (micro avg)  0.7106
2023-07-21 12:17:48,023 TEST : loss 0.0611976683139801 - f1-score (micro avg)  0.9166
2023-07-21 12:17:48,193 ----------------------------------------------------------------------------------------------------
2023-07-21 12:19:59,474 epoch 5 - iter 31/311 - loss 0.02014714 - time (sec): 131.28 - samples/sec: 311.89 - lr: 0.000046 - momentum: 0.000000
2023-07-21 12:22:08,765 epoch 5 - iter 62/311 - loss 0.02078144 - time (sec): 260.57 - samples/sec: 313.46 - lr: 0.000045 - momentum: 0.000000
2023-07-21 12:24:17,518 epoch 5 - iter 93/311 - loss 0.01946986 - time (sec): 389.32 - samples/sec: 313.28 - lr: 0.000044 - momentum: 0.000000
2023-07-21 12:26:23,927 epoch 5 - iter 124/311 - loss 0.02052200 - time (sec): 515.73 - samples/sec: 315.85 - lr: 0.000044 - momentum: 0.000000
2023-07-21 12:28:30,829 epoch 5 - iter 155/311 - loss 0.02110562 - time (sec): 642.63 - samples/sec: 315.79 - lr: 0.000043 - momentum: 0.000000
2023-07-21 12:30:40,920 epoch 5 - iter 186/311 - loss 0.02079338 - time (sec): 772.72 - samples/sec: 314.58 - lr: 0.000042 - momentum: 0.000000
2023-07-21 12:32:48,702 epoch 5 - iter 217/311 - loss 0.02093873 - time (sec): 900.51 - samples/sec: 314.53 - lr: 0.000041 - momentum: 0.000000
2023-07-21 12:34:59,443 epoch 5 - iter 248/311 - loss 0.02101437 - time (sec): 1031.25 - samples/sec: 315.20 - lr: 0.000041 - momentum: 0.000000
2023-07-21 12:37:11,501 epoch 5 - iter 279/311 - loss 0.02095178 - time (sec): 1163.31 - samples/sec: 314.05 - lr: 0.000040 - momentum: 0.000000
2023-07-21 12:39:23,565 epoch 5 - iter 310/311 - loss 0.02086756 - time (sec): 1295.37 - samples/sec: 313.74 - lr: 0.000039 - momentum: 0.000000
2023-07-21 12:39:26,428 ----------------------------------------------------------------------------------------------------
2023-07-21 12:39:26,428 EPOCH 5 done: loss 0.0208 - lr: 0.000039
2023-07-21 12:40:26,990 DEV : loss 0.1779567450284958 - f1-score (micro avg)  0.7196
2023-07-21 12:42:56,540 TEST : loss 0.05860697850584984 - f1-score (micro avg)  0.9205
2023-07-21 12:42:56,735 ----------------------------------------------------------------------------------------------------
2023-07-21 12:45:08,884 epoch 6 - iter 31/311 - loss 0.01377889 - time (sec): 132.15 - samples/sec: 306.09 - lr: 0.000038 - momentum: 0.000000
2023-07-21 12:47:20,641 epoch 6 - iter 62/311 - loss 0.01446629 - time (sec): 263.90 - samples/sec: 308.00 - lr: 0.000037 - momentum: 0.000000
2023-07-21 12:49:30,907 epoch 6 - iter 93/311 - loss 0.01374803 - time (sec): 394.17 - samples/sec: 309.16 - lr: 0.000037 - momentum: 0.000000
2023-07-21 12:51:38,277 epoch 6 - iter 124/311 - loss 0.01438033 - time (sec): 521.54 - samples/sec: 312.42 - lr: 0.000036 - momentum: 0.000000
2023-07-21 12:53:45,534 epoch 6 - iter 155/311 - loss 0.01410682 - time (sec): 648.80 - samples/sec: 312.40 - lr: 0.000035 - momentum: 0.000000
2023-07-21 12:55:57,176 epoch 6 - iter 186/311 - loss 0.01403862 - time (sec): 780.44 - samples/sec: 312.59 - lr: 0.000034 - momentum: 0.000000
2023-07-21 12:58:04,133 epoch 6 - iter 217/311 - loss 0.01385840 - time (sec): 907.40 - samples/sec: 314.33 - lr: 0.000034 - momentum: 0.000000
2023-07-21 13:00:14,462 epoch 6 - iter 248/311 - loss 0.01355538 - time (sec): 1037.72 - samples/sec: 314.08 - lr: 0.000033 - momentum: 0.000000
2023-07-21 13:02:29,282 epoch 6 - iter 279/311 - loss 0.01373412 - time (sec): 1172.54 - samples/sec: 312.31 - lr: 0.000032 - momentum: 0.000000
2023-07-21 13:04:39,672 epoch 6 - iter 310/311 - loss 0.01361383 - time (sec): 1302.93 - samples/sec: 311.97 - lr: 0.000031 - momentum: 0.000000
2023-07-21 13:04:42,978 ----------------------------------------------------------------------------------------------------
2023-07-21 13:04:42,978 EPOCH 6 done: loss 0.0136 - lr: 0.000031
2023-07-21 13:05:43,892 DEV : loss 0.20487748086452484 - f1-score (micro avg)  0.7069
2023-07-21 13:08:13,440 TEST : loss 0.057358164340257645 - f1-score (micro avg)  0.9286
2023-07-21 13:08:13,567 ----------------------------------------------------------------------------------------------------
2023-07-21 13:10:25,060 epoch 7 - iter 31/311 - loss 0.01133441 - time (sec): 131.49 - samples/sec: 297.54 - lr: 0.000030 - momentum: 0.000000
2023-07-21 13:12:37,761 epoch 7 - iter 62/311 - loss 0.01007758 - time (sec): 264.19 - samples/sec: 310.35 - lr: 0.000030 - momentum: 0.000000
2023-07-21 13:14:44,518 epoch 7 - iter 93/311 - loss 0.01047863 - time (sec): 390.95 - samples/sec: 317.16 - lr: 0.000029 - momentum: 0.000000
2023-07-21 13:16:52,451 epoch 7 - iter 124/311 - loss 0.01001764 - time (sec): 518.88 - samples/sec: 316.82 - lr: 0.000028 - momentum: 0.000000
2023-07-21 13:19:02,049 epoch 7 - iter 155/311 - loss 0.01002178 - time (sec): 648.48 - samples/sec: 315.74 - lr: 0.000027 - momentum: 0.000000
2023-07-21 13:21:06,526 epoch 7 - iter 186/311 - loss 0.00936163 - time (sec): 772.96 - samples/sec: 316.84 - lr: 0.000027 - momentum: 0.000000
2023-07-21 13:23:15,957 epoch 7 - iter 217/311 - loss 0.00936473 - time (sec): 902.39 - samples/sec: 314.56 - lr: 0.000026 - momentum: 0.000000
2023-07-21 13:25:25,838 epoch 7 - iter 248/311 - loss 0.00955686 - time (sec): 1032.27 - samples/sec: 314.53 - lr: 0.000025 - momentum: 0.000000
2023-07-21 13:27:38,767 epoch 7 - iter 279/311 - loss 0.00922235 - time (sec): 1165.20 - samples/sec: 313.36 - lr: 0.000024 - momentum: 0.000000
2023-07-21 13:29:51,572 epoch 7 - iter 310/311 - loss 0.00912150 - time (sec): 1298.00 - samples/sec: 313.15 - lr: 0.000023 - momentum: 0.000000
2023-07-21 13:29:55,535 ----------------------------------------------------------------------------------------------------
2023-07-21 13:29:55,535 EPOCH 7 done: loss 0.0091 - lr: 0.000023
2023-07-21 13:30:58,910 DEV : loss 0.22087252140045166 - f1-score (micro avg)  0.7207
2023-07-21 13:33:31,646 TEST : loss 0.061075057834386826 - f1-score (micro avg)  0.9318
2023-07-21 13:33:31,820 ----------------------------------------------------------------------------------------------------
2023-07-21 13:35:43,189 epoch 8 - iter 31/311 - loss 0.00661734 - time (sec): 131.37 - samples/sec: 305.75 - lr: 0.000023 - momentum: 0.000000
2023-07-21 13:37:56,067 epoch 8 - iter 62/311 - loss 0.00574063 - time (sec): 264.25 - samples/sec: 308.67 - lr: 0.000022 - momentum: 0.000000
2023-07-21 13:40:04,468 epoch 8 - iter 93/311 - loss 0.00557099 - time (sec): 392.65 - samples/sec: 311.82 - lr: 0.000021 - momentum: 0.000000
2023-07-21 13:42:16,162 epoch 8 - iter 124/311 - loss 0.00609410 - time (sec): 524.34 - samples/sec: 309.59 - lr: 0.000020 - momentum: 0.000000
2023-07-21 13:44:23,395 epoch 8 - iter 155/311 - loss 0.00594175 - time (sec): 651.57 - samples/sec: 313.00 - lr: 0.000020 - momentum: 0.000000
2023-07-21 13:46:31,383 epoch 8 - iter 186/311 - loss 0.00571707 - time (sec): 779.56 - samples/sec: 314.06 - lr: 0.000019 - momentum: 0.000000
2023-07-21 13:48:38,294 epoch 8 - iter 217/311 - loss 0.00575028 - time (sec): 906.47 - samples/sec: 314.06 - lr: 0.000018 - momentum: 0.000000
2023-07-21 13:50:47,095 epoch 8 - iter 248/311 - loss 0.00576315 - time (sec): 1035.27 - samples/sec: 314.01 - lr: 0.000017 - momentum: 0.000000
2023-07-21 13:52:59,336 epoch 8 - iter 279/311 - loss 0.00580575 - time (sec): 1167.51 - samples/sec: 313.06 - lr: 0.000017 - momentum: 0.000000
2023-07-21 13:55:15,022 epoch 8 - iter 310/311 - loss 0.00620637 - time (sec): 1303.20 - samples/sec: 312.02 - lr: 0.000016 - momentum: 0.000000
2023-07-21 13:55:17,688 ----------------------------------------------------------------------------------------------------
2023-07-21 13:55:17,688 EPOCH 8 done: loss 0.0062 - lr: 0.000016
2023-07-21 13:56:14,556 DEV : loss 0.2740419805049896 - f1-score (micro avg)  0.6535
2023-07-21 13:58:48,179 TEST : loss 0.06485176086425781 - f1-score (micro avg)  0.9291
2023-07-21 13:58:48,338 ----------------------------------------------------------------------------------------------------
2023-07-21 14:00:59,084 epoch 9 - iter 31/311 - loss 0.00468181 - time (sec): 130.74 - samples/sec: 303.91 - lr: 0.000015 - momentum: 0.000000
2023-07-21 14:03:09,120 epoch 9 - iter 62/311 - loss 0.00462327 - time (sec): 260.78 - samples/sec: 309.14 - lr: 0.000014 - momentum: 0.000000
2023-07-21 14:05:14,169 epoch 9 - iter 93/311 - loss 0.00454410 - time (sec): 385.83 - samples/sec: 311.41 - lr: 0.000013 - momentum: 0.000000
2023-07-21 14:07:23,775 epoch 9 - iter 124/311 - loss 0.00446894 - time (sec): 515.44 - samples/sec: 312.58 - lr: 0.000013 - momentum: 0.000000
2023-07-21 14:09:33,053 epoch 9 - iter 155/311 - loss 0.00458259 - time (sec): 644.71 - samples/sec: 314.72 - lr: 0.000012 - momentum: 0.000000
2023-07-21 14:11:43,889 epoch 9 - iter 186/311 - loss 0.00462824 - time (sec): 775.55 - samples/sec: 315.65 - lr: 0.000011 - momentum: 0.000000
2023-07-21 14:13:54,464 epoch 9 - iter 217/311 - loss 0.00483822 - time (sec): 906.12 - samples/sec: 315.36 - lr: 0.000010 - momentum: 0.000000
2023-07-21 14:16:04,539 epoch 9 - iter 248/311 - loss 0.00476429 - time (sec): 1036.20 - samples/sec: 314.99 - lr: 0.000010 - momentum: 0.000000
2023-07-21 14:18:15,304 epoch 9 - iter 279/311 - loss 0.00469869 - time (sec): 1166.96 - samples/sec: 313.93 - lr: 0.000009 - momentum: 0.000000
2023-07-21 14:20:28,787 epoch 9 - iter 310/311 - loss 0.00478029 - time (sec): 1300.45 - samples/sec: 312.64 - lr: 0.000008 - momentum: 0.000000
2023-07-21 14:20:32,266 ----------------------------------------------------------------------------------------------------
2023-07-21 14:20:32,267 EPOCH 9 done: loss 0.0048 - lr: 0.000008
2023-07-21 14:21:33,362 DEV : loss 0.27065402269363403 - f1-score (micro avg)  0.6783
2023-07-21 14:24:06,519 TEST : loss 0.06148085743188858 - f1-score (micro avg)  0.9338
2023-07-21 14:24:06,709 ----------------------------------------------------------------------------------------------------
2023-07-21 14:26:21,902 epoch 10 - iter 31/311 - loss 0.00267597 - time (sec): 135.19 - samples/sec: 303.36 - lr: 0.000007 - momentum: 0.000000
2023-07-21 14:28:36,631 epoch 10 - iter 62/311 - loss 0.00315186 - time (sec): 269.92 - samples/sec: 299.73 - lr: 0.000006 - momentum: 0.000000
2023-07-21 14:30:47,901 epoch 10 - iter 93/311 - loss 0.00290834 - time (sec): 401.19 - samples/sec: 305.81 - lr: 0.000006 - momentum: 0.000000
2023-07-21 14:32:59,364 epoch 10 - iter 124/311 - loss 0.00312016 - time (sec): 532.65 - samples/sec: 309.86 - lr: 0.000005 - momentum: 0.000000
2023-07-21 14:35:05,979 epoch 10 - iter 155/311 - loss 0.00304471 - time (sec): 659.27 - samples/sec: 311.46 - lr: 0.000004 - momentum: 0.000000
2023-07-21 14:37:14,522 epoch 10 - iter 186/311 - loss 0.00317227 - time (sec): 787.81 - samples/sec: 311.05 - lr: 0.000003 - momentum: 0.000000
2023-07-21 14:39:24,342 epoch 10 - iter 217/311 - loss 0.00302828 - time (sec): 917.63 - samples/sec: 311.56 - lr: 0.000003 - momentum: 0.000000
2023-07-21 14:41:37,208 epoch 10 - iter 248/311 - loss 0.00315081 - time (sec): 1050.50 - samples/sec: 310.57 - lr: 0.000002 - momentum: 0.000000
2023-07-21 14:43:53,267 epoch 10 - iter 279/311 - loss 0.00320804 - time (sec): 1186.56 - samples/sec: 308.70 - lr: 0.000001 - momentum: 0.000000
2023-07-21 14:46:03,180 epoch 10 - iter 310/311 - loss 0.00322004 - time (sec): 1316.47 - samples/sec: 308.75 - lr: 0.000000 - momentum: 0.000000
2023-07-21 14:46:07,005 ----------------------------------------------------------------------------------------------------
2023-07-21 14:46:07,005 EPOCH 10 done: loss 0.0032 - lr: 0.000000
2023-07-21 14:47:08,826 DEV : loss 0.26926571130752563 - f1-score (micro avg)  0.6918
2023-07-21 14:49:44,482 TEST : loss 0.06273368746042252 - f1-score (micro avg)  0.9355
2023-07-21 14:49:55,359 ----------------------------------------------------------------------------------------------------
2023-07-21 14:49:55,364 Testing using last state of model ...
2023-07-21 14:52:27,108 
Results:
- F-score (micro) 0.9355
- F-score (macro) 0.9321
- Accuracy 0.9087

By class:
              precision    recall  f1-score   support

         PER     0.9737    0.9827    0.9782      2715
         ORG     0.8978    0.9331    0.9152      2543
         LOC     0.9559    0.9328    0.9442      2442
        MISC     0.8884    0.8931    0.8907      1889

   micro avg     0.9318    0.9392    0.9355      9589
   macro avg     0.9290    0.9354    0.9321      9589
weighted avg     0.9323    0.9392    0.9356      9589

2023-07-21 14:52:27,109 ----------------------------------------------------------------------------------------------------
