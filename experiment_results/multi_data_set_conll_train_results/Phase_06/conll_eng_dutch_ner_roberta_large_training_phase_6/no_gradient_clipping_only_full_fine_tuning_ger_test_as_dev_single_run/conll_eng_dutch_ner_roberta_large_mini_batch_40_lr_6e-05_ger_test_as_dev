2023-07-20 13:26:40,718 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,720 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLMRobertaModel(
      (embeddings): XLMRobertaEmbeddings(
        (word_embeddings): Embedding(250003, 1024)
        (position_embeddings): Embedding(514, 1024, padding_idx=1)
        (token_type_embeddings): Embedding(1, 1024)
        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): XLMRobertaEncoder(
        (layer): ModuleList(
          (0-23): 24 x XLMRobertaLayer(
            (attention): XLMRobertaAttention(
              (self): XLMRobertaSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): XLMRobertaSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): XLMRobertaIntermediate(
              (dense): Linear(in_features=1024, out_features=4096, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): XLMRobertaOutput(
              (dense): Linear(in_features=4096, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): XLMRobertaPooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): Tanh()
      )
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=17, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-07-20 13:26:40,720 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,720 MultiCorpus: 31080 train + 3160 dev + 8998 test sentences
 - CONLL_03_DUTCH Corpus: 16093 train + 2969 dev + 5314 test sentences - /vol/fob-vol4/mi17/christod/.flair/datasets/conll_03_dutch
 - CONLL_03 Corpus: 14987 train + 3466 dev + 3684 test sentences - /vol/fob-vol4/mi17/christod/.flair/datasets/conll_03
2023-07-20 13:26:40,720 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,720 Train:  31080 sentences
2023-07-20 13:26:40,721         (train_with_dev=False, train_with_test=False)
2023-07-20 13:26:40,721 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,722 Training Params:
2023-07-20 13:26:40,722  - learning_rate: "6e-05" 
2023-07-20 13:26:40,722  - mini_batch_size: "40"
2023-07-20 13:26:40,722  - max_epochs: "10"
2023-07-20 13:26:40,722  - shuffle: "True"
2023-07-20 13:26:40,722 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,722 Plugins:
2023-07-20 13:26:40,722  - LinearScheduler | warmup_fraction: '0.1'
2023-07-20 13:26:40,722 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,722 Final evaluation on model after last epoch (final-model.pt)
2023-07-20 13:26:40,722  - metric: "('micro avg', 'f1-score')"
2023-07-20 13:26:40,722 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,723 Computation:
2023-07-20 13:26:40,723  - compute on device: cuda:2
2023-07-20 13:26:40,723  - embedding storage: none
2023-07-20 13:26:40,723 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,723 Model training base path: "resources/taggers/conll_eng_dutch_ner_roberta_large_mini_batch_40_lr_6e-05_ger_test_as_dev"
2023-07-20 13:26:40,724 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,724 Removed gradient clipping
2023-07-20 13:26:40,724 ----------------------------------------------------------------------------------------------------
2023-07-20 13:26:40,724 ----------------------------------------------------------------------------------------------------
2023-07-20 13:29:05,570 epoch 1 - iter 77/777 - loss 1.86927277 - time (sec): 144.85 - samples/sec: 287.40 - lr: 0.000006 - momentum: 0.000000
2023-07-20 13:31:25,215 epoch 1 - iter 154/777 - loss 1.20381477 - time (sec): 284.49 - samples/sec: 285.70 - lr: 0.000012 - momentum: 0.000000
2023-07-20 13:33:49,441 epoch 1 - iter 231/777 - loss 0.91500615 - time (sec): 428.72 - samples/sec: 283.96 - lr: 0.000018 - momentum: 0.000000
2023-07-20 13:36:14,521 epoch 1 - iter 308/777 - loss 0.74764784 - time (sec): 573.80 - samples/sec: 280.52 - lr: 0.000024 - momentum: 0.000000
2023-07-20 13:38:42,678 epoch 1 - iter 385/777 - loss 0.62821306 - time (sec): 721.95 - samples/sec: 278.34 - lr: 0.000030 - momentum: 0.000000
2023-07-20 13:41:10,715 epoch 1 - iter 462/777 - loss 0.54205514 - time (sec): 869.99 - samples/sec: 275.71 - lr: 0.000036 - momentum: 0.000000
2023-07-20 13:43:38,176 epoch 1 - iter 539/777 - loss 0.47311724 - time (sec): 1017.45 - samples/sec: 277.90 - lr: 0.000042 - momentum: 0.000000
2023-07-20 13:45:52,909 epoch 1 - iter 616/777 - loss 0.42379205 - time (sec): 1152.18 - samples/sec: 280.94 - lr: 0.000047 - momentum: 0.000000
2023-07-20 13:48:10,458 epoch 1 - iter 693/777 - loss 0.38616873 - time (sec): 1289.73 - samples/sec: 281.45 - lr: 0.000053 - momentum: 0.000000
2023-07-20 13:50:32,893 epoch 1 - iter 770/777 - loss 0.36098757 - time (sec): 1432.17 - samples/sec: 281.96 - lr: 0.000059 - momentum: 0.000000
2023-07-20 13:50:43,495 ----------------------------------------------------------------------------------------------------
2023-07-20 13:50:43,495 EPOCH 1 done: loss 0.3588 - lr: 0.000059
2023-07-20 13:51:44,684 DEV : loss 0.13959866762161255 - f1-score (micro avg)  0.7342
2023-07-20 13:54:13,114 TEST : loss 0.07925235480070114 - f1-score (micro avg)  0.8723
2023-07-20 13:54:13,299 ----------------------------------------------------------------------------------------------------
2023-07-20 13:56:42,065 epoch 2 - iter 77/777 - loss 0.11228824 - time (sec): 148.76 - samples/sec: 266.95 - lr: 0.000059 - momentum: 0.000000
2023-07-20 13:59:09,047 epoch 2 - iter 154/777 - loss 0.09596916 - time (sec): 295.75 - samples/sec: 272.99 - lr: 0.000059 - momentum: 0.000000
2023-07-20 14:01:30,276 epoch 2 - iter 231/777 - loss 0.09110026 - time (sec): 436.98 - samples/sec: 275.42 - lr: 0.000058 - momentum: 0.000000
2023-07-20 14:03:59,354 epoch 2 - iter 308/777 - loss 0.08816191 - time (sec): 586.05 - samples/sec: 274.41 - lr: 0.000057 - momentum: 0.000000
2023-07-20 14:06:25,879 epoch 2 - iter 385/777 - loss 0.10357885 - time (sec): 732.58 - samples/sec: 274.00 - lr: 0.000057 - momentum: 0.000000
2023-07-20 14:08:51,793 epoch 2 - iter 462/777 - loss 0.10311918 - time (sec): 878.49 - samples/sec: 274.25 - lr: 0.000056 - momentum: 0.000000
2023-07-20 14:11:16,046 epoch 2 - iter 539/777 - loss 0.12202065 - time (sec): 1022.75 - samples/sec: 274.45 - lr: 0.000055 - momentum: 0.000000
2023-07-20 14:13:41,564 epoch 2 - iter 616/777 - loss 0.13200225 - time (sec): 1168.26 - samples/sec: 273.28 - lr: 0.000055 - momentum: 0.000000
2023-07-20 14:16:11,055 epoch 2 - iter 693/777 - loss 0.12982047 - time (sec): 1317.75 - samples/sec: 274.29 - lr: 0.000054 - momentum: 0.000000
2023-07-20 14:18:31,801 epoch 2 - iter 770/777 - loss 0.12705650 - time (sec): 1458.50 - samples/sec: 276.94 - lr: 0.000053 - momentum: 0.000000
2023-07-20 14:18:45,720 ----------------------------------------------------------------------------------------------------
2023-07-20 14:18:45,720 EPOCH 2 done: loss 0.1272 - lr: 0.000053
2023-07-20 14:19:53,401 DEV : loss 0.4036148190498352 - f1-score (micro avg)  0.4761
2023-07-20 14:22:32,417 TEST : loss 0.08674091100692749 - f1-score (micro avg)  0.8662
2023-07-20 14:22:32,624 ----------------------------------------------------------------------------------------------------
2023-07-20 14:24:55,552 epoch 3 - iter 77/777 - loss 0.12357266 - time (sec): 142.93 - samples/sec: 278.37 - lr: 0.000053 - momentum: 0.000000
2023-07-20 14:27:14,285 epoch 3 - iter 154/777 - loss 0.11443858 - time (sec): 281.66 - samples/sec: 286.31 - lr: 0.000052 - momentum: 0.000000
2023-07-20 14:29:39,308 epoch 3 - iter 231/777 - loss 0.10164450 - time (sec): 426.68 - samples/sec: 284.24 - lr: 0.000051 - momentum: 0.000000
2023-07-20 14:32:08,990 epoch 3 - iter 308/777 - loss 0.09484107 - time (sec): 576.36 - samples/sec: 279.77 - lr: 0.000051 - momentum: 0.000000
2023-07-20 14:34:37,596 epoch 3 - iter 385/777 - loss 0.09020878 - time (sec): 724.97 - samples/sec: 277.32 - lr: 0.000050 - momentum: 0.000000
2023-07-20 14:37:06,338 epoch 3 - iter 462/777 - loss 0.08559775 - time (sec): 873.71 - samples/sec: 276.14 - lr: 0.000049 - momentum: 0.000000
2023-07-20 14:39:27,404 epoch 3 - iter 539/777 - loss 0.08130021 - time (sec): 1014.78 - samples/sec: 277.13 - lr: 0.000049 - momentum: 0.000000
2023-07-20 14:41:43,186 epoch 3 - iter 616/777 - loss 0.07711798 - time (sec): 1150.56 - samples/sec: 280.22 - lr: 0.000048 - momentum: 0.000000
2023-07-20 14:44:10,465 epoch 3 - iter 693/777 - loss 0.07303857 - time (sec): 1297.84 - samples/sec: 280.19 - lr: 0.000047 - momentum: 0.000000
2023-07-20 14:46:43,601 epoch 3 - iter 770/777 - loss 0.07075025 - time (sec): 1450.97 - samples/sec: 278.18 - lr: 0.000047 - momentum: 0.000000
2023-07-20 14:46:53,917 ----------------------------------------------------------------------------------------------------
2023-07-20 14:46:53,918 EPOCH 3 done: loss 0.0705 - lr: 0.000047
2023-07-20 14:47:58,991 DEV : loss 0.236536905169487 - f1-score (micro avg)  0.6193
2023-07-20 14:50:40,135 TEST : loss 0.05515715479850769 - f1-score (micro avg)  0.9127
2023-07-20 14:50:40,377 ----------------------------------------------------------------------------------------------------
2023-07-20 14:53:06,194 epoch 4 - iter 77/777 - loss 0.03624820 - time (sec): 145.81 - samples/sec: 271.45 - lr: 0.000046 - momentum: 0.000000
2023-07-20 14:55:29,389 epoch 4 - iter 154/777 - loss 0.03680428 - time (sec): 289.01 - samples/sec: 275.11 - lr: 0.000045 - momentum: 0.000000
2023-07-20 14:57:54,584 epoch 4 - iter 231/777 - loss 0.03560753 - time (sec): 434.20 - samples/sec: 276.77 - lr: 0.000045 - momentum: 0.000000
2023-07-20 15:00:10,178 epoch 4 - iter 308/777 - loss 0.03612704 - time (sec): 569.80 - samples/sec: 282.63 - lr: 0.000044 - momentum: 0.000000
2023-07-20 15:02:40,428 epoch 4 - iter 385/777 - loss 0.03637111 - time (sec): 720.05 - samples/sec: 281.37 - lr: 0.000043 - momentum: 0.000000
2023-07-20 15:05:07,607 epoch 4 - iter 462/777 - loss 0.03777223 - time (sec): 867.23 - samples/sec: 279.31 - lr: 0.000043 - momentum: 0.000000
2023-07-20 15:07:32,162 epoch 4 - iter 539/777 - loss 0.03841423 - time (sec): 1011.78 - samples/sec: 279.56 - lr: 0.000042 - momentum: 0.000000
2023-07-20 15:09:55,605 epoch 4 - iter 616/777 - loss 0.04016460 - time (sec): 1155.23 - samples/sec: 278.79 - lr: 0.000041 - momentum: 0.000000
2023-07-20 15:12:25,952 epoch 4 - iter 693/777 - loss 0.04010942 - time (sec): 1305.57 - samples/sec: 278.47 - lr: 0.000041 - momentum: 0.000000
2023-07-20 15:14:56,215 epoch 4 - iter 770/777 - loss 0.04028145 - time (sec): 1455.84 - samples/sec: 277.60 - lr: 0.000040 - momentum: 0.000000
2023-07-20 15:15:07,857 ----------------------------------------------------------------------------------------------------
2023-07-20 15:15:07,857 EPOCH 4 done: loss 0.0402 - lr: 0.000040
2023-07-20 15:16:10,501 DEV : loss 0.2557727098464966 - f1-score (micro avg)  0.5701
2023-07-20 15:18:57,864 TEST : loss 0.054073940962553024 - f1-score (micro avg)  0.9199
2023-07-20 15:18:58,051 ----------------------------------------------------------------------------------------------------
2023-07-20 15:21:26,343 epoch 5 - iter 77/777 - loss 0.02840171 - time (sec): 148.29 - samples/sec: 268.49 - lr: 0.000039 - momentum: 0.000000
2023-07-20 15:23:49,731 epoch 5 - iter 154/777 - loss 0.02798835 - time (sec): 291.68 - samples/sec: 279.86 - lr: 0.000039 - momentum: 0.000000
2023-07-20 15:26:10,443 epoch 5 - iter 231/777 - loss 0.03120174 - time (sec): 432.39 - samples/sec: 281.77 - lr: 0.000038 - momentum: 0.000000
2023-07-20 15:28:29,034 epoch 5 - iter 308/777 - loss 0.03023860 - time (sec): 570.98 - samples/sec: 284.89 - lr: 0.000037 - momentum: 0.000000
2023-07-20 15:30:51,037 epoch 5 - iter 385/777 - loss 0.03700160 - time (sec): 712.98 - samples/sec: 284.13 - lr: 0.000037 - momentum: 0.000000
2023-07-20 15:33:09,480 epoch 5 - iter 462/777 - loss 0.03855787 - time (sec): 851.43 - samples/sec: 284.55 - lr: 0.000036 - momentum: 0.000000
2023-07-20 15:35:35,532 epoch 5 - iter 539/777 - loss 0.04077259 - time (sec): 997.48 - samples/sec: 283.27 - lr: 0.000035 - momentum: 0.000000
2023-07-20 15:38:08,410 epoch 5 - iter 616/777 - loss 0.04606537 - time (sec): 1150.36 - samples/sec: 281.82 - lr: 0.000035 - momentum: 0.000000
2023-07-20 15:40:31,879 epoch 5 - iter 693/777 - loss 0.04578185 - time (sec): 1293.83 - samples/sec: 281.08 - lr: 0.000034 - momentum: 0.000000
2023-07-20 15:42:59,814 epoch 5 - iter 770/777 - loss 0.04458505 - time (sec): 1441.76 - samples/sec: 280.04 - lr: 0.000033 - momentum: 0.000000
2023-07-20 15:43:13,799 ----------------------------------------------------------------------------------------------------
2023-07-20 15:43:13,800 EPOCH 5 done: loss 0.0446 - lr: 0.000033
2023-07-20 15:44:18,244 DEV : loss 0.3560357391834259 - f1-score (micro avg)  0.5326
2023-07-20 15:47:11,440 TEST : loss 0.06057814881205559 - f1-score (micro avg)  0.9114
2023-07-20 15:47:11,686 ----------------------------------------------------------------------------------------------------
2023-07-20 15:49:40,406 epoch 6 - iter 77/777 - loss 0.03095846 - time (sec): 148.72 - samples/sec: 277.35 - lr: 0.000033 - momentum: 0.000000
2023-07-20 15:52:10,822 epoch 6 - iter 154/777 - loss 0.03005557 - time (sec): 299.13 - samples/sec: 270.02 - lr: 0.000032 - momentum: 0.000000
2023-07-20 15:54:38,131 epoch 6 - iter 231/777 - loss 0.03467711 - time (sec): 446.44 - samples/sec: 272.84 - lr: 0.000031 - momentum: 0.000000
2023-07-20 15:56:54,159 epoch 6 - iter 308/777 - loss 0.03472048 - time (sec): 582.47 - samples/sec: 280.52 - lr: 0.000031 - momentum: 0.000000
2023-07-20 15:59:19,187 epoch 6 - iter 385/777 - loss 0.03535297 - time (sec): 727.50 - samples/sec: 280.07 - lr: 0.000030 - momentum: 0.000000
2023-07-20 16:01:37,016 epoch 6 - iter 462/777 - loss 0.03525913 - time (sec): 865.33 - samples/sec: 281.27 - lr: 0.000029 - momentum: 0.000000
2023-07-20 16:03:54,905 epoch 6 - iter 539/777 - loss 0.03463842 - time (sec): 1003.22 - samples/sec: 282.84 - lr: 0.000029 - momentum: 0.000000
2023-07-20 16:06:13,378 epoch 6 - iter 616/777 - loss 0.03416169 - time (sec): 1141.69 - samples/sec: 284.28 - lr: 0.000028 - momentum: 0.000000
2023-07-20 16:08:29,460 epoch 6 - iter 693/777 - loss 0.03414307 - time (sec): 1277.77 - samples/sec: 283.94 - lr: 0.000027 - momentum: 0.000000
2023-07-20 16:10:52,381 epoch 6 - iter 770/777 - loss 0.03387250 - time (sec): 1420.69 - samples/sec: 284.18 - lr: 0.000027 - momentum: 0.000000
2023-07-20 16:11:06,139 ----------------------------------------------------------------------------------------------------
2023-07-20 16:11:06,139 EPOCH 6 done: loss 0.0339 - lr: 0.000027
2023-07-20 16:12:12,478 DEV : loss 0.3452310264110565 - f1-score (micro avg)  0.4993
2023-07-20 16:14:55,953 TEST : loss 0.06615615636110306 - f1-score (micro avg)  0.8974
2023-07-20 16:14:56,169 ----------------------------------------------------------------------------------------------------
2023-07-20 16:17:15,513 epoch 7 - iter 77/777 - loss 0.05478083 - time (sec): 139.34 - samples/sec: 291.63 - lr: 0.000026 - momentum: 0.000000
2023-07-20 16:19:39,661 epoch 7 - iter 154/777 - loss 0.04403552 - time (sec): 283.49 - samples/sec: 285.51 - lr: 0.000025 - momentum: 0.000000
2023-07-20 16:21:59,837 epoch 7 - iter 231/777 - loss 0.04550763 - time (sec): 423.67 - samples/sec: 288.06 - lr: 0.000025 - momentum: 0.000000
2023-07-20 16:24:18,461 epoch 7 - iter 308/777 - loss 0.04062406 - time (sec): 562.29 - samples/sec: 289.72 - lr: 0.000024 - momentum: 0.000000
2023-07-20 16:26:33,920 epoch 7 - iter 385/777 - loss 0.03723469 - time (sec): 697.75 - samples/sec: 290.19 - lr: 0.000023 - momentum: 0.000000
2023-07-20 16:28:51,192 epoch 7 - iter 462/777 - loss 0.03480431 - time (sec): 835.02 - samples/sec: 290.36 - lr: 0.000023 - momentum: 0.000000
2023-07-20 16:31:07,755 epoch 7 - iter 539/777 - loss 0.03281236 - time (sec): 971.58 - samples/sec: 290.84 - lr: 0.000022 - momentum: 0.000000
2023-07-20 16:33:24,563 epoch 7 - iter 616/777 - loss 0.03122687 - time (sec): 1108.39 - samples/sec: 290.43 - lr: 0.000021 - momentum: 0.000000
2023-07-20 16:35:44,579 epoch 7 - iter 693/777 - loss 0.02986129 - time (sec): 1248.41 - samples/sec: 289.95 - lr: 0.000021 - momentum: 0.000000
2023-07-20 16:38:09,483 epoch 7 - iter 770/777 - loss 0.03078319 - time (sec): 1393.31 - samples/sec: 289.86 - lr: 0.000020 - momentum: 0.000000
2023-07-20 16:38:23,095 ----------------------------------------------------------------------------------------------------
2023-07-20 16:38:23,095 EPOCH 7 done: loss 0.0312 - lr: 0.000020
2023-07-20 16:39:29,066 DEV : loss 0.35746699571609497 - f1-score (micro avg)  0.4911
2023-07-20 16:42:10,808 TEST : loss 0.06457412987947464 - f1-score (micro avg)  0.8984
2023-07-20 16:42:11,039 ----------------------------------------------------------------------------------------------------
2023-07-20 16:44:32,330 epoch 8 - iter 77/777 - loss 0.03109671 - time (sec): 141.29 - samples/sec: 279.27 - lr: 0.000019 - momentum: 0.000000
2023-07-20 16:46:56,156 epoch 8 - iter 154/777 - loss 0.02533292 - time (sec): 285.11 - samples/sec: 279.66 - lr: 0.000019 - momentum: 0.000000
2023-07-20 16:49:11,186 epoch 8 - iter 231/777 - loss 0.02244083 - time (sec): 420.14 - samples/sec: 284.74 - lr: 0.000018 - momentum: 0.000000
2023-07-20 16:51:28,610 epoch 8 - iter 308/777 - loss 0.02137993 - time (sec): 557.57 - samples/sec: 286.06 - lr: 0.000017 - momentum: 0.000000
2023-07-20 16:53:49,389 epoch 8 - iter 385/777 - loss 0.02033779 - time (sec): 698.35 - samples/sec: 285.91 - lr: 0.000017 - momentum: 0.000000
2023-07-20 16:56:06,434 epoch 8 - iter 462/777 - loss 0.02010927 - time (sec): 835.39 - samples/sec: 287.68 - lr: 0.000016 - momentum: 0.000000
2023-07-20 16:58:25,372 epoch 8 - iter 539/777 - loss 0.01963129 - time (sec): 974.33 - samples/sec: 288.28 - lr: 0.000015 - momentum: 0.000000
2023-07-20 17:00:39,667 epoch 8 - iter 616/777 - loss 0.01908786 - time (sec): 1108.62 - samples/sec: 290.26 - lr: 0.000015 - momentum: 0.000000
2023-07-20 17:02:58,655 epoch 8 - iter 693/777 - loss 0.01827549 - time (sec): 1247.61 - samples/sec: 291.81 - lr: 0.000014 - momentum: 0.000000
2023-07-20 17:05:16,739 epoch 8 - iter 770/777 - loss 0.01784557 - time (sec): 1385.70 - samples/sec: 291.42 - lr: 0.000013 - momentum: 0.000000
2023-07-20 17:05:30,790 ----------------------------------------------------------------------------------------------------
2023-07-20 17:05:30,790 EPOCH 8 done: loss 0.0178 - lr: 0.000013
2023-07-20 17:06:34,174 DEV : loss 0.2832663059234619 - f1-score (micro avg)  0.6147
2023-07-20 17:09:12,334 TEST : loss 0.055212851613759995 - f1-score (micro avg)  0.9285
2023-07-20 17:09:12,562 ----------------------------------------------------------------------------------------------------
2023-07-20 17:11:29,809 epoch 9 - iter 77/777 - loss 0.01230391 - time (sec): 137.24 - samples/sec: 291.93 - lr: 0.000013 - momentum: 0.000000
2023-07-20 17:13:50,670 epoch 9 - iter 154/777 - loss 0.01161202 - time (sec): 278.11 - samples/sec: 289.78 - lr: 0.000012 - momentum: 0.000000
2023-07-20 17:16:05,632 epoch 9 - iter 231/777 - loss 0.01173484 - time (sec): 413.07 - samples/sec: 293.47 - lr: 0.000011 - momentum: 0.000000
2023-07-20 17:18:22,361 epoch 9 - iter 308/777 - loss 0.01107531 - time (sec): 549.80 - samples/sec: 294.04 - lr: 0.000011 - momentum: 0.000000
2023-07-20 17:20:43,753 epoch 9 - iter 385/777 - loss 0.01085813 - time (sec): 691.19 - samples/sec: 292.31 - lr: 0.000010 - momentum: 0.000000
2023-07-20 17:23:00,617 epoch 9 - iter 462/777 - loss 0.01113520 - time (sec): 828.05 - samples/sec: 292.91 - lr: 0.000009 - momentum: 0.000000
2023-07-20 17:25:14,738 epoch 9 - iter 539/777 - loss 0.01099769 - time (sec): 962.17 - samples/sec: 294.56 - lr: 0.000009 - momentum: 0.000000
2023-07-20 17:27:31,877 epoch 9 - iter 616/777 - loss 0.01071354 - time (sec): 1099.31 - samples/sec: 294.90 - lr: 0.000008 - momentum: 0.000000
2023-07-20 17:29:53,847 epoch 9 - iter 693/777 - loss 0.01070002 - time (sec): 1241.28 - samples/sec: 293.87 - lr: 0.000007 - momentum: 0.000000
2023-07-20 17:32:17,682 epoch 9 - iter 770/777 - loss 0.01061957 - time (sec): 1385.12 - samples/sec: 291.70 - lr: 0.000007 - momentum: 0.000000
2023-07-20 17:32:31,101 ----------------------------------------------------------------------------------------------------
2023-07-20 17:32:31,101 EPOCH 9 done: loss 0.0106 - lr: 0.000007
2023-07-20 17:33:32,806 DEV : loss 0.3727502226829529 - f1-score (micro avg)  0.559
2023-07-20 17:36:11,303 TEST : loss 0.056080177426338196 - f1-score (micro avg)  0.9289
2023-07-20 17:36:11,457 ----------------------------------------------------------------------------------------------------
2023-07-20 17:38:31,594 epoch 10 - iter 77/777 - loss 0.00900007 - time (sec): 140.13 - samples/sec: 289.41 - lr: 0.000006 - momentum: 0.000000
2023-07-20 17:40:54,097 epoch 10 - iter 154/777 - loss 0.00869044 - time (sec): 282.64 - samples/sec: 286.39 - lr: 0.000005 - momentum: 0.000000
2023-07-20 17:43:10,642 epoch 10 - iter 231/777 - loss 0.00864983 - time (sec): 419.18 - samples/sec: 290.12 - lr: 0.000005 - momentum: 0.000000
2023-07-20 17:45:24,541 epoch 10 - iter 308/777 - loss 0.00838124 - time (sec): 553.08 - samples/sec: 291.30 - lr: 0.000004 - momentum: 0.000000
2023-07-20 17:47:40,296 epoch 10 - iter 385/777 - loss 0.00861493 - time (sec): 688.84 - samples/sec: 293.65 - lr: 0.000003 - momentum: 0.000000
2023-07-20 17:49:53,520 epoch 10 - iter 462/777 - loss 0.00855703 - time (sec): 822.06 - samples/sec: 294.90 - lr: 0.000003 - momentum: 0.000000
2023-07-20 17:52:09,601 epoch 10 - iter 539/777 - loss 0.00853879 - time (sec): 958.14 - samples/sec: 294.50 - lr: 0.000002 - momentum: 0.000000
2023-07-20 17:54:25,226 epoch 10 - iter 616/777 - loss 0.00871300 - time (sec): 1093.77 - samples/sec: 296.05 - lr: 0.000001 - momentum: 0.000000
2023-07-20 17:56:43,557 epoch 10 - iter 693/777 - loss 0.00865154 - time (sec): 1232.10 - samples/sec: 295.06 - lr: 0.000001 - momentum: 0.000000
2023-07-20 17:59:06,548 epoch 10 - iter 770/777 - loss 0.00877978 - time (sec): 1375.09 - samples/sec: 293.52 - lr: 0.000000 - momentum: 0.000000
2023-07-20 17:59:19,993 ----------------------------------------------------------------------------------------------------
2023-07-20 17:59:19,993 EPOCH 10 done: loss 0.0088 - lr: 0.000000
2023-07-20 18:00:26,882 DEV : loss 0.3305884897708893 - f1-score (micro avg)  0.6065
2023-07-20 18:03:03,161 TEST : loss 0.057251010090112686 - f1-score (micro avg)  0.9299
2023-07-20 18:03:25,060 ----------------------------------------------------------------------------------------------------
2023-07-20 18:03:25,065 Testing using last state of model ...
2023-07-20 18:06:04,730 
Results:
- F-score (micro) 0.9299
- F-score (macro) 0.9263
- Accuracy 0.9006

By class:
              precision    recall  f1-score   support

         PER     0.9722    0.9801    0.9762      2715
         ORG     0.8979    0.9162    0.9070      2543
         LOC     0.9370    0.9378    0.9374      2442
        MISC     0.8842    0.8851    0.8847      1889

   micro avg     0.9261    0.9337    0.9299      9589
   macro avg     0.9228    0.9298    0.9263      9589
weighted avg     0.9262    0.9337    0.9299      9589

2023-07-20 18:06:04,730 ----------------------------------------------------------------------------------------------------
